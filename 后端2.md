# Netty



## BIO

### 同步阻塞案例

- Server

  ```java
  public class Server {
      public static void main(String[] args) {
          try {
              ServerSocket server = new ServerSocket(8848);
              System.out.println("服务端已启动");
              Socket socket = server.accept();
              InputStream is = socket.getInputStream();
              BufferedReader br = new BufferedReader(new InputStreamReader(is));
              String msg;
              // 此处用if
              if ((msg = br.readLine()) != null){
                  System.out.println("服务端收到：【 "+msg+" 】");
              }
  
          } catch (IOException e) {
              throw new RuntimeException(e);
          }
      }
  }
  ```

- Client

  ```java
  public class Client {
      public static void main(String[] args) throws IOException {
          Socket socket = new Socket("127.0.0.1", 8848);
          OutputStream outputStream = socket.getOutputStream();
          PrintStream ps = new PrintStream(outputStream);
          // 用print未写完一行数据，服务器无法读取到完整一行
          ps.print("hello, server!");
          ps.flush();
          // 未关闭，java.net.SocketException: Connection reset
      }
  }
  ```



### 多发多收

- Server

  ```java
  public class Server {
      public static void main(String[] args) {
          try {
              ServerSocket server = new ServerSocket(8848);
              System.out.println("服务端已启动");
              Socket socket = server.accept();
              InputStream is = socket.getInputStream();
              BufferedReader br = new BufferedReader(new InputStreamReader(is));
              String msg;
              // 此处用while
              while ((msg = br.readLine()) != null){
                  System.out.println("服务端收到：【 "+msg+" 】");
              }
  
          } catch (IOException e) {
              throw new RuntimeException(e);
          }
      }
  }
  ```

- Client

  ```java
  public class Client {
      public static void main(String[] args) throws IOException {
          Socket socket = new Socket("127.0.0.1", 8848);
          OutputStream outputStream = socket.getOutputStream();
          PrintStream ps = new PrintStream(outputStream);
          Scanner scanner = new Scanner(System.in);
          while (true) {
              System.out.print("请说：");
              ps.println(scanner.next());
              ps.flush();
          }
      }
  }
  ```



### 接收多个客户端

- Server：多线程

  ```java
  public class Server {
      public static void main(String[] args) {
          try {
              ServerSocket server = new ServerSocket(8848);
              System.out.println("服务端已启动");
              while (true){
                  Socket socket = server.accept();
                  // 开启线程
                  new Thread(() -> {
                      try {
                          InputStream is = socket.getInputStream();
                          BufferedReader br = new BufferedReader(new InputStreamReader(is));
                          String msg;
                          while ((msg = br.readLine()) != null){
                              System.out.println("服务端收到"+Thread.currentThread()+"的消息：【 "+msg+" 】");
                          }
                      }catch (IOException e) {
                          throw new RuntimeException(e);
                      }
                  }).start();
              }
          } catch (IOException e) {
              throw new RuntimeException(e);
          }
      }
  }
  ```

- Client



### 伪异步

- Server：线程池

- Client



### 文件传输

- Server

  ```java
  public class Server {
      public static void main(String[] args) {
          try {
              ServerSocket server = new ServerSocket(8848);
              Socket socket = server.accept();
              DataInputStream dis = new DataInputStream(socket.getInputStream());
              String suffix = dis.readUTF();
              System.out.println(suffix);
              // 读取文件 ...
  
          }catch (Exception e){
              e.printStackTrace();
          }
      }
  }
  ```

- Client

  ```java
  public class Client {
      public static void main(String[] args) {
          File file = new File("D:\\picture\\4823e7c.31a80e298383812fe498b567.png");
          String fileName = file.getName();
          String[] split = fileName.split("\\.");
  
          try(InputStream is = new FileInputStream(file);) {
              Socket socket = new Socket("127.0.0.1", 8848);
              DataOutputStream dos = new DataOutputStream(socket.getOutputStream());
              dos.writeUTF(split[split.length-1]);
              byte[] buffer = new byte[1024];
              int len;
              while ((len = is.read(buffer)) != -1){
                  dos.write(buffer, 0, len);
              }
              dos.flush();
              dos.close();
              // 及时关闭通道
              socket.shutdownOutput();
          }catch (Exception e){
              e.printStackTrace();
          }
      }
  }
  ```

  

### 端口转发

- Server

  ```java
  public class Server {
      // 定义一个静态集合，用来存储在线的socket
      private static List<Socket> socketsOnline = new ArrayList<>();
  
      public static void main(String[] args) {
          try {
              ServerSocket server = new ServerSocket(8848);
              System.out.println("服务器启动");
              while (true){
                  Socket socket = server.accept();
                  Server.socketsOnline.add(socket);
                  new Thread(() -> {
                      try {
                          BufferedReader br = new BufferedReader(new InputStreamReader(socket.getInputStream()));
                          String msg;
                          while ((msg = br.readLine()) != null){
                              // 服务端接收到客户端的消息后，推送给所有在线的客户端
                              for (Socket socketOnline : Server.socketsOnline) {
                                  PrintStream printStream = new PrintStream(socket.getOutputStream());
                                  printStream.println(msg);
                                  printStream.flush();
                              }
                          }
                      }catch (Exception e){
                          // 捕获到连接重置异常后表示有人下线
                          System.out.println(socket+" 客户端用户下线");
                          Server.socketsOnline.remove(socket);
                      }
                  }).start();
              }
  
          } catch (IOException e) {
              throw new RuntimeException(e);
          }
      }
  }
  ```

- Client





## NIO

### Buffer

#### 常用API

- 缓冲区操作

  - Buffer clear()：清空缓冲区，切换为写模式，并返回对缓冲区的引用
  - Buffer compact()：清空position指针前的数据，切换为写模式
  - Buffer flip()：将 limit 的位置设置到 position 上，并将 position 的位置改为0
  - int capacity()：返回 Buffer 的 capacity 大小
  - boolean hasRemaining()：判断缓冲区中是否还有元素
  - int limit()：返回 Buffer 的 limit 的位置
  - Buffer limit(int n)：设置 limit 为n，并返回对缓冲区的引用
  - Buffer mark()：对缓冲区设置标记
  - int position()：返回 position 的位置
  - Buffer position(int n)：设置 position 的位置，并返回对缓冲区的引用
  - int remaining()：返回 position 和 limit 间的元素个数
  - Buffer reset()：将位置 position 转到之前设置的 mark 位置上
  - Buffer rewind()：将 position 设置为0，取消之前的 mark
  
- 数据操作

  - byte get()：读取单个字节
  - ByteBuffer get(byte[] dst)：批量读取多个字节到 dst 中
  - byte get(int index)：读取指定索引位置的字节（不会移动position）
  - ByteBuffer put(byte b)：将单个字节写到 position 位置上
  - ByteBuffer put(byte[] src)：将src中的字节写入到 position 位置上
  - ByteBuffer put(int index, byte b)：将指定字节写入的索引位置上（不会移动position）
  
- 字符串和Buffer的相互转换

  - 字符串 -> ByteBuffer

    ```java
    byteBuffer.put("你好，世界！".getBytes(StandardCharsets.UTF_8));
    ByteBuffer buffer = StandardCharsets.UTF_8.encode("你好，世界");
    ByteBuffer buffer = ByteBuffer.wrap("你好，世界！".getBytes(StandardCharsets.UTF_8));
    ```

  - ByteBuffer -> 字符串

    ```java
    CharBuffer charBuffer = StandardCharsets.UTF_8.decode(buffer);
    String string = charBuffer.toString();
    ```

    





#### 直接内存缓冲区

- 非直接内存作用链
  - 本地IO -> 直接内存 -> 非直接内存 -> 直接内存 -> 本地IO
- 直接内存作用链
  - 本地IO -> 直接内存 -> 本地IO
- 直接内存效率更高，但申请慢，需要及时关闭
- API
  - 创建直接内存：Buffer.allocateDirect(int bytes);
  - 判断是否是直接内存：buffer.isDirect();





### Channel

#### 概述

- 类似于Stream流，但channel是双向的
- 用于在缓冲区和位于通道另一侧的实体间的数据传输
- 通道依赖于缓冲区，从而可以实现异步读写数据
- channel实现
  - FileChannel：从文件中读写数据
  - DatagramChannel：能通过UDP读写网络中的数据
  - SocketChannel：能通过TCP读写网络中的数据
  - ServerSocketChannel：可以监听新来的TCP连接，类似于web服务器，对每个新进来的连接都会创建一个SocketChannel
- 支持通道的类（调用getChannel()方法）
  - FileInputStream、FileOutputStream
  - RandomAccessFile
  - DatagramSocket
  - Socket、ServerSocket



#### 常用API

- FileChannel
  - int read(ByteBuffer dst)：从 channel 中读取数据到 ByteBuffer
  - long read(ByteBuffer[] dsts)：将 Channel 中的数据“分散”到 ByteBuffer[]中
  - int write(ByteBuffer src)：将 ByteBuffer 中的数据写入到 channel
  - long write(ByteBuffer[] srcs)：将 ByteBuffer[] 中的数据“聚集”到 channel
  - long positon()：返回此通道的文件位置
  - FileChannel position(long p)：设置此通道的文件位置
  - long size()：返回此通道的文件当前大小
  - FileChannel truncate(long s)：将此通道的文件截取为给定大小
  - void force(boolean metaData) ：强制将所有对此通道的文件更新写入到存储设备中
  - long transferFrom(ReadableChannel str, long position, long count)
  - long transferTo(long position, long, count, WritableByteChannel target)：拷贝channel中的数据，若数据超过 2g ，需要多次传输

- Path

  ```java
  Path path1 = Paths.get("d:/1.txt");
  Path path2 = Paths.get("d:\\data");
  
  // 支持 . 和 ..
  Path path3 = Paths.get("./../bbb/bbb.txt");
  Path normalize = path.normalize();
  ```

- Files

  ```java
  // 检查文件是否存在
  Files.exists(path);
  
  // 创建一级目录，若目录已存在，或是多级目录，都会报错
  Files.createDirectory(path);
  // 创建多级目录
  Files.createDirectorys(path);
  
  // 拷贝文件
  Files.copy(sourcePath, targetPath); // 若文件已存在，报异常
  Files.copy(sourcePath, targetPath, StandardCopyOption.REPLACE_EXISTING); // 覆盖
  
  // 移动文件
  Files.move(sourcePath, targetPath, StandardCopyOption.ATOMIC_MOVE); // 保证文件移动时的原子性
  
  // 删除文件
  Files.delete(targetPath); // 文件不存在，会报错；如果文件为目录，若目录中还有内容，也会报错
  ```

  ```java
  // 遍历目录
  Files.walkFileTree(path, new FileVisitor<Path>() {
      @Override
      public FileVisitResult preVisitDirectory(Path dir, BasicFileAttributes attrs) throws IOException {
          return null;
      }
  
      @Override
      public FileVisitResult visitFile(Path file, BasicFileAttributes attrs) throws IOException {
          return null;
      }
  
      @Override
      public FileVisitResult visitFileFailed(Path file, IOException exc) throws IOException {
          return null;
      }
  
      @Override
      public FileVisitResult postVisitDirectory(Path dir, IOException exc) throws IOException {
          return null;
      }
  });
  ```





### Selector

#### 概述

- Selector 是 SelectableChannle 对象的多路复用器，Selector 可以同时监听控制多个 SelectableChannel 的 IO 事件
- Selector 是非阻塞 IO 的核心
- 不必为每个连接都创建一个线程，避免了多线程间上下文切换导致的开销





### 网络通信

#### 服务端流程

- 创建服务器

  ```java
  ServerSocketChannel sschannel = ServerSocketChannel.open();
  ```

- 切换非阻塞模式（在注册选择器前设置阻塞模式）

  ```java
  sschannel.configureBlocking(false);
  ```

- 绑定监听端口

  ```java
  ssChannel.bind(new InetSocketAddress(8080));
  ```

- 获取连接器

  ```java
  Selector selector = Selector.open();
  ```

- 将通道注册到选择器上，并且指定“监听接收事件”

  ```java
  SelectionKey sscKey = sschannel.register(selector, SelectionKey.OP_ACCEPT);
  ```

  - 监听接收事件
    - 读：SelectionKey.OP_READ（1）
    - 写：SelectionKey.OP_WRITE（4）
    - 连接：SelectionKey.OP_CONNECT（8）
    - 接收：SelectionKey.OP_ACCEPT（16）
    - 多个事件可用 "|" 来连接

- 轮询式获取选择器上已经“准备就绪”的事件

  ```java
  ByteBuffer byteBuffer = ByteBuffer.allocate(1024);
  while (selector.select() > 0) {
      Iterator<SelectionKey> iterator = selector.selectedKeys().iterator();
      while (iterator.hasNext()) {
          SelectionKey selectionKey = iterator.next();
          if (selectionKey.isAcceptable()) {
              SocketChannel socketChannel = ssc.accept();
              log.info("接收到连接请求，socketChannel：{}", socketChannel);
              // 客户端channel设置为非阻塞后，read方法将不再阻塞，如果没读到数据，将返回0
              socketChannel.configureBlocking(false);
              socketChannel.register(selector, SelectionKey.OP_READ);
          }else if (selectionKey.isReadable()) {
              try {
                  SocketChannel socketChannel = (SocketChannel) selectionKey.channel();
                  int len = 0;
                  while((len = socketChannel.read(byteBuffer)) > 0){
                      byteBuffer.flip();
                      String string = StandardCharsets.UTF_8.decode(byteBuffer).toString();
                      // 此处可能产生消息边界问题
                      log.info("处理收到的数据【{}】", string);
                      byteBuffer.clear();
                  }
                  if (len == -1) {
                      log.info("客户端关闭");
                      selectionKey.cancel();
                  }
              }catch (IOException e) {
                  log.warn(e.getMessage());
                  selectionKey.cancel();
              }
          }
          // 如果不移出，下一次迭代器遍历时，该key仍保留在集合中，可能导致空指针异常
          iterator.remove();
      }
  }
  ```

- 消息边界问题处理方案（半包、黏包）

  - 服务器和客户端约定最大传输长度，接收端根据长度划分ByteBuffer空间

  - 将传输的数据按分隔符进行拆分

    - 缺点：效率低

    - 问题：

      > 若存在一段无法拆分且数据量大的数据，接收端无法通过一次read读取完，此时会触发两次或多次读取事件。

      > 若大文件在触发第一次读事件时扩容，则需要将 ByteBuffer 对象提出处理区域，供每次处理时调用，才能允许内部数据不被清除；但若简单从作用域中提出，则可能导致不同的处理事件共享包含残留数据的 ByteBuffer 对象，从而导致数据混乱

      > 简单解决：利用附件，可为每一个 SelectionKey 对象（每个事件）绑定一个 ByteBuffer 对象作为附件。这样，同一事件使用的是相同的 ByteBuffer 对象，不同事件也不会混用该对象

      ```java
      SelectionKey key = oneChannel.register(选择器, 事件类型, byteBuffer(附件));
      ```

      ```java
      // 获取附件
      ByteBuffer byteBuffer = (ByteBuffer) key.attachment();
      ```

      ```java
      // 先进行拆分，拆分后，存在某段数据仍大于接收的byteBuffer容量，再扩容
      if (byteBuffer.position() == byteBuffer.limit()) {
          ByteBuffer newBuffer = ByteBuffer.allocate(bytebuffer.capacity()*2);
          byteBuffer.flip();
          newBuffer.put(byteBuffer);
          key.attach(newBuffer);
      }
      ```

      



#### 客户端流程

- 获取通道

  ```java
  SocketChannel sChannel = SocketChannel.open(new InetSocketAddress("127.0.0.1",8080));
  ```

- 切换非阻塞模式

  ```java
  sChannel.configureBlocking(false);
  ```

- 分配指定大小的缓冲区

  ```java
  ByteBuffer buf = ByteBuffer.allocate(1024);
  ```

- 发送数据给服务端

  ```java
  Scanner scanner = new Scanner(System.in);
  while(scanner.hasNext()){
      System.out.println("请输入：");
      String str = scanner.nextLine();
      buf.put((new SimpleDateFormat("yyyy/MM/dd HH:mm:ss").format(System.currentTimeMillis())+"/n"+str).getBytes());
      buf.flip();
      sChannel.write(buf);
      buf.clear();
  }
  ```





## Netty

### 快速入门

- 引入依赖

  ```xml
  <dependency>
      <groupId>io.netty</groupId>
      <artifactId>netty-all</artifactId>
      <version>4.1.95.Final</version>
  </dependency>
  ```

- Server

  ```java
  // 启动器，负责组装 netty 组件，启动服务器
  new ServerBootstrap()
      // BossEventLoop, WorkerEventLoop(selector, thread), group 组
      .group(new NioEventLoopGroup())
      // 选择服务器的 ServerSocketChannel 实现
      .channel(NioServerSocketChannel.class)
      // boss 负责处理连接; worker(child) 负责处理读写
      // handler 规定了 worker(child) 执行的操作
      .childHandler(
      // 是一个用来初始化的 handler，负责添加别的 handler
      new ChannelInitializer<NioSocketChannel>() {
          @Override
          protected void initChannel(NioSocketChannel nsc) throws Exception {
              // 添加具体的 handler
              // 将 ByteBuf 转换为字符串
              nsc.pipeline().addLast(new StringDecoder());
              // 自定义 handler
              nsc.pipeline().addLast(new ChannelInboundHandlerAdapter() {
                  @Override
                  // 读事件处理方案
                  public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception {
                      // 打印上一步转换好的字符串
                      log.info("接收到信息：【{}】", msg);
                  }
              });
          }
      })
      .bind(8080);
  ```

- Client

  ```java
  new Bootstrap()
      // 添加 EventLoop
      .group(new NioEventLoopGroup())
      // 选择客户端 channel 实现
      .channel(NioSocketChannel.class)
      // 添加处理器
      .handler(new ChannelInitializer<NioSocketChannel>() {
          @Override
          protected void initChannel(NioSocketChannel nioSocketChannel) throws Exception {
              nioSocketChannel.pipeline().addLast(new StringEncoder());
          }
      })
      // 异步非阻塞，main 线程调用该方法，但实际执行 连接操作 的是 EventLoopGroup 中的线程
      .connect(new InetSocketAddress("localhost", 8080))
      // main 线程阻塞，直到其他线程建立完连接
      .sync()
      .channel()
      .writeAndFlush("你好，世界！");
  ```
  
  

### 组件

#### EventLoop

> EventLoop 本质是一个单线程线程池（同时维护了一个 Selector），里面有 run 方法处理 Channel 上源源不断的 io 事件

> 它的继承关系比较复杂
>
> > 一条是继承自 J.U.C.ScheduledExecutorService，因此可执行定时任务
>
> > 另一条是继承自 netty 自己的 OrderedEventExecutor

- 创建 EventLoopGroup

  ```java
  // 可处理 io事件，普通任务，定时任务
  // 若不指定创建的 EventLoop 数，默认创建 核心数*2 个
  EventLoopGroup group = new NioEventLoopGroup(2);
  
  // 可处理 普通任务，定时任务
  EventLoopGroup group = new DefaultEventLoopGroup();
  ```

- 获取下一个 EventLoop

  ```java
  // 若指定 group 为2个 EventLoop
  EventLoop eventLoop1 = group.next();
  EventLoop eventLoop2 = group.next();
  EventLoop eventLoop3 = group.next();
  log.info("是否为同一个对象：{}", eventLoop1 == eventLoop3); // true
  ```

- 执行任务

  - 普通任务

    > group.next().submit(Runnable task)

    > group.next().execute(Runnable task)

  - 定时任务

    > group.next().scheduleAtFixedRate(Runnable task, int initialDelay, int period, TimeUnit unit)

  - IO任务

    ```java
    new ServerBootstrap()
        .group(new NioEventLoopGroup())
        .channel(NioServerSocketChannel.class)
        .childHandler(
        new ChannelInitializer<NioSocketChannel>() {
            @Override
            protected void initChannel(NioSocketChannel nsc) throws Exception {
                // 自定义 handler
                nsc.pipeline().addLast(new ChannelInboundHandlerAdapter() {
                    @Override
                    // 读事件处理方案
                    public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception {
                        // 处理IO任务
                        ByteBuf byteBuf = (ByteBuf) msg;
                        String str = byteBuf.toString(StandardCharsets.UTF_8);
                        log.info("收到的信息：【{}】", str);
                    }
                });
            }
        })
        .bind(8080);
    ```

- eventLoop 分工细化

  - 细分1：职责划分

    > boss 只负责 ServerSocketChannel 上的 accept 事件

    > worker 只负责 SocketChannel 上的 读写 事件

    ```java
    new ServerBootstrap()
        // 指定 boss 和 worker 各自的 group
        .group(new NioEventLoopGroup(1), new NioEventLoopGroup())
        . ...
    ```

  - 细分2：创建一个独立的 EventLoopGroup 用来处理一些耗时操作

    ```java
    // 创建一个独立的 group
    EventLoopGroup group = new DefaultEventLoopGroup(2);
    
    new ServerBootstrap()
        .group(new NioEventLoopGroup(), new NioEventLoopGroup(2))
        .channel(NioServerSocketChannel.class)
        .childHandler(
        new ChannelInitializer<NioSocketChannel>() {
            @Override
            protected void initChannel(NioSocketChannel nsc) throws Exception {
                // 自定义 handler1
                nsc.pipeline().addLast("handler1", new ChannelInboundHandlerAdapter() {
                    @Override
                    public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception {
                        ByteBuf byteBuf = (ByteBuf) msg;
                        String str = byteBuf.toString(StandardCharsets.UTF_8);
                        log.info("收到的信息：【{}】", str);
                        // 再将消息传递给下一个 handler 进行处理
                        ctx.fireChannelRead(msg);
                    }
                });
                
                // 该 handler 所指定的任务，交由独立出的 group 里的线程进行处理
                nsc.pipeline().addLast(group, "handler2", new ChannelInboundHandlerAdapter() {
                    @Override
                    public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception {
                        log.info("处理一些耗时操作");
                    }
                });
            }
        })
        .bind(8080);
    ```

  



#### Channel

- 常用方法

  - close()：关闭 channel
  - pipeline()：添加处理器
  - write()：将数据写入
  - writeAndFlush()：将数据写入并刷出
  - closeFuture()：获得 CloseFuture 对象

- ChannelFuture

  ```java
  ChannelFuture channelFuture = new Bootstrap()
                  .group(...)
                  .channel(...)
                  .handler(...)
      // 异步非阻塞，main 线程调用 connect()，但实际执行 连接操作 的是 EventLoopGroup 中的线程
                  .connect(...);
  ```

  - sync()：作用是同步等待连接完成

    ```java
    // 异步转同步。main线程阻塞，等待其他线程建立完连接
    ChannelFuture channelFuture = channelFuture.sync();
    
    // main 线程阻塞结束后，开启通道，传递数据
    Channel channel = channelFuture1.channel();
    channel.writeAndFlush("你好，世界！");
    ```

  - addListener()：是异步等待连接完成

    ```java
    // mian 线程不阻塞，由其他线程建立完连接后开启通道，传递数据
    channelFuture.addListener(new ChannelFutureListener() {
        @Override
        public void operationComplete(ChannelFuture channelFuture) throws Exception {
            Channel channel = channelFuture.channel();
            channel.writeAndFlush("你好，世界！");
        }
    });
    ```

- closeFuture()：用来处理 channel 的关闭

  ```java
  ChannelFuture closeFuture = channel.closeFuture();
  // channel 的关闭也是一个异步操作，由 main 线程调用，由其他线程真正执行关闭
  channel.close();
  ```

  - sync()：作用是同步等待 channel 关闭

    ```java
    // 异步转同步
    closeFuture.sync();
    log.info("执行后续操作");
    ```

  - addListener()：是异步等待 channel 关闭

    ```java
    closeFuture.addListener(new ChannelFutureListener() {
        @Override
        public void operationComplete(ChannelFuture channelFuture) throws Exception {
            log.info("执行后续操作");
        }
    });
    ```

- 完全停止客户端

  > channel 真正关闭后，客户端程序仍无法停止，原因是 EventLoopGroup 中仍有线程在执行，可调用 EventLoopGroup 对象的 shutdownGracefully() 方法优雅停止线程（拒绝新任务，执行完已有任务）





#### Future Promise

> netty Future 继承 jdk Future

> netty Promise 继承 netty Future

-  jdk Future
  - cancel()：取消任务
  - isCanceled()：任务是否取消
  - isDone()：任务是否完成，不能区分成功失败
  - get()：获取任务结果，阻塞等待
- netty Future
  - getNow()：获取任务结果，若还未产生，返回null
  - sync()：等待任务结束，如果任务失败，抛出异常
  - await()：等待任务结束，如果任务失败，不会抛出异常，而通过 isSuccess() 判断
  - isSuccess()：判断任务是否成功
  - cause()：获取失败信息，非阻塞，如果尚未失败，返回null
  - addLinstener()：添加回调
- netty Promise\<T>：一个存放结果的容器
  - setSuccess(T t)：设置成功结果
  - setFailure(Throwable cause)：设置失败结果





#### Handler

> ChannelHandler 用来处理 Channel 上的各种事件，分为入站、出站两种。所有 ChannelHandler 被连成一串，就是 Pipeline

> 入站Handler 通常是 ChannelInboundHandlerAdapter 的子类，主要用来读取客户端数据，写回结果

> 出站Handler 通常是 ChannelOutBoundhandlerAdapter 的子类，主要对写回结果进行加工

```java
new ServerBootstrap()
    .group(...)
    .channel(...)
    .childHandler(
    new ChannelInitializer<NioSocketChannel>() {
        @Override
        protected void initChannel(NioSocketChannel nsChannel) throws Exception {
            // 获得 pipeline
            ChannelPipeline pipeline = nsChannel.pipeline();
            
            // 添加处理器
            // 处理顺序（双向链表）：head <=> h1 <=> h2 <=> h3 <=> h4 <=> tail
            // 入站顺序：head -> handler1 -> handler2 -> tail
            // 出站顺序：tail -> handler4 -> handler3 -> head
            pipeline.addLast("handler1", new ChannelInboundHandlerAdapter() {
                @Override
                public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception {
                    // 使用pipeline的channel会从tail处理器向前找出站处理器进行处理
                    nsChannel.writeAndFlush(...);
                    // 使用handler的channel会从当前处理器向前找出站处理器进行处理
                    ctx.writeAndFlush(...);
                    
                    // 再将消息传递给下一个 handler 进行处理
                    ctx.fireChannelRead(msg); // super.channelRead(ctx, msg);
                }
            });
            pipeline.addLast("handler2", 入站handler2);
            pipeline.addLast("handler3", 出站handler3);
            pipeline.addLast("handler4", 出站handler4);
        }
    })
    .bind(...);
```

- 基础 Handler

  - 通用处理器：ChannelInboundHandlerAdapter

  - 专注处理器：SimpleChannelInboundHandler\<ByteBuf>

    > Object msg 的实际类型是 ByteBuf 的，会进入该处理器

  - 日志处理器：new LoggingHandler(LogLevel.INFO)



#### ByteBuf

- 创建

  ```java
  // 创建直接内存ByteBuf，若不指定容量，默认为256
  ByteBuf buffer = ByteBufAllocator.DEFAULT.buffer();
  ByteBuf buffer = ByteBufAllocator.DEFAULT.buffer(int capacity);
  ByteBuf buffer = ByteBufAllocator.DEFAULT.buffer(int capacity, int maxCapacity);
  
  // 创建堆内存、直接内存ByteBuf，若不指定容量，默认为256
  ByteBuf byteBuf = ByteBufAllocator.DEFAULT.heapBuffer(int capacity);
  ByteBuf byteBuf = ByteBufAllocator.DEFAULT.directBuffer(int capacity);
  
  System.out.println(byteBuf.getClass());
  ```

  - 池化：可以重用 ByteBuf

  - 启停：

    - 使用代码：Unpooled.buffer();

    - 配置参数：-Dio.netty.allocator.type=unpolled/polled

    - 4.1 前，池化功能不成熟，默认是非池化

    - 4.2 后，非Android平台默认启用池化

- 指针

  - 读指针
  - 写指针

  > 读指针 到 写指针 间可读
  >
  > 写指针 到 剩余部分边界 可写

- 部分方法

  - readInt()：一次性读取4个字节，并转换为 int

  - writeBytes(byte[] src)：写入 byte[]

  - int writeCharSequence(CharSequence s, Charset charset)

    > CharSequence 是 String 的父类，写入字符串时需要指定字符集

- 扩容

  - ByteBuf 在容量不够时，会自动扩容

    - 如果写入后的数据大小未超过512，则会选择扩容到下一个16的整数倍，如写入后是17，若扩容，会扩容到32

    - 如果写入后的数据大小超过512，则会选择下一个2^n^

    - 扩容不能超过指定的 maxCapacity，否则会报错

- 释放

  - 释放原理

    - 每个 ByteBuf 对象的初始计数为 1
    - 调用 release 方法后计数减1，如果计数为0，ByteBuf内存被回收
    - 调用 retain 方法后计数加1，调用该方法后，其他线程调用 release 也不会造成回收
    - 当计数为 0 时，底层内存被回收，这时即使 ByteBuf 对象还在，各方法也无法正常使用

  - 释放时机

    - head handler 会在出站；tail hanler 会在入站时，对 ByteBuf 对象进行尝试释放处理

    - 但仍应该在最后一个使用ByteBuf对象的handler中进行释放处理

      > 如：head 和 tail 间若有 handler 将实际为ByteBuf的 Object msg 转变为了实际为String 的 Object msg后继续向下传递，该msg传递到终点处理器时会判断 <font color=red><strong>`msg instanceof ReferenceCounted`</strong></font>，若不是，终点处理器无法强转并释放

- slice()（切片）：零拷贝切片（切片和原始的ByteBuf共享同一块内存）

  ```java
  ByteBuf buffer = ByteBufAllocator.DEFAULT.buffer(6);
  buffer.writeBytes(new byte[]{'a', 'b', 'c', 'd', 'e', 'f'});
  
  // 在切片的过程中，并没有数据的复制
  ByteBuf slice1 = buffer.slice(0, 3);
  slice1.retain(); // 加的是 buffer 的 referenceCount
  ByteBuf slice2 = buffer.slice(0, 3);
  
  buffer.release();
  log.info("从切片1中读出一个字节，字节为：{}", (char) slice1.readByte());
  slice1.release(); // 减的是 buffer 的 referenceCount
  // 此时 buffer 的 referenceCount 已减为零，不能再调用 slice2.release();
  // slice2.release();
  ```

  - 切片后，将对切片进行容量限制

  - 原始ByteBuf对象 的 release 将对切片造成影响

    - 调用切片的 retain 方法。

      > 无论是调用 源ByteBuf 还是 切片 的release、retain方法，计算的都是 源ByteBuf 的引用计数

    - 将 切片 内存转化为非共享的内存

      ```java
      ByteBuf slice1 = buffer.slice(0, 3);
      ByteBuf byteBuf = ByteBufAllocator.DEFAULT.buffer().writeBytes(slice1);
      ```

- duplicate()：零拷贝复制（复制出的ByteBuf与原始的ByteBuf完全共用一块内存，没有容量限制）

- copy()：深拷贝（数据复制）





#### Option

- 配置参数

  - 客户端

    ```java
    new ServerBootstrap()
        // 给 ServerSocketChannel 配置参数
        .option()
        // 给 SocketChannel 配置参数
        .childOption()
        . ...
    ```

  - 服务器端

    ```java
    new ServerBootstrap()
        .option()
        . ...
    ```

- 常用参数（ChannelOption.参数名）

  - CONNECT_TIMEOUT_MILLIS
    - 属于 SocketChannal 参数
    - 客户端在建立连接时，若在指定毫秒内无法连接，会抛出 timeout 异常
    - SO_TIMEOUT 主要用在阻塞IO中，阻塞IO的accept、read都是无限等待的，如果不希望永远阻塞，可配置此超时时间
    - 原理：利用线程池定时任务，延期 timeout 执行导致抛出超时异常的任务，若连接上，取消该任务
      - 实际上客户端调用 sync() 方法后，阻塞等待promise结果；
      - 到达超时时间时，在定时任务中向 promise 添加timeout异常结果，sync() 阻塞结束
  - SO_BACKLOG
    - 属于 ServerSocketChannel 参数
    - tcp 3次交互：为了让自己和对方都意识到自己的接收和发送都没问题
      - 半连接队列：尚为完成3次交互的会记录在半连接队列中
        - 上限通过 linux 目录 /proc/sys/net/ipv4/tcp_max_syn_backlog 指定，在 syncookies 启用的情况下，逻辑上没有最大值限制
      - 全连接队列：成功建立连接的会记录在全连接队列中，如果队列满了，server 将发送Connection refused拒绝连接的错误信息到 client
        - 操作系统层限制：上限通过 linux 目录 /proc/sys/net/core/somaxconn 指定
        - 代码层限制：
          - NIO：bind(port: 8080, backlog: 4069)
          - Netty：配置 SO_BACKLOG
  - TCP_NODELAY：默认关闭不延迟，即开启nagle
    - 属于 SocketChannel 参数
    - nagle 算法
      - 将多个小数据合并为一个大数据，再一起发送
      - 会导致数据延迟发送

  











### 协议

#### 黏包半包

- 黏包

  - 现象：分别发送abc、def，接收到的却是 abcdef

  - 原因
    - 应用层：接收方的 ByteBuf 设置太大
    - 滑动窗口：假设发送方 256 bytes表示一个完整的报文，但由于接收方处理不及时，且窗口大小足够大，这 256bytes 字节就会缓冲在接收方的滑动窗口中，当滑动窗口中缓冲了多个报文就会黏包
    - Nagle算法

- 半包

  - 现象：发送 abcdef ，接收到的是 abc、def
  - 原因
    - 应用层：接收放 ByteBuf 小于实际发送数据量
    - 滑动窗口：接收方窗口只剩 128b ，发送方发送超过 129b 数据，会先发送 128b ，再发送 1b，造成半包
    - MSS限制：Maximum Segment Size，最大报文长度，TCP payload的最大值，TCP协议定义的一个选项，MSS是TCP用来限制应用层最大的发送字节数

- 解决方式

  - 短链接法

    - 客户端若要发送多次消息时，发送一次消息后与服务器断开连接，再建立连接，再发送下一条消息
    - 服务段接收到客户端断开连接后，不会将本次消息与下一次重新连接的客户端发送消息进行粘接

  - 添加 定长消息解码器 FixedLengthFrameDecoder

    - 客户端发送固定长度的消息，不足该长度的，补齐

    - 服务端添加 定长消息解码器

      ```java
      ch.pipeline().addLast(new FixedLengthFrameDecoder(fixedLength: 10));
      ```

  - 分隔符

    - LineBasedFrameDecoder：能解析到 windows 和 linux 的换行符，并作为分隔条件

      > 需要指定一个 maxLength ，若解析消息时，超过该长度，仍未解析到换行符，则报 TooLongFrameException

      - 客户端在发送多条消息后，在每一条消息后加入换行符 '\n' or '\r\n'

      - 服务端添加 解码器

        ```
        ch.pipeline().addLast(new FixedLengthFrameDecoder(maxLength: 1024));
        ```

    - DelimiterBasedFrameDecoder：指定分隔符

  - LengthFieldBaseFrameDecoder

    - 构造方法参数
      - maxFrameLength：最大总长度，单次信息超出该长度报错
      - lengthFieldOffset：长度部分第一个字节位置
      - lengthFieldLength：长度部分的长度
      - lengthAdjustment：长度调节，长度部分后多少个字节才到真正的内容
      - initialBytesToStrip：解析内容时，跳过开头后面多少个字节

    ```java
    // 嵌入式Channel，可用来模拟处理器链处理过程
    EmbeddedChannel channel = new EmbeddedChannel(
        // 若不想解析长度和版本号，initialBytesToStrip 设置为 4+4=8
        new LengthFieldBasedFrameDecoder(1024, 0, 4, 4, 8),
        new ChannelInboundHandlerAdapter() {
            @Override
            public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception {
                if (msg instanceof ByteBuf) {
                    ByteBuf byteBuf = (ByteBuf) msg;
                    log.info("收到的信息是：【{}】", byteBuf.readCharSequence(byteBuf.readableBytes(), StandardCharsets.UTF_8));
                }
                // 若每次接收到的都是新划分的ByteBuf，需要释放
                if (msg instanceof ReferenceCounted)
                    ((ReferenceCounted) msg).release();
            }
        }
    );
    
    AtomicInteger stamp = new AtomicInteger(1);
    Consumer<String> send = (String s) -> {
        ByteBuf byteBuf = ByteBufAllocator.DEFAULT.directBuffer();
        byte[] bytes = s.getBytes(StandardCharsets.UTF_8);
        // 一个Int占四个字节，所以 lengthFieldLength 为4
        byteBuf.writeInt(bytes.length);
        // 模拟在长度部分后，添加一个 Int 的版本。lengthAdjustment 设为4
        byteBuf.writeInt(stamp.getAndIncrement());
        byteBuf.writeBytes(bytes);
        channel.writeInbound(byteBuf);
    };
    
    send.accept("Hello, world!");
    send.accept("你好，世界！");
    ```
    





#### 自定义协议

- 常见协议

  - Redis 协议：以 SET name zhangsan 为例

    ```aof
    *3
    $3
    SET
    $4
    name
    $8
    zhangsan
    ```

  - Http 协议

    ```java
    // Http协议的处理器。HttpServerCodec：HttpRequestDecoder + HttpResponseEncoder
    pipeline.addLast(new HttpServerCodec());
    pipeline.addLast(new ChannelInboundHandlerAdapter() {
        @Override
        public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception {
            log.info("类型为：{}", msg.getClass());
            if (msg instanceof HttpRequest) {
                DefaultFullHttpResponse httpResponse =
                    new DefaultFullHttpResponse(HttpVersion.HTTP_1_0, HttpResponseStatus.OK);
                byte[] bytes = "<h1>Hello!<h1>".getBytes(StandardCharsets.UTF_8);
                httpResponse.headers().setInt(HttpHeaderNames.CONTENT_LENGTH, bytes.length);
                httpResponse.content().writeBytes(bytes);
                nioSocketChannel.writeAndFlush(httpResponse);
            }
            if (msg instanceof LastHttpContent) log.info("LastHttpContent");
            super.channelRead(ctx, msg);
        }
    });
    ```

- <a href="https://www.bilibili.com/video/BV1py4y1E7oA?p=101&vd_source=25ad2de4838bd28372a4956bac63c618">自定义协议</a>

  - 组成部分

    - 魔数：用来第一时间判断是否为无效数据包
    - 版本号：可以支持协议的升级
    - 序列化算法：支持正文到底采用哪种序列化反序列化方式，如json
    - 请求类型：是登录、注册、...
    - 请求序号：用于双工通信下，确定多个请求的顺序
    - 正文长度
    - 正文

  - 消息

    ```java
    @Data
    public abstract class MyMessage implements Serializable {
        private int messageType;
        priavte int sequenceId;
        
        // 定义子类的一些细分类型，供子类返回
        public static final int LoginRequestMessage = 0;
        public static final int LoginResponseMessage = 1;
        public static final int ChatRequestMessage = 3;
        public static final int ChatResponseMessage = 4;
        
        // 子类实现该方法，并返回自己的类型
        public abstract int getMessageType();
        
        private static final Map<Integer, Class<?>> messageClasses = new HashMap<>();
        
        static {
            messageClasses.put(LoginRequestMessage, LoginRequestMessage.class);
            messageClasses.put(LoginResponseMessage, LoginResponseMessage.class);
            ......
        }
        
        public static Class<?> getMessageClass(int messageType) {
            return messageClasses.get(messageType);
        }
    }
    ```
  
  - 处理器编码
  
    ```java
    @Sharable
    public class MyProtocolCodec extends ByteToMessageCodec<MyMessage> {
        @Override
        protected void encode(ChannelHandlerContext chc, MyMessage msg, ByteBuf byteBuf) throws Exception {
            // 将 魔数、版本号。。。msg 写入到 ByteBuf 中
        }
    
        @Override
        protected void decode(ChannelHandlerContext chc, ByteBuf byteBuf, List<Object> list) throws Exception {
            // 将 ByteBuf 转为 魔数、版本号。。。msg
        }
    }
    ```
    
    - @ Sharable 注解：添加在类上，表示该处理器可以被共享
      - LoggingHandler：没有记录状态信息，可以被共享
      - LengthFieldBasedFrameDecoder：由于记录了半包数据等状态信息，不能被多线程共享
    
  - 拓展序列化算法
  
    ```java
    public interface Serializer {
        <T> byte[] serialize(T t);
    
        <T> T deserialize(Class<T> clazz, byte[] bytes);
    
        enum Algorithm implements Serializer{
            JDK {
                @Override
                public <T> byte[] serialize(T t) {
                    return new byte[0];
                }
    
                @Override
                public <T> T deserialize(Class<T> clazz, byte[] bytes) {
                    return null;
                }
            },
            JSON {
                ......
            }
        }
    }
    ```





#### RPC

- RpcRequestMessage

  ```java
  @Getter
  public class RpcRequestMessage extends MyMessage {
      // 调用的接口全限定名，服务端根据它找到实现
      private String interfaceName;
      // 调用接口中的方法名
      private String methodName;
      // 方法返回类型
      private Class<?> returnType;
      // 方法参数类型数组
      private Class[] parameterTypes;
      // 方法参数值数值
      private Object[] parameterValue;
      
      public RpcRequestMessage(...){...}
      
      @Override
      public int getMessageType() {
          return RPC_MESSAGE_TYPE_REQUEST;
      }
  }
  ```









# JUC



## 常用API

### Thread

| 方法名                 | 说明                                                         |
| ---------------------- | ------------------------------------------------------------ |
| start()                | 启动一个新线程                                               |
| run()                  | 启动新线程后，新线程调用的方法                               |
| join()                 | 调用该方法的线程等待该方法所属线程运行结束                   |
| join(long n)           | 最多等待 n 毫秒                                              |
| getId()                | 获得线程 long 型的唯一id                                     |
| getName()              | 获取线程名                                                   |
| setName(String)        | 修改线程名                                                   |
| getPriority()          | 获取线程优先级                                               |
| setPriority(int)       | 修改线程优先级                                               |
| getState()             | 获取线程状态：new runnable blocked waiting timed_waiting treminated |
| setDaemon              | 是否将所属线程设置为守护线程                                 |
| isAlive()              | 线程是否存活                                                 |
| interrupt()            | 打断所属线程，如果被打断线程正在 sleep、wait、join 会导致被打断的<br/>线程抛出InterruptedException ，并清除打断标记；如果被打断的线程<br/>正在运行，则会为被打断的线程设置打断标记，不会直接打断线程 |
| isInterrupted()        | 获取所属线程是否被设置打断标记，获取后不会清除打断标记       |
| static interrupted()   | 获取调用线程是否被设置打断标记，获取后会清除打断标记         |
| static currentThread() | 获取当前正在运行的线程                                       |
| static sleep(long n)   | 休眠 n 毫秒，休眠期间让出CPU资源                             |
| static yield()         | 提示线程调度器让出调用线程对CPU的使用                        |

- 两阶段终止模式

  ```java
  @Slf4j
  public class InterruptTest {
      public static void main(String[] args) throws InterruptedException {
          Thread thread = new Thread(() -> {
              while (true) {
                  if (Thread.interrupted()) {
                      log.info("释放资源、锁等");
                      break;
                  }
                  log.info("执行循环任务");
                  try {
                      Thread.sleep(2000);
                  } catch (InterruptedException e) {
                      log.warn("休眠期间被打断");
                      Thread.currentThread().interrupt();
                  }
              }
          });
          thread.start();
          Thread.sleep(5000);
          thread.interrupt();
      }
  }
  ```





### Stack

| 常用方法             | 作用                                     |
| -------------------- | ---------------------------------------- |
| boolean empty()      | 判断栈是否为空                           |
| E peek()             | 返回栈顶部的对象，但不从栈中移出         |
| E pop()              | 返回栈顶部的对象，并从栈中移出           |
| E push(E item)       | 把对象压入栈中                           |
| int search(Object o) | 返回对象在堆栈中的位置，若不存在则返回-1 |



### Queue

| 常用方法           | 作用                                                 |
| ------------------ | ---------------------------------------------------- |
| boolean add(E e)   | 在队列尾部插入一个元素，若队列已满，抛出异常         |
| boolean offer(E e) | 在队列尾部插入一个元素，若队列已满，只返回false      |
| E element()        | 返回队列头部的对象，但不从队列中移出，若空，抛异常   |
| E peek()           | 返回队列头部的对象，但不从队列中移出，若空，返回null |
| E remove()         | 返回队列头部的对象，并从队列中移出，若空，抛异常     |
| E poll()           | 返回队列头部的对象，并从队列中移出，若空，返回null   |



### BlockingQueue

- 放入数据

  - offer(anObject):表示如果可能的话,将anObject加到BlockingQueue里,即如果BlockingQueue可以容纳,则返回true,否则返回false.（本方法不阻塞当前执行方法的线程）；　　　　　　 

  - offer(E o, long timeout, TimeUnit unit)：可以设定等待的时间，如果在指定的时间内，还不能往队列中加入BlockingQueue，则返回失败。

  - put(anObject):把anObject加到BlockingQueue里,如果BlockQueue没有空间,则调用此方法的线程被阻断直到BlockingQueue里面有空间再继续.

- 获取数据

  - poll(time):取走BlockingQueue里排在首位的对象,若不能立即取出,则可以等time参数规定的时间,取不到时返回null;
  - poll(long timeout, TimeUnit unit)：从BlockingQueue取出一个队首的对象，如果在指定时间内，队列一旦有数据可取，则立即返回队列中的数据。否则知道时间超时还没有数据可取，返回失败。
  - take():取走BlockingQueue里排在首位的对象,若BlockingQueue为空,阻断进入等待状态直到BlockingQueue有新的数据被加入; 
  - drainTo():一次性从BlockingQueue获取所有可用的数据对象（还可以指定获取数据的个数），通过该方法，可以提升获取数据效率；不需要多次分批加锁或释放锁。



### CompletableFuture

- 四种静态方法

  ```java
  // 默认使用 ForkJoin 线程池，ForkJoin 线程池创建的线程是守护线程
  CompletableFuture<Void> static runAsync(Runnable r)
  CompletableFuture<T> static supplyAsync(supplier<T> s)
  
  CompletableFuture<Void> static runAsync(Runnable r, Executor e)
  CompletableFuture<T> static supplyAsync(supplier<T> s, Executor e)
  ```

- 异步调用

  ```java
  completableFuture.get();
  completableFuture
      // 无论是否报错，获得结果后都会进入这个分支
      .whenComplete((t, throwable) -> {
          log.info(t.toString());
      })
      // 报错后还会进入这个分支
      .exceptionally(throwable -> {
          throwable.printStackTrace();
          return t;
      });
  ```



### Cyclicbarrier

```java
AtomicInteger times = new AtomicInteger(1);
CyclicBarrier cyclicBarrier = new CyclicBarrier(2, () -> {
    log.info("第 {} 轮执行完毕", times.getAndIncrement());
});
Runnable r = () -> {
    try {
        int costTime = new Random().nextInt(3);
        TimeUnit.SECONDS.sleep(costTime);
        log.info("执行结束，耗时：{} 秒", costTime);
        cyclicBarrier.await();
    } catch (InterruptedException | BrokenBarrierException e) {
        throw new RuntimeException(e);
    }
};
ExecutorService threadPool = Executors.newFixedThreadPool(2);
for (int i = 0; i < 3; i++) {
    threadPool.submit(r);
    threadPool.submit(r);
}
```

```log
[INFO ] 12:26:39:693   pool-1-thread-1 --->    执行结束，耗时：1 秒
[INFO ] 12:26:40:704   pool-1-thread-2 --->    执行结束，耗时：2 秒
[INFO ] 12:26:40:704   pool-1-thread-2 --->    第 1 轮执行完毕
[INFO ] 12:26:41:719   pool-1-thread-1 --->    执行结束，耗时：1 秒
[INFO ] 12:26:42:715   pool-1-thread-2 --->    执行结束，耗时：2 秒
[INFO ] 12:26:42:715   pool-1-thread-2 --->    第 2 轮执行完毕
[INFO ] 12:26:43:717   pool-1-thread-2 --->    执行结束，耗时：1 秒
[INFO ] 12:26:43:717   pool-1-thread-1 --->    执行结束，耗时：1 秒
[INFO ] 12:26:43:717   pool-1-thread-1 --->    第 3 轮执行完毕
```



### ConcurrentHashMap

```java
ConcurrentHashMap<String, Integer> map = new ConcurrentHashMap<>();

// 错误用法
while ((str = bufferedReader.readLine()) != null && !str.isBlank()) {
    Integer integer = map.get(str);
    integer = integer == null ? 1 : integer + 1;
    map.put(str, integer);
}


while ((str = bufferedReader.readLine()) != null && !str.isBlank()) {
    map.computeIfAbsent(str, s -> 0);
    map.computeIfPresent(str, (s, integer) -> integer+1);
}
// 利用累加器
ConcurrentHashMap<String, LongAdder> map = new ConcurrentHashMap<>();
while ((str = bufferedReader.readLine()) != null && !str.isBlank()) {
    map.computeIfAbsent(str, s -> new LongAdder());
    map.get(str).increment();
}
```











## 共享模型

### 线程安全

常见的线程安全类：String、Integer、StringBuffer、Random、Vector、Hashtable、java.util.concurrent包下的类

```java
@RestController
public class MyController {
    // HashMap 线程不安全，Hashtable 线程安全
    Map<String,Object> map = new Hashmap<>();
    
    @Autowire
    private MyService myService;
}

@Service
public class MyAservice {
    private Integer insertCount = 0;
    
    // 线程不安全
    public void insert() {
        // insert 操作
        inserCount++;
    }
}
```

```java
// 线程安全，因为 service 中的 MyDao 私有，无法修改
@RestController
public class MyController {
    @Autowire
    private MyService myService;
}

// 线程安全，因为 MyDao 中没有成员变量
@Service
public class MyAservice {
    @Autowire
    private MyDao myDao;
}

@Service
public class MyDao {
    @Select
    ....
}
```



### <a href="https://www.bilibili.com/video/BV16J411h7Rd?p=84&spm_id_from=pageDriver&vd_source=25ad2de4838bd28372a4956bac63c618">Synchronized</a>

- 偏向锁：当第一个线程通过 Synchronized 代码块，并且没有其他线程通过该代码块时，锁是偏向锁
- 轻量级锁：当偏向锁有第二个线程错过第一个线程执行代码块，会升级为轻量级锁

- 重量级锁：Monitor

  ![Monitor](D:\picture\typora\java2\Monitor.png)

- 批量重偏向：当撤销偏向锁超过阈值20次，会由偏向A线程变更为偏向B线程
- 批量撤销：当撤销偏向锁超过阈值40次，会撤销偏向锁变为不可偏向锁
- 锁撤销：即时编译器可以对不需要加锁的流程撤销锁
- 锁粗化：可以将多个连续的小锁合并成一个大锁，从而减少锁的竞争次数，提高程序性能。
- obj.wait()：让进入object 监视器的线程到 waitSet 中等待
- obj.notify()：从 waitSet 中挑一个唤醒



### 线程间通讯

- synchronized

  ```java
  public class CommunicationTest {
      public static void main(String[] args) {
          new Thread(() -> {while (true) Message.createBun();}, "生产者1").start();
          new Thread(() -> {while (true) Message.sellBun();}, "消费者1").start();
          new Thread(() -> {while (true) Message.createBun();}, "生产者2").start();
          new Thread(() -> {while (true) Message.sellBun();}, "消费者2").start();
      }
  
  }
  
  @Slf4j
  class Message {
      private static Queue<String> msgQueue = new PriorityQueue<>();
      private static AtomicInteger id = new AtomicInteger();
  
      public static synchronized void createBun() {
          String str = "消息"+("M"+id.incrementAndGet());
          msgQueue.offer(str);
          log.info("向消息队列中添加消息：{}，消息队列：{}", str, msgQueue);
          Message.class.notifyAll();
          try {
              Message.class.wait();
          } catch (InterruptedException e) {
              throw new RuntimeException(e);
          }
      }
  
      public static synchronized void sellBun(){
          if (msgQueue.size() > 0) {
              log.info("取出消息：{}，消息队列：{}", msgQueue.poll(), msgQueue);
          }
          Message.class.notifyAll();
          try {
              Message.class.wait();
          } catch (InterruptedException e) {
              throw new RuntimeException(e);
          }
      }
  }
  ```
  
- Lock 接口

  ```java
  private Lock lock = new ReentrantLock();
  private Condition condition = lock.newCondition();
  public void test() throws RuntimeException {
      lock.lock();
      condition.await();
      condition.signalAll();
      lock.unlock();
  
  }
  ```

- 注意：<font color=red>**线程在哪里进入等待，下次被唤醒将在哪里继续执行**</font>

- 保护性暂停：wait

  ```java
  public class FutureTest {
      public static void main(String[] args) {
          Future future = new Future();
          new Thread(() -> future.calculate(), "计算线程").start();
          Thread.currentThread().setName("结果线程");
          future.getResult();
      }
  }
  
  @Slf4j
  class Future {
      private Object result;
  
      // 因为要通过锁被calculate()唤醒，所以要加和calculate()方法一样的锁
      public synchronized Object getResult() {
          log.info("准备获取结果");
          if (result == null) {
              log.info("尚未得到结果，进入等待");
              try {
                  this.wait();
              } catch (InterruptedException e) {
                  log.info("受到打断请求，但不进行打断操作");
              }
          }
          log.info("得到结果");
          return result;
      }
  
      public synchronized void calculate() {
          try {
              TimeUnit.SECONDS.sleep(1);
          } catch (InterruptedException e) {
              throw new RuntimeException(e);
          }
          result = new Object();
          log.info("已计算出结果");
          this.notifyAll();
      }
  }
  ```
  
- 保护性暂停：pack

  ```java
  public class FutureTest {
      public static void main(String[] args) {
          Future2 future2 = new Future2();
          Thread getResultThread = Thread.currentThread();
          new Thread(() -> future2.calculate(getResultThread), "计算线程").start();
          getResultThread.setName("结果线程");
          // 该线程干了些别的事，可能耗费了比计算结果要更长的时间后，再获取结果
          TimeUnit.SECONDS.sleep(new Random().nextInt(3));
          future2.getResult();
      }
  }
  
  @Slf4j
  class Future2 {
      private Object result;
  
      // 查询线程不需要被锁唤醒，因此也不需要加锁
      public Object getResult() {
          log.info("准备获取结果");
          // 若有锁，park暂停时不会释放锁，因此不能加与calculate()相同的锁
          LockSupport.park();
          log.info("得到结果");
          return result;
      }
  
      public synchronized void calculate(Thread thread) {
          log.info("开始计算");
          try {
              TimeUnit.SECONDS.sleep(1);
          } catch (InterruptedException e) {
              throw new RuntimeException(e);
          }
          result = new Object();
          log.info("已计算出结果");
          // unpark 该线程后，回唤醒该线程park状态，并且即使之后被park，也不会停止
          LockSupport.unpark(thread);
      }
  }
  ```

  - <font color=red>**park 不会释放锁，或者说 park 和 锁 是不相关的，park 是线程上的属性，锁是作为锁的对象上的属性**</font>
  - <font color=red>**unpark 某条正在运行的线程后，会唤醒该线程park状态，若该线程未被park，则下一次park不会停止**</font>
  - <font color=red>**interrupt 可以打断所属线程的park状态，打断后，打断标记为true，打断标记为true时，该线程将无法再被park**</font>



### ReentranLock

- 使用

  ```java
  ReentrantLock reentrantLock = new ReentrantLock();
  reentrantLock.lock();
  try {
      log.info("获取到锁，执行临界区代码")
  } finally {
      reentrantLock.unlock();
  }
  ```

- 可打断锁

  ```java
  try {
      // reentrantLock.lock(); 无法接收打断信号
      reentrantLock.lockInterruptibly();
  } catch (InterruptedException e) {
      log.info("收到打断信号，打断阻塞状态");
      return;
  }
  ```

- 可设置超时时间

  ```java
  if (!reentrantLock.tryLock()){
      log.info("未获取到锁，结束");
      return;
  }
  
  // 支持打断
  try {
      if (!reentrantLock.tryLock(2, TimeUnit.SECONDS)){
          log.info("未获取到锁，结束");
          return;
      }
  } catch (InterruptedException e) {
      log.info("收到打断信号，打断阻塞状态");
      return;
  }
  ```

- 可设置公平锁

  ```java
  // 构造方法中传递是否开启公平锁
  ReentrantLock reentrantLock = new ReentrantLock(true);
  ```

- 支持多个条件变量：可理解为将 WaitSet 分成了多个休息室，线程可以进入指定的休息室等待，也可以唤醒指定休息室的线程

  ```java
  Condition condition1 = reentrantLock.newCondition();
  Condition condition2 = reentrantLock.newCondition();
  
  condition1.await();
  condition.await(1, TimeUnit.SECONDS);
  condition.awaitNanos(10000000);
  condition.awaitUninterruptibly();
  condition.awaitUntil(new Date());
  
  condition1.signal();
  condition1.signalAll();
  ```

- Lock 与 synchronized 的区别

  - Lock 是一个接口；synchronized 是一个关键字
  - synchronized 在发生异常时，会自动释放线程所占有的锁；而 Lock 在发生异常事，如果不主动使用 unlock() 去释放锁，则可能造成死锁现象
  - Lock 的性能优于 synchronized



### 不可变

- 不可变类设计：类和类中的属性都用 final 修饰

  - 属性用 final 修饰，保证了该属性是只读的，不能修改
  - 类用 final 修饰，保证了该类中的方法不能被覆盖，防止子类无意间破坏不可变性

  ```java
  public final class String 
      implements java.io.Serializable, Comparable<String>, CharSequence {
      private final char[] value;
      
      // 私有，外界无法更改
      private int hash;
  }
  ```

- 无状态设计：不设置成员变量

- 保护性拷贝

- 享元模式



### ThreadLocal

- 初始化

  ```java
  class MyStore{
      // 建议使用 static 修饰
      static ThreadLocal count = new ThreadLocal() {
          @Override
          protected Integer initialValue() {
              return 0;
          }
      };
      static ThreadLocal<Integer> count = ThreadLocal.withInitial(() -> 0);
      
      public void sell() {
          count.set(1+count.get());
      }
  }
  ```
  
- 使用

  ```java
  MyStore myStore = new MyStore();
  new Thread(() -> {
      try {
          
      } finally {
          // 线程结束时释放，以防内存泄露
          myStore.count.remove();
      }
  }).start();
  ```

- 内存泄露

  - 引用：内存回收后，引用会被放入指定的ReferenceQueue中
    - 强引用 Reference
    - 软引用 SoftReference：内存充足时不会进行垃圾收集，内存回收；内存不充足时会进行
    - 弱引用 WeakReference：只要垃圾回收机制运行，就会回收该对象占用的内存
    - 虚引用 PhantomReference：虚引用不会决定对象的生命周期，调用get()返回的是null

  - Thread 聚合 ThreadLocal，ThreadLocal 中有一个 ThreadLocalMap 的内部类。调用 ThreadLocal 的 set(value) 方法实际上是将 <font color=red>ThreadLocal 弱引用对象作为 key，value 作为值从而形成的Entry对象</font>存入 ThreadLocalMap 中。
    - 两条引用
      - 线程中 `ThreadLocal tl = new ThreadLocal()` tl指向这个对象是强引用
      - 调用 set() 方法后，新建一个 Entry 对象，Entry对象里的key是弱引用指向这个 ThreadLocal 对象

    - 当第一个中的强引用失效时（如设tl=null），ThreadLocal 对象只剩下弱引用，就会被回收，此时就会形成 Entry 中 key 为 null 而 值依旧存在的状况，此时的值无意义，但有引用无法回收
      - 调用 threadLocal 的 set()、get()、remove() 方法时，都会调用 expungeStaleEntry() 方法，将key为null的值全部置为null从而回收值的内存；其中remove先将key置为null在调用该方法






## 拓展

### JMM

- jvm 规范中试图定义一种 java 内存模型（java memory model）来<font color=red>屏蔽各种硬件和操作系统的内存访问</font>，用以实现 java 程序在各种平台下都<font color=red>能达到一致的内存访问效果</font>
  - 描述的是一组约束和规范，定义了程序（尤其是多线程）各个变量的读写访问方式并决定一个线程对共享变量的写入何时以及如何变为对另一个线程可见
  - 三大特性
    - 原子性
    - 可见性
    - 有序性
- happens-before：先行发生
  - 如果一个操作 happens-before 另一个操作，那么第一个操作的执行结果将对第二个操作可见，而且第一个操作的执行顺序排在第二个操作之前
  - 两个操作之间存在 happens-before 关系，并不意味着一定要按照 happens-before 原则制定的顺序来执行。如果重排序之后的执行结果与按照 happens-before 关系执行的结果一致，那么这种重排序并不非法
  - 8条规则
    - 次序规则：一个线程内，写在前面的操作先行发生于写在后面的操作
    - 锁定规则：unlock操作先行发生于
    - volatile 变量规则：对一个 volatile 变量的写操作先行发生于**后面**对这个变量的读操作
    - 传递规则：A 先行发生于 B，B 先行发生于 C，则 A 先行发生于 C
    - 线程启动规则：线程对象的 start() 方法先行发生于此线程中的每个操作
    - 线程中断规则：对线程 interrupt() 方法的调用先行发生于被中断线程的代码检测到中断的发生
    - 线程终止规则：线程中的所有操作都先行发生于对终止线程的终止检测，如可用 isAlive() 检测是否终止
    - 对象终结规则：一个对象的初始化完成（构造函数的执行结束）先行发生于它的 finalize() 方法



### <a href="https://www.bilibili.com/video/BV1ar4y1x727?p=63&vd_source=25ad2de4838bd28372a4956bac63c618">volatile</a>

- 可见性

  ```java
  public class VisiableTest {
      static volatile boolean flag = true;
      public static void main(String[] args) throws InterruptedException {
          System.out.println("start");
          // 循环体中有sout打印语句，不加volatile也可以保证可见性
          new Thread(() -> {while(flag) {}}).start();
          Thread.sleep(2000);
          System.out.println("设置为false");
          flag = false;
      }
  }
  ```

  - 锁对于其加锁的代码部分，既可以保证原子性，也可以保证可见性
  - 锁对于其加锁的代码部分，保证只有一个线程执行，根据先行发生happens-before原则下的次序规则：一个线程内，写在前面的操作先行发生于写在后面的操作，而先行发生虽然不能保证不发生指令重排，但其保证是否发生指令重排对结果不影响，因此锁也可以保证有序性

- 有序性

  ```java
  public class Singleton {
      private Singleton(){};
      private static Singleton instance = null;
      
      public static Singleton getInstance() {
          if (instance == null) {
              synchronized (Singleton.class) {
                  if (instance == null) {
                      
                      instance = new Singleton();
                      // new：创建对象，将对象引用入栈
                      // dup：复制一份对象引用
                      // invokespecial：创建实例关联对象引用
                      // putstatic :将对象引用赋值给 static instance 
                  }
              }
          }
          return instance;
      }
  }
  ```

  - 若 invokespecial 和 putstatic 指令重排，另一个线程返回的可能是未初始完的实例对象

- 原理：底层实现的原理是内存屏障

  - 对 volatile 变量的写指令后会加入写屏障，写屏障保证在该屏障之前的、对共享变量的改动，都同步到主存中；写屏障之前的代码不会被指令重排的写屏障之后
  - 对 volatile 变量的读指令前会加入读屏障，读屏障保证在该屏障之后的、对共享变量的读取，加载的是主存中最新的数据；读屏障之前的代码不会被指令重排到读屏障之前



### 内存布局

- 对象的堆内存中的存储布局

  - 对象头

    - 对象标记（Mark Word）

      <table>
          <caption>64位虚拟机</caption>
          <tr>
              <td rowspan="2">锁状态</td>
              <td colspan="4">56bit</td>
              <td rowspan="2">1bit</td>
              <td rowspan="2">4bit</td>
              <td rowspan="2">1bit<br/>(是否是偏向锁)</td>
              <td rowspan="2">1bit<br/>(锁标记位)</td>
          </tr>
          <tr>
              <td colspan="2">25bit</td>
              <td colspan="2">31bit</td>
          </tr>
          <tr>
              <td>无锁</td>
              <td colspan="2">unused</td>
              <td colspan="2">对象 hashCode</td>
              <td>Cms_free</td>
              <td>对象分代年龄</td>
              <td>0</td>
              <td>01</td>
          </tr>
          <tr>
              <td>偏向锁</td>
              <td colspan="3">threadId(54bit)</td>
              <td colspan="1">Epoch(2bit)</td>
              <td>Cms_free</td>
              <td>对象分代年龄</td>
              <td>1</td>
              <td>01</td>
          </tr>
          <tr>
              <td>轻量级锁</td>
              <td colspan="7">指向栈中的记录的指针</td>
              <td>00</td>
          </tr>
          <tr>
              <td>重量级锁</td>
              <td colspan="7">指向重量级锁的指针</td>
              <td>10</td>
          </tr>
          <tr>
              <td>GC标志</td>
              <td colspan="7">空</td>
              <td>01</td>
          </tr>
      </table>

    - 类元信息（类型指针、klass Pointer）：指向方法区中某个类的Klass类元信息

    - 长度（length）：数组对象拥有

  - 实例数据（instance data）：存放类的属性（Field）数据信息，包括父类的属性信息

  - 对齐填充（padding）：保证对象存储大小为8个字节的倍数

- 问题

  - `Object o = new Object()`中各部分存储位置
    - Object是方法区中的类元信息；o是栈内存中的引用；new Object()在堆内存中
  - new 一个对象占多少内存大小
    - 64位操作系统中，Mark Word 占8个字节，类型指针占8个字节，对象头一共16个字节。所以一个对象最小16个字节
      - 默认开启了压缩指针，一个对象最小 12+4(对齐填充) 个字节
    - 若包含属性`int id`、`boolean flag`，实例数据 4+1 个字节
    - 对齐填充会填充3个字节到24个字节
  - 为什么新生区对象经过15次垃圾回收到养老区
    - 对象标记中对象分代年龄由 4bit 记录，最大 1111 即为15



### AQS

- AQS使用一个 `volatile int state` 的成员变量来表示同步状态，通过内置的 FIFO 队列来完成资源获取的排队工作，将每条要去抢占资源的线程封装成一个静态内部类Node的节点对象来实现锁的分配，通过CAS完成对state值的修改

  ![AQS](D:\picture\typora\java2\AQS.png)

- 源码分析

  - 结构

    - ReentrantLock 类中有三个静态内部类，分别是：抽象类Sync，Sync的子类NonfairSync、FairSync

    - 抽象类Sync继承AbstractQueuedSynchro

    - AbstractQueuedSynchro 中有一个静态内部类Node

    - AbstractQueuedSynchro 中定义了多个模板方法，常用的是加锁时的acquire()和释放锁时的release()

  - 流程
  
    - lock() 方法会调用模板方法 asq.acquire(1)
  
      ```java
      public final void acquire(int arg) {
          // AQS类定义了多个方法供子类实现或覆盖
          if (!tryAcquire(arg) &&
              acquireQueued(addWaiter(Node.EXCLUSIVE), arg))
              selfInterrupt();
      }
      ```
  
      - 首先调用 tryAcquire() 尝试抢占资源
      - 抢占失败，调用 addWaiter() 将新节点加入队列
        - 创建一个虚拟占位空节点放在head，虚拟头阶段的thread属性为null
        - 后续加入的包含线程的节点依次放在head的后面
      - 将加入队列的节点的waitstate设置为-1
        - 先判断当前节点的前一个节点是否为虚拟节点，再 tryAcquire() 尝试抢占资源
          - 若抢占成功，将头节点设置为当前抢占成功的阶段，虚拟节点的next 置为null
        - 若失败，则判断waitstate的值
          - 若为0，将值改为-1，返回flase。进入第二次循环，回到上一步
          - 若为-1，返回true，在执行 LockSupport.park(this) 进入等待
  
    - unlock() 方法会调用模板方法 asq.release(1)
  
      ```java
      public final boolean release(int arg) {
          if (tryRelease(arg)) {
              Node h = head;
              if (h != null && h.waitStatus != 0)
                  unparkSuccessor(h);
              return true;
          }
          return false;
      }
      ```
  
  - NonfairSync 和 FairSync 都实现了 tryAcquire() 方法，区别在于非公平锁获取锁时比公平锁中少一个判断 !hasQueuedPredecessors()；hasQueuedPredecessors() 中判断了FIFO中是否有非空Node（是否需要排队）
  
    ```java
    // 此处为公平锁的 tryAcquire 方法实现
    protected final boolean tryAcquire(int acquires) {
        final Thread current = Thread.currentThread();
        int c = getState();
        if (c == 0) {
            // 公平锁会去检查FIFO中是否有等待的节点，若有，则不会去执行compareAndSetState
            if (!hasQueuedPredecessors() &&
                compareAndSetState(0, acquires)) {
                setExclusiveOwnerThread(current);
                return true;
            }
        }
        // 如果已经获得了锁，线程还是当前线程，表示发生了锁重入
        else if (current == getExclusiveOwnerThread()) {
            // state ++
            int nextc = c + acquires;
            if (nextc < 0)
                throw new Error("Maximum lock count exceeded");
            setState(nextc);
            return true;
        }
        return false;
    }
    ```
  
  - AQS类已经实现了addWaiter()
  
    ```java
    private Node addWaiter(Node mode) {
        // mode：Node.EXCLUSIVE 排他模式
        // 创建一个封装当前线程的新node，新node的waitState属性值为0
        Node node = new Node(mode);
    
        for (;;) {
            Node oldTail = tail;
            if (oldTail != null) {
                node.setPrevRelaxed(oldTail);
                if (compareAndSetTail(oldTail, node)) {
                    oldTail.next = node;
                    return node;
                }
            } else {
                // 初始化队列。new一个空节点作为虚拟节点，head = tail = new Node()
                initializeSyncQueue();
            }
        }
    }
    ```
  
  - AQS类已经实现了acquiredQueued()
  
    ```java
    // 不可打断模式：当线程抢到锁时，才会跳出循环，返回打断标记，再打断
    final boolean acquireQueued(final Node node, int arg) {
        try {
            boolean interrupted = false;
            for (;;) {
                // 获得node前一个节点，若前一个节点为null，报错
                final Node p = node.predecessor();
                if (p == head && tryAcquire(arg)) {
                    // node设置为头节点，node的thread、prev属性置为null
                    setHead(node);
                    // 此时原先的虚拟头节点无引用指向，将被回收；node节点将成为新的虚拟头节点
                    p.next = null; // help GC
                    // 当线程抢到锁时，才会跳出循环，返回打断标记
                    return interrupted;
                }
                // 若p节点的waitstate为0，则设置为-1并返回false；若为-1，则返回true
                if (shouldParkAfterFailedAcquire(p, node) &&
                    // 调用 LockSupport.park(this)
                    parkAndCheckInterrupt())
                    interrupted = true;
            }
        } catch (Throwable t) {
            cancelAcquire(node);
            throw t;
        }
    }
    ```
    
    ```java
    private final boolean parkAndCheckInterrupt() {
        LockSupport.park(this);
        // 返回为当前线程在park时是否被打断过，并清除打断标记
        return Thread.interrupted();
    }
    ```
  
  - tryRelease(int releases)
  
    ```java
    protected final boolean tryRelease(int releases) {
        // 若是重入锁，释放是 state--
        int c = getState() - releases;
        if (Thread.currentThread() != getExclusiveOwnerThread())
            throw new IllegalMonitorStateException();
        boolean free = false;
        if (c == 0) {
            free = true;
            setExclusiveOwnerThread(null);
        }
        setState(c);
        return free;
    }
    ```
  
- 问题

  - 锁重入原理：通过查看tryAcquire和tryRelease方法可知，利用state的++和--实现

  - 可打断原理：lock.lockInterruptible() 调用的是 aqs.doAcquireInterruptibly() 方法

    ```java
    public void lockInterruptibly() throws InterruptedException {
        sync.acquireInterruptibly(1);
    }
    ```

    ```java
    private void doAcquireInterruptibly(int arg)
        throws InterruptedException {
        final Node node = addWaiter(Node.EXCLUSIVE);
        try {
            for (;;) {
                final Node p = node.predecessor();
                if (p == head && tryAcquire(arg)) {
                    setHead(node);
                    p.next = null; // help GC
                    return;
                }
                if (shouldParkAfterFailedAcquire(p, node) &&
                    parkAndCheckInterrupt())
                    // 与不可打断相比，这里在被打断时，直接抛出异常，不会在进入下一次循环
                    throw new InterruptedException();
            }
        } catch (Throwable t) {
            cancelAcquire(node);
            throw t;
        }
    }
    ```

  - 公平锁原理：通过tryAcquire方法可知，公平锁会去检查FIFO中是否有等待的节点

  - <a href="https://www.bilibili.com/video/BV16J411h7Rd?p=245&vd_source=25ad2de4838bd28372a4956bac63c618">await 和 singal 原理</a>




### 读写锁

- ReentrantReadWriteLock使用

  - 读锁不支持条件变量
  - 重入时不支持升级：即持有读锁的情况下去获取写锁，会导致获取写多永久等待
  - 重入时支持降级：即持有写锁的情况下可以获取读锁

  ```java
  class CacheData {
      Object data;
      // 判断数据是否有效，如果为false，说明要更新数据
      volatile boolean cacheValid;
      final ReentrantReadWriteLock rwl = new ReentrantReadWriteLock();
      
      void processCachedData() {
          rwl.readLock().lock();
          if (! cacheValid) {
              // 获取写锁前必须释放读锁
              rwl.readLock().unlock();
              rwl.writeLock().lock();
              try {
                  // double check
                  if (! cacheValid) {
                      data = ...; // 更新数据操作
                      cacheValid = true;
                  }
                  // 将写锁降级为读锁，释放写锁
                  rwl.readLock().lock();
              } finally {
                  rwl.writeLock().unlock();
              }
          }
          // 使用完数据后释放读锁
          try {
              use(data);
          } finally {
              rwl.readLock().unlock();
          }
      }
  }
  ```

- ReentrantReadWriteLock原理

  - 读写锁用的是同一个Sycn同步器，因此等待队列、state等也是同一个
  - state 的低16位供写锁使用，高16位供读锁使用

- StampedLock 读写锁

  ```java
  @Slf4j
  class DataContainer {
      private int data = 0;
      private final StampedLock lock = new StampedLock();
  
      public int optimisticRead() throws InterruptedException {
          long stamp = lock.tryOptimisticRead();
          log.info("乐观读锁添加成功，stamp：{}", stamp);
          TimeUnit.MILLISECONDS.sleep(1000);
          if(lock.validate(stamp)) {
              log.info("乐观读锁未升级，stamp：{}", stamp);
              return data;
          }
          log.info("乐观读锁升级，stamp：{}", stamp);
          try {
              stamp = lock.readLock();
              log.info("读锁添加成功，stamp：{}", stamp);
              TimeUnit.MILLISECONDS.sleep(1000);
              return data;
          }finally {
              log.info("释放读锁，stamp：{}", stamp);
              lock.unlockRead(stamp);
          }
      }
  
      public void write() throws InterruptedException {
          TimeUnit.MILLISECONDS.sleep(500);
          long stamp = lock.writeLock();
          log.info("写锁添加成功，stamp：{}", stamp);
          data ++;
          TimeUnit.MILLISECONDS.sleep(2000);
          lock.unlockWrite(stamp);
          log.info("释放写锁，stamp：{}", stamp);
      }
  }
  ```

  ```log
  [INFO ] 12:05:56:426   Thread-0   --->    乐观读锁添加成功，stamp：256
  [INFO ] 12:05:56:936   Thread-1   --->    写锁添加成功，stamp：384
  [INFO ] 12:05:57:437   Thread-0   --->    乐观读锁升级，stamp：256
  [INFO ] 12:05:58:943   Thread-1   --->    释放写锁，stamp：384
  [INFO ] 12:05:58:943   Thread-0   --->    读锁添加成功，stamp：513
  [INFO ] 12:05:59:954   Thread-0   --->    释放读锁，stamp：513
  ```

  - 乐观读锁不会修改stamp值
  - 读锁和写锁会修改stamp值









# MQ



## 问题处理

- 消息可靠性问题：确保发送的消息至少被消费一次
- 消息延迟问题
- 消息堆积问题
- 高可用问题：避免单点mq故障



### 消息可靠性

- 哪些可能会导致消息丢失
  - 发送者发送的消息未送达exchange
  - 消息到exchange后未到达queue

- mq宕机，queue将消息丢失
- consumer接收到消息后未消费就宕机



#### 生产者消息确认

- Rabbitmq提供了publisher confirm机制来避免消息发送到MQ的过程中丢失。消息发送到MQ以后，会返回一个结果给发送者，表示消息是否处理成功。结果有两种请求
  - publisher-confirm，发送者确认
    - 消息成功投递到交换机，返回ack
    - 消息未成功投递到交换机，返回nack
  - publisher-return，发送者回执
    - 消息投递到交换机，但是没有路由到队列，返回ack，及路由失败原因
  - 确认机制发送消息时，需要给每个消息设置一个全局唯一id，以区分不同消息





#### 消息持久化

#### 消费者消息确认

#### 消费失败重试机制





### 私信交换机



### 惰性队列

### MQ集群









# ELK

![ELFK](D:\picture\typora\java2\ElasticStack\ELFK.png)

## ElasticSearch

### 概念

#### docker部署

- 还需要部署kibana容器，因此需要先创建一个网络，让es和kibana容器互联。

  ```shell
  docker network create es-net
  ```

- 拉去elasticsearch镜像

  ```shell
  docker pull elasticsearch:7.12.1
  ```

- 创建挂载目录

  ```shell
  mkdir -p /var/docker-volume/es
  ```

- 转移数据

  ```shell
  docker run -d \
  	--name es \
  	-e "ES_JAVA_OPTS=-Xms512m -Xmx512m" \
  	-e "discovery.type=single-node" \
  	--privileged \
  	--network es-net \
  	elasticsearch:7.12.1
  	
  docker cp es:/usr/share/elasticsearch/data /var/docker-volume/es
  docker cp es:/usr/share/elasticsearch/plugins /var/docker-volume/es
  
  docker stop es
  docker rm es
  ```

- 运行es容器

  ```shell
  docker run -d \
  	--name es \
  	-e "ES_JAVA_OPTS=-Xms512m -Xmx512m" \
  	-e "discovery.type=single-node" \
  	-v /var/docker-volume/es/data:/usr/share/elasticsearch/data \
  	-v /var/docker-volume/es/plugins:/usr/share/elasticsearch/plugins \
  	--privileged \
  	--network es-net \
  	-p 9200:9200 \
  	-p 9300:9300 \
  	elasticsearch:7.12.1
  ```

- 安装运行kibana

  ```shell
  docker run -d \
  	--name kibana \
  	-e ELASTICSEARCH_HOSTS=http://192.168.36.132:9200 \
  	--network=es-net \
  	-p 5601:5601 \
  	kibana:7.12.1
  ```



#### ik分词器

- 安装ik分词器

  ```shell
  # 进入容器内部
  docker exec -it es /bin/bash
  # 在线下载并安装
  ./bin/elasticsearch-plugin install https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v7.12.1/elasticsearch-analysis-ik-7.12.1.zip
  # 退出容器
  exit
  # 重启容器
  docker restart es
  ```

- 拓展词库

  - 修改ik分词器目录下的config目录中的IkAnalyzer.cfg.xml文件

    ```xml
    <?xml version="1.0" encoding="UTF-8"?>
    <!DOCTYPE properties SYSTEM "http://java.sun.com/dtd/properties.dtd">
    <properties>
    	<comment>IK Analyzer 扩展配置</comment>
    	<!--用户可以在这里配置自己的扩展字典 -->
    	<entry key="ext_dict"></entry>
    	 <!--用户可以在这里配置自己的扩展停止词字典-->
    	<entry key="ext_stopwords"></entry>
        
    	<!--用户可以在这里配置远程扩展字典 -->
    	<!-- <entry key="remote_ext_dict">words_location</entry> -->
    	<!--用户可以在这里配置远程扩展停止词字典-->
    	<!-- <entry key="remote_ext_stopwords">words_location</entry> -->
    </properties>
    ```





### CRUD

#### devTool

##### 操作索引库

- mapping
  - mapping是对索引库中文档的约束，常见的mapping属性包括
    - type：字段数据类型，常用的简单类型有：
      - 字符串：text（可分次的文本）、keyword（精确值，例如：品牌、国家、ip地址）
      - 数值：long、integer、short、byte、double、float
      - 布尔：boolean
      - 日期：date
      - 对象：object
    - index：是否创建倒排索引，默认为true
    - analyzer：使用哪种分词器
      - ik插件：ik_smart、ik_max_word
    - properties：该字段的子属性
  
- 创建索引库

  - ES中通过Restful请求操作索引库、文档。请求内容用DSL语句来表示

    ```json
    PUT /索引库名称
    {
        "mappings": {
            "properties": {
                "字段名1": {
                    "type": "text",
                    "analyzer": "ik_smart"
                },
                "字段名2": {
                    "type": "keyword",
                    "analyzer": "false",
                    "properties": {
                        "子字段": {
                            "type": "keyword"
                        }
                    }
                },
                // ... 略
            }
        }
    }
    ```

- 查询索引库

  - GET /索引库名

- 删除索引库

  - DELETE /索引库名

- 修改索引库：只能添加新字段

  ```json
  PUT /索引库名/_mapping
  {
      "properties": {
          "新字段名": {
              "type": "integer"
          }
      }
  }
  ```



##### 文档操作

- 新增文档

  ```json
  POST /索引库名/_doc/文档id
  {
      "字段1": "值1",
      "字段2": "值2",
      "字段3": {
          "子属性1": "值3",
          "子属性2": "值4"
      },
      // ...
  }
  ```

- 查询文档：GET /索引库/_doc/文档id

- 删除文档：DELETE  /索引库/_doc/文档id

- 修改文档：

  - 全文修改，会删除旧文档，添加新文档，使用PUT请求

  - 局部修改

    ```json
    PUT /索引库名/_update/文档id
    {
        "doc": {
            "字段名": "新的值"
        }
    }
    ```






#### java

##### 前置配置

- 引入es的 RestHighLevelClient 依赖

  ```xml
  <dependency>
      <groupId>org.elasticsearch.client</groupId>
      <artifactId>elasticsearch-rest-high-level-client</artifactId>
  </dependency>
  ```

- 因为springboot默认配置的es版本是7.6.2，所有需要覆盖默认的es版本

  ```xml
  <properties>
      <elasticsearch.version>7.12.1</elasticsearch.version>
  </properties>
  ```

- 初始化RestHighLevelClient

  ```java
  @SpringBootTest
  public class TestApp {
      private RestHighLevelClient client;
  
      @BeforeEach
      void setUp() {
          this.client = new RestHighLevelClient(RestClient.builder(
              HttpHost.create("http://192.168.36.132:9200")));
      }
  
      @AfterEach
      void tearDown() throws IOException {
          this.client.close();
      }
  }
  ```



##### 操作索引库

- 创建索引库

  ```java
  CreateIndexRequest request = new CreateIndexRequest("anime");
  request.source(ESConstant.animeIndex, XContentType.JSON);
  client.indices().create(request, RequestOptions.DEFAULT);
  ```

- 删除索引库

  ```java
  DeleteIndexRequest request = new DeleteIndexRequest("anime");
  client.indices().delete(request, RequestOptions.DEFAULT );
  ```

- 判断索引库是否存在

  ```java
  GetIndexRequest request = new GetIndexRequest("anime");
  boolean exists = client.indices().exists(request, RequestOptions.DEFAULT);
  System.out.println(exists);
  ```



##### 操作文档

- 新增文档

  ```java
  @Test
  public void addDoc() throws IOException {
      Anime anime = animeService.getById(1);
      AnimeDoc animeDoc = new AnimeDoc(anime);
      IndexRequest request = new IndexRequest("anime").id("1");
      request.source(JSONUtil.toJsonStr(animeDoc), XContentType.JSON);
      client.index(request, RequestOptions.DEFAULT);
  }
  ```

- 查询文档

  ```java
  GetRequest getRequest = new GetRequest("anime").id("1");
  GetResponse response = client.get(getRequest, RequestOptions.DEFAULT);
  AnimeDoc animeDoc = JSONUtil.toBean(response.getSourceAsString(), AnimeDoc.class);
  System.out.println(animeDoc);
  ```

- 删除文档

  ```java
  DeleteRequest request = new DeleteRequest("anime").id("1");
  client.delete(request, RequestOptions.DEFAULT);
  ```

- 修改文档

  - 全量更新：与新增文档类似

  - 局部更新

    ```java
    @Test
    public void updateDoc() throws IOException {
        UpdateRequest request = new UpdateRequest("anime", "1");
        request.doc("state", 10, "type", "日常");
        client.update(request, RequestOptions.DEFAULT);
    }
    ```

- 批量新增

  ```java
  BulkRequest request = new BulkRequest();
  List<Anime> list = animeService.list();
  for (Anime anime : list) {
      AnimeDoc animeDoc = new AnimeDoc(anime);
      IndexRequest indexRequest = new IndexRequest("anime")
          .id(anime.getId()+"")
          .source(JSONUtil.toJsonStr(animeDoc), XContentType.JSON);
      request.add(indexRequest);
  }
  client.bulk(request, RequestOptions.DEFAULT);
  ```





### DSL

#### devTool

##### 基本语法

- DSL Query基本语法

  ```json
  GET /索引库名/_search
  {
      "query": {
          "查询类型": {
              "查询条件": "条件值"
          }
      }
  }
  ```

- match查询

  ```json
  GET /索引库名/_search
  {
      "query": {
          "match": {
              "字段": "内容"
          }
      }
  }
  ```

- multi_match查询

  ```json
  GET /索引库名/_search
  {
      "query": {
          "multi_match": {
              "query": "内容",
              "field": ["字段1", "字段2"]
          }
      }
  }
  ```

- 精确查询

  - term：根据词条精确值查询

    ```json
    GET /索引库名/_search
    {
        "query": {
            "term": {
                "字段": {
                    "value": "值"
                }
            }
        }
    }
    ```

  - range：根据值的范围查询

    ```json
    GET /索引库名/_search
    {
        "query": {
            "range": {
                "字段": {
                    "gte": 最小值,
                    "lte": 最大值
                }
            }
        }
    }
    ```

  - geo_bounding_box：根据geo_point值落在某个矩形范围的所有文档

    ```json
    GET /索引库名/_search
    {
        "query": {
            "geo_bounding_box": {
                "字段": {
                    "top_left": {
                        "lat": 31.1,
                        "lon": 121.5
                    },
                    "bottom_right": {
                        "lat": 30.9,
                        "lon": 121.7
                    }
                }
            }
        }
    }
    ```

  - geo_distance：根据geo_point搜索附近指定范围内的所有文档

    ```json
    GET /索引库名/_search
    {
        "query": {
            "geo_distance": {
                "distance": "15km",
                "字段": "3"
            }
        }
    }
    ```

    

##### 复合查询

- 相关性算分

  - TF
    - TF（词条频率）= 词条出现次数 / 文档中词条总数
  - TF-IDF：elasticsearch5.0之前，分数会随着词频的增加而越来越大
    - IDF（逆文档频率）= log(文档总数 / 包含词条的文档总数)
    - score = ∑^n^~i~ TF  * IDF
  - BM25：elasticsearch5.0后，分数会随着词频增大而增大，但曲线最终会趋于水平

- Function Score Query

  - 修改文档的相关性算分
  - 算分函数：functions
    - filter：定义对哪些文档进行处理
    - weight：给一个常量值，作为函数结果
    - field_value_factor：用文档中的某个字段值作为函数结果
    - random_score：随机生成一个值，作为函数结果
    - scropt_score：自定义计算公式，公式结果作为函数结果
  - 加权模式：boost_mode
    - multiply：function score和query score相乘，默认
    - replace：用function score 替换 query score
    - 其他：sum、avg、max、min

  ```json
  GET /索引库名/_search
  {
      "query": {
          "function_score": {
              "query": {"match": {"字段": "内容"}},
              "functions": [
                  {
                      "filter": {"term": {"字段": "内容"}},
                      "weight": 10
                  }
              ],
              "boost_mode": "multiply"
          }
      }
  }
  ```

- Boolean Query

  - 布尔查询是一个或多个查询子句的组合，子查询的组合方式有：
    - must：必须匹配每个字符串，参与算分
    - should：选择性匹配，参与算分
    - must_not：必须不匹配，不参与算分
    - filter：必须匹配，不参与算分

  ```json
  GET /索引库名/_search
  {
      "query": {
          "bool": {
              "must": [{"term": {"字段": "内容"}}],
              "should": [{"term": {"字段1": "内容2"}, {"term": {"字段2": "内容2"}],
              "must_not": [{"range": {"price": {"let": 500}}}],
              "filter": [
                  {
                      "geo_distance": {
                          "distance": "10km",
                          "location": {"lat": 31.21, "lon": 121.5}
                      }
                  }
              ]
          }
      }
  }
  ```

  

##### 结果处理

- 结果排序

  - 默认根据相关度算分来排序，可排序的字段类型有：keyword、数值类型、地理坐标类型、日期类型
    - asc：升序
    - desc：降序

  ```json
  GET /索引库名/_search
  {
      "query": {
          "match_all": {}
      },
      "sort": [
          {"字段": "desc"},
          {
              "_geo_distance": {
                  "location": {"lat": "纬度", "lon": "经度"},
                  "order": "asc",
                  "unit": "km"
              }
          }
      ]
  }
  ```

- 分页

  - 简单分页
    - from：分页开始的位置
    - size：每页文档条数
    - 优点：支持随机翻页
    - 缺点：深度分页问题，默认查询上限是10000
  - after search
    - 先排序，再记录该页最后条数据，下次查询从该范围查询
    - 优点：利用多次查询，可查出10000以上数据
    - 缺点：只能向后查询，不支持随机翻页
  - scroll：记录快照

- 高亮显示

  - 默认匹配的字段要与需要高亮的字段相同

  ```json
  GET /索引库名/_search
  {
      "query": {
          "match": {
              "字段 ": "内容"
          }
      },
      "highlight": {
          "fields": {
              "字段": {
                  //"reuqire_field_match": "false" //字段可以不相同
                  "pre_tags": "<em>",
                  "post_tags": "</em>"
              }
          }
      }
  }
  ```

  



#### java

##### 简单查询

```java
@Test
public void matchAll() throws IOException {
    SearchRequest request = new SearchRequest("anime");

    BoolQueryBuilder boolQueryBuilder = QueryBuilders.boolQuery();
    boolQueryBuilder.must(QueryBuilders.matchQuery("all", "日常搞笑"));
    boolQueryBuilder.must(QueryBuilders.termQuery("all", "校园"));
    request.source().query(boolQueryBuilder);
    request.source().from(0).size(5);

    SearchResponse response = client.search(request, RequestOptions.DEFAULT);
    SearchHits hits = response.getHits();
    System.out.println("共搜索到 " + hits.getTotalHits().value + " 条数据");
    for (SearchHit hit : hits.getHits()) {
        System.out.println(hit.getSourceAsString());
        // 获得一个map集合，可用于替换hit中的信息
        System.out.println(hit.getHighlightFields());
    }
}
```



##### 组合查询

```java
FunctionScoreQueryBuilder functionScoreQueryBuilder = QueryBuilders.functionScoreQuery(
    QueryBuilders.boolQuery()
    .must(QueryBuilders.matchQuery("all", "日常搞笑"))
    .must(QueryBuilders.termQuery("all", "校园")),
    new FunctionScoreQueryBuilder.FilterFunctionBuilder[]{
        new FunctionScoreQueryBuilder.FilterFunctionBuilder(
            QueryBuilders.termQuery("type", "搞笑"),
            ScoreFunctionBuilders.weightFactorFunction(10))
    }
);
```





### 数据聚合

- 聚合的分类
  - Bucket：桶聚合
  - Metric：度量聚合
  - Pipeline：管道聚合

- devTool

  ```json
  GET /索引库名/_search
  {
      //"query": {}, // 可加限定条件，指定对部分数据进行聚合，默认对所有文档聚合 
      "size": 0, // 分页中每页展示数据
      "aggs": {
          "自定义聚合名": {
              "terms": {
                  "field": "聚合字段",
                  //"order": {"_count": "asc"}, // 升序排列，默认降序
                  "size": 10 // 展示数据条数
              }
          }
      }
  }
  ```

  ```json
  GET /索引库名/_search
  {
      "size": 0,
      "aggs": {
          "自定义聚合名1": {
              "terms": {"field": "聚合字段", "size": 10},
              // 聚合的嵌套
              "order": {"自定义聚合名2.avg": "asc"},
              "aggs": {
                  "自定义聚合名2": {
                      "stats": { // 聚合类型，这里的stats可以计算min、max、avg等
                          "field": "聚合字段"
                      }
                  }
              }
          }
      }
  }
  ```

- java

  ```java
  SearchRequest request = new SearchRequest("anime");
  request.source().size(0);
  request.source().aggregation(AggregationBuilders.stats("stateAgg").field("state"));
  ```

  



### 自动补全

#### 分词器

- 拼音分词器

- 自定义分词器：在创建索引库的时候设置分词器

  ```json
  PUT /test
  {
    "settings": {
      "analysis": {
        "analyzer": {
          "my_analyzer": {
            "tokenizer": "ik_max_word",
            "filter": "py"
          }
        },
        "filter": {
          "py": {
            "type": "pinyin",
            "keep_full_pinyin": false,
            "keep_joined_full_pinyin": true,
            "keep_original": true,
            "limit_first_letter_length": 16,
            "remove_duplicated_term": true,
            "none_chinese_pinyin_tokenize": false
          }
        }
      }
    },
    "mappings": {
      "properties": {
        "overview": {
          "type": "text",
          "analyzer": "my_analyzer",
          "search_analyzer": "ik_smart"
        }
      }
    }
  }
  ```

  ```json
  POST /test/_analyze
  {
    "text": "你好世界",
    "analyzer": "my_analyzer"
  }
  ```

  

#### 自动补全

- 自动补全对字段的要求
  - 类型是completion类型
  - 字段值是多词条的数组

- 查询语法

  ```json
  GET /索引库名/_search
  {
      "suggest": {
          "自定义名": {
              "text": "关键字",
              "completion": {
                  "field": "字段",
                  "skip_duplicates": true, // 跳过重复的
                  "size": 10 // 显示条数
              }
          }
      }
  }
  ```





### 数据同步

- mysql与es间数据的同步

- 解决

  - 同步调用

  - 异步通知：使用消息中间键

  - 监听binlog





### 集群

- 海量数据存储问题：
  - 将索引库从逻辑上拆分为n个分片，存储到多个节点
- 单点故障问题：
  - 将分片数据备份，并放在其他节点上
- 集群状态的监控
  - cerebro：https://github.com/lmenezes/cerebro/releases



#### 创建集群

- docker-compose编排文件

  ```shell
  version: '2.2'
  services:
    es01:
      image: elasticsearch:7.12.1
      container_name: es01
      environment:
        - node.name=es01
        - cluster.name=es-docker-cluster # 集群名称相同后，会自动组装为一个集群
        - discovery.seed_hosts=es02,es03 # 已配置容器互连后，地址简写为容器名
        - cluster.initial_master_nodes=es01,es02,es03 # 初始化的主节点
        - bootstrap.memory_lock=true
        - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
      ulimits:
        memlock:
          soft: -1
          hard: -1
      volumes:
        - ./data/node0:/usr/share/elasticsearch/data
        - ./logs/node0:/usr/share/elasticsearch/logs
      ports:
        - 9200:9200
      networks:
        - elastic
    es02:
      image: docker.elastic.co/elasticsearch/elasticsearch:7.4.0
      container_name: es02
      environment:
        - node.name=es02
        - cluster.name=es-docker-cluster
        - discovery.seed_hosts=es01,es03
        - cluster.initial_master_nodes=es01,es02,es03
        - bootstrap.memory_lock=true
        - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
      ulimits:
        memlock:
          soft: -1
          hard: -1
      volumes:
        - ./data/node1:/usr/share/elasticsearch/data
        - ./logs/node1:/usr/share/elasticsearch/logs
      networks:
        - elastic
    es03:
      image: docker.elastic.co/elasticsearch/elasticsearch:7.4.0
      container_name: es03
      environment:
        - node.name=es03
        - cluster.name=es-docker-cluster
        - discovery.seed_hosts=es01,es02
        - cluster.initial_master_nodes=es01,es02,es03
        - bootstrap.memory_lock=true
        - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
      ulimits:
        memlock:
          soft: -1
          hard: -1
      volumes:
        - ./logs/node2:/usr/share/elasticsearch/data
        - ./logs/node2:/usr/share/elasticsearch/logs
      networks:
        - elastic
        
  networks:
    elastic:
      driver: bridge
  ```

- 修改linux的系统权限

  - 编辑文件：vi /etc/sysctl.conf
  - 添加内容：vm.max_map_count=262144
  - 让配置生效：sysctl -p

- 设置分片与备份

  ```json
  PUT /索引库名
  {
      "settings": {
          "number_of_shards": 3, // 分片信息
          "number_of_replicas": 1 // 副本数量
      },
      "mappings": {"properties": { 。。。}}
  }
  ```

  

#### 集群职责

| 节点类型        | 配置参数    | 默认值 | 节点职责                                                     |
| --------------- | ----------- | ------ | ------------------------------------------------------------ |
| master eligible | node.master | true   | 备选主节点：主节点可以管理和记录集群状态、决定分片<br/>在哪个节点、处理创建和删除索引库的请求 |
| data            | node.data   | true   | 数据节点：存储数据、搜索、聚合、CRUD                         |
| ingest          | node.ingest | true   | 数据存储之前的预处理                                         |
| coordinating    |             |        | 所有es节点：路由请求，合并结果                               |

- 脑裂问题
  - 解决：成为主节点需要选票超过（eligible节点数 + 1）/ 2 才能当选，因此eligible节点最好为奇数
- coordinating节点
  - 新增是，通过算法将请求发送到一个data节点
  - 查询时，将请求路由到各个data节点，各个节点查完后，汇总到该coordinating节点
- 故障转移
  - 集群中的master节点会监控各个节点状态，如果有节点宕机
    - 启用其他节点上的备份数据
    - 将宕机节点的分片数据迁移到其他节点，使数据处于健康状态
  - 健康状态：如果有节点宕机，可利用备份数据进行恢复













## Logstash

## Kibana









# Kubenetes
