# Netty



## BIO

### 同步阻塞案例

- Server

  ```java
  public class Server {
      public static void main(String[] args) {
          try {
              ServerSocket server = new ServerSocket(8848);
              System.out.println("服务端已启动");
              Socket socket = server.accept();
              InputStream is = socket.getInputStream();
              BufferedReader br = new BufferedReader(new InputStreamReader(is));
              String msg;
              // 此处用if
              if ((msg = br.readLine()) != null){
                  System.out.println("服务端收到：【 "+msg+" 】");
              }
  
          } catch (IOException e) {
              throw new RuntimeException(e);
          }
      }
  }
  ```

- Client

  ```java
  public class Client {
      public static void main(String[] args) throws IOException {
          Socket socket = new Socket("127.0.0.1", 8848);
          OutputStream outputStream = socket.getOutputStream();
          PrintStream ps = new PrintStream(outputStream);
          // 用print未写完一行数据，服务器无法读取到完整一行
          ps.print("hello, server!");
          ps.flush();
          // 未关闭，java.net.SocketException: Connection reset
      }
  }
  ```



### 多发多收

- Server

  ```java
  public class Server {
      public static void main(String[] args) {
          try {
              ServerSocket server = new ServerSocket(8848);
              System.out.println("服务端已启动");
              Socket socket = server.accept();
              InputStream is = socket.getInputStream();
              BufferedReader br = new BufferedReader(new InputStreamReader(is));
              String msg;
              // 此处用while
              while ((msg = br.readLine()) != null){
                  System.out.println("服务端收到：【 "+msg+" 】");
              }
  
          } catch (IOException e) {
              throw new RuntimeException(e);
          }
      }
  }
  ```

- Client

  ```java
  public class Client {
      public static void main(String[] args) throws IOException {
          Socket socket = new Socket("127.0.0.1", 8848);
          OutputStream outputStream = socket.getOutputStream();
          PrintStream ps = new PrintStream(outputStream);
          Scanner scanner = new Scanner(System.in);
          while (true) {
              System.out.print("请说：");
              ps.println(scanner.next());
              ps.flush();
          }
      }
  }
  ```



### 接收多个客户端

- Server：多线程

  ```java
  public class Server {
      public static void main(String[] args) {
          try {
              ServerSocket server = new ServerSocket(8848);
              System.out.println("服务端已启动");
              while (true){
                  Socket socket = server.accept();
                  // 开启线程
                  new Thread(() -> {
                      try {
                          InputStream is = socket.getInputStream();
                          BufferedReader br = new BufferedReader(new InputStreamReader(is));
                          String msg;
                          while ((msg = br.readLine()) != null){
                              System.out.println("服务端收到"+Thread.currentThread()+"的消息：【 "+msg+" 】");
                          }
                      }catch (IOException e) {
                          throw new RuntimeException(e);
                      }
                  }).start();
              }
          } catch (IOException e) {
              throw new RuntimeException(e);
          }
      }
  }
  ```

- Client



### 伪异步

- Server：线程池

- Client



### 文件传输

- Server

  ```java
  public class Server {
      public static void main(String[] args) {
          try {
              ServerSocket server = new ServerSocket(8848);
              Socket socket = server.accept();
              DataInputStream dis = new DataInputStream(socket.getInputStream());
              String suffix = dis.readUTF();
              System.out.println(suffix);
              // 读取文件 ...
  
          }catch (Exception e){
              e.printStackTrace();
          }
      }
  }
  ```

- Client

  ```java
  public class Client {
      public static void main(String[] args) {
          File file = new File("D:\\picture\\4823e7c.31a80e298383812fe498b567.png");
          String fileName = file.getName();
          String[] split = fileName.split("\\.");
  
          try(InputStream is = new FileInputStream(file);) {
              Socket socket = new Socket("127.0.0.1", 8848);
              DataOutputStream dos = new DataOutputStream(socket.getOutputStream());
              dos.writeUTF(split[split.length-1]);
              byte[] buffer = new byte[1024];
              int len;
              while ((len = is.read(buffer)) != -1){
                  dos.write(buffer, 0, len);
              }
              dos.flush();
              dos.close();
              // 及时关闭通道
              socket.shutdownOutput();
          }catch (Exception e){
              e.printStackTrace();
          }
      }
  }
  ```

  

### 端口转发

- Server

  ```java
  public class Server {
      // 定义一个静态集合，用来存储在线的socket
      private static List<Socket> socketsOnline = new ArrayList<>();
  
      public static void main(String[] args) {
          try {
              ServerSocket server = new ServerSocket(8848);
              System.out.println("服务器启动");
              while (true){
                  Socket socket = server.accept();
                  Server.socketsOnline.add(socket);
                  new Thread(() -> {
                      try {
                          BufferedReader br = new BufferedReader(new InputStreamReader(socket.getInputStream()));
                          String msg;
                          while ((msg = br.readLine()) != null){
                              // 服务端接收到客户端的消息后，推送给所有在线的客户端
                              for (Socket socketOnline : Server.socketsOnline) {
                                  PrintStream printStream = new PrintStream(socket.getOutputStream());
                                  printStream.println(msg);
                                  printStream.flush();
                              }
                          }
                      }catch (Exception e){
                          // 捕获到连接重置异常后表示有人下线
                          System.out.println(socket+" 客户端用户下线");
                          Server.socketsOnline.remove(socket);
                      }
                  }).start();
              }
  
          } catch (IOException e) {
              throw new RuntimeException(e);
          }
      }
  }
  ```

- Client





## NIO

### Buffer

#### 常用API

- 缓冲区操作

  - Buffer clear()：清空缓冲区，切换为写模式，并返回对缓冲区的引用
  - Buffer compact()：清空position指针前的数据，切换为写模式
  - Buffer flip()：将 limit 的位置设置到 position 上，并将 position 的位置改为0
  - int capacity()：返回 Buffer 的 capacity 大小
  - boolean hasRemaining()：判断缓冲区中是否还有元素
  - int limit()：返回 Buffer 的 limit 的位置
  - Buffer limit(int n)：设置 limit 为n，并返回对缓冲区的引用
  - Buffer mark()：对缓冲区设置标记
  - int position()：返回 position 的位置
  - Buffer position(int n)：设置 position 的位置，并返回对缓冲区的引用
  - int remaining()：返回 position 和 limit 间的元素个数
  - Buffer reset()：将位置 position 转到之前设置的 mark 位置上
  - Buffer rewind()：将 position 设置为0，取消之前的 mark
  
- 数据操作

  - byte get()：读取单个字节
  - ByteBuffer get(byte[] dst)：批量读取多个字节到 dst 中
  - byte get(int index)：读取指定索引位置的字节（不会移动position）
  - ByteBuffer put(byte b)：将单个字节写到 position 位置上
  - ByteBuffer put(byte[] src)：将src中的字节写入到 position 位置上
  - ByteBuffer put(int index, byte b)：将指定字节写入的索引位置上（不会移动position）
  
- 字符串和Buffer的相互转换

  - 字符串 -> ByteBuffer

    ```java
    byteBuffer.put("你好，世界！".getBytes(StandardCharsets.UTF_8));
    ByteBuffer buffer = StandardCharsets.UTF_8.encode("你好，世界");
    ByteBuffer buffer = ByteBuffer.wrap("你好，世界！".getBytes(StandardCharsets.UTF_8));
    ```

  - ByteBuffer -> 字符串

    ```java
    CharBuffer charBuffer = StandardCharsets.UTF_8.decode(buffer);
    String string = charBuffer.toString();
    ```

    





#### 直接内存缓冲区

- 非直接内存作用链
  - 本地IO -> 直接内存 -> 非直接内存 -> 直接内存 -> 本地IO
- 直接内存作用链
  - 本地IO -> 直接内存 -> 本地IO
- 直接内存效率更高，但申请慢，需要及时关闭
- API
  - 创建直接内存：Buffer.allocateDirect(int bytes);
  - 判断是否是直接内存：buffer.isDirect();





### Channel

#### 概述

- 类似于Stream流，但channel是双向的
- 用于在缓冲区和位于通道另一侧的实体间的数据传输
- 通道依赖于缓冲区，从而可以实现异步读写数据
- channel实现
  - FileChannel：从文件中读写数据
  - DatagramChannel：能通过UDP读写网络中的数据
  - SocketChannel：能通过TCP读写网络中的数据
  - ServerSocketChannel：可以监听新来的TCP连接，类似于web服务器，对每个新进来的连接都会创建一个SocketChannel
- 支持通道的类（调用getChannel()方法）
  - FileInputStream、FileOutputStream
  - RandomAccessFile
  - DatagramSocket
  - Socket、ServerSocket



#### 常用API

- FileChannel
  - int read(ByteBuffer dst)：从 channel 中读取数据到 ByteBuffer
  - long read(ByteBuffer[] dsts)：将 Channel 中的数据“分散”到 ByteBuffer[]中
  - int write(ByteBuffer src)：将 ByteBuffer 中的数据写入到 channel
  - long write(ByteBuffer[] srcs)：将 ByteBuffer[] 中的数据“聚集”到 channel
  - long positon()：返回此通道的文件位置
  - FileChannel position(long p)：设置此通道的文件位置
  - long size()：返回此通道的文件当前大小
  - FileChannel truncate(long s)：将此通道的文件截取为给定大小
  - void force(boolean metaData) ：强制将所有对此通道的文件更新写入到存储设备中
  - long transferFrom(ReadableChannel str, long position, long count)
  - long transferTo(long position, long, count, WritableByteChannel target)：拷贝channel中的数据，若数据超过 2g ，需要多次传输

- Path

  ```java
  Path path1 = Paths.get("d:/1.txt");
  Path path2 = Paths.get("d:\\data");
  
  // 支持 . 和 ..
  Path path3 = Paths.get("./../bbb/bbb.txt");
  Path normalize = path.normalize();
  ```

- Files

  ```java
  // 检查文件是否存在
  Files.exists(path);
  
  // 创建一级目录，若目录已存在，或是多级目录，都会报错
  Files.createDirectory(path);
  // 创建多级目录
  Files.createDirectorys(path);
  
  // 拷贝文件
  Files.copy(sourcePath, targetPath); // 若文件已存在，报异常
  Files.copy(sourcePath, targetPath, StandardCopyOption.REPLACE_EXISTING); // 覆盖
  
  // 移动文件
  Files.move(sourcePath, targetPath, StandardCopyOption.ATOMIC_MOVE); // 保证文件移动时的原子性
  
  // 删除文件
  Files.delete(targetPath); // 文件不存在，会报错；如果文件为目录，若目录中还有内容，也会报错
  ```

  ```java
  // 遍历目录
  Files.walkFileTree(path, new FileVisitor<Path>() {
      @Override
      public FileVisitResult preVisitDirectory(Path dir, BasicFileAttributes attrs) throws IOException {
          return null;
      }
  
      @Override
      public FileVisitResult visitFile(Path file, BasicFileAttributes attrs) throws IOException {
          return null;
      }
  
      @Override
      public FileVisitResult visitFileFailed(Path file, IOException exc) throws IOException {
          return null;
      }
  
      @Override
      public FileVisitResult postVisitDirectory(Path dir, IOException exc) throws IOException {
          return null;
      }
  });
  ```





### Selector

#### 概述

- Selector 是 SelectableChannle 对象的多路复用器，Selector 可以同时监听控制多个 SelectableChannel 的 IO 事件
- Selector 是非阻塞 IO 的核心
- 不必为每个连接都创建一个线程，避免了多线程间上下文切换导致的开销





### 网络通信

#### 服务端流程

- 创建服务器

  ```java
  ServerSocketChannel sschannel = ServerSocketChannel.open();
  ```

- 切换非阻塞模式（在注册选择器前设置阻塞模式）

  ```java
  sschannel.configureBlocking(false);
  ```

- 绑定监听端口

  ```java
  ssChannel.bind(new InetSocketAddress(8080));
  ```

- 获取连接器

  ```java
  Selector selector = Selector.open();
  ```

- 将通道注册到选择器上，并且指定“监听接收事件”

  ```java
  SelectionKey sscKey = sschannel.register(selector, SelectionKey.OP_ACCEPT);
  ```

  - 监听接收事件
    - 读：SelectionKey.OP_READ（1）
    - 写：SelectionKey.OP_WRITE（4）
    - 连接：SelectionKey.OP_CONNECT（8）
    - 接收：SelectionKey.OP_ACCEPT（16）
    - 多个事件可用 "|" 来连接

- 轮询式获取选择器上已经“准备就绪”的事件

  ```java
  ByteBuffer byteBuffer = ByteBuffer.allocate(1024);
  while (selector.select() > 0) {
      Iterator<SelectionKey> iterator = selector.selectedKeys().iterator();
      while (iterator.hasNext()) {
          SelectionKey selectionKey = iterator.next();
          if (selectionKey.isAcceptable()) {
              SocketChannel socketChannel = ssc.accept();
              log.info("接收到连接请求，socketChannel：{}", socketChannel);
              // 客户端channel设置为非阻塞后，read方法将不再阻塞，如果没读到数据，将返回0
              socketChannel.configureBlocking(false);
              socketChannel.register(selector, SelectionKey.OP_READ);
          }else if (selectionKey.isReadable()) {
              try {
                  SocketChannel socketChannel = (SocketChannel) selectionKey.channel();
                  int len = 0;
                  while((len = socketChannel.read(byteBuffer)) > 0){
                      byteBuffer.flip();
                      String string = StandardCharsets.UTF_8.decode(byteBuffer).toString();
                      // 此处可能产生消息边界问题
                      log.info("处理收到的数据【{}】", string);
                      byteBuffer.clear();
                  }
                  if (len == -1) {
                      log.info("客户端关闭");
                      selectionKey.cancel();
                  }
              }catch (IOException e) {
                  log.warn(e.getMessage());
                  selectionKey.cancel();
              }
          }
          // 如果不移出，下一次迭代器遍历时，该key仍保留在集合中，可能导致空指针异常
          iterator.remove();
      }
  }
  ```

- 消息边界问题处理方案（半包、黏包）

  - 服务器和客户端约定最大传输长度，接收端根据长度划分ByteBuffer空间

  - 将传输的数据按分隔符进行拆分

    - 缺点：效率低

    - 问题：

      > 若存在一段无法拆分且数据量大的数据，接收端无法通过一次read读取完，此时会触发两次或多次读取事件。

      > 若大文件在触发第一次读事件时扩容，则需要将 ByteBuffer 对象提出处理区域，供每次处理时调用，才能允许内部数据不被清除；但若简单从作用域中提出，则可能导致不同的处理事件共享包含残留数据的 ByteBuffer 对象，从而导致数据混乱

      > 简单解决：利用附件，可为每一个 SelectionKey 对象（每个事件）绑定一个 ByteBuffer 对象作为附件。这样，同一事件使用的是相同的 ByteBuffer 对象，不同事件也不会混用该对象

      ```java
      SelectionKey key = oneChannel.register(选择器, 事件类型, byteBuffer(附件));
      ```

      ```java
      // 获取附件
      ByteBuffer byteBuffer = (ByteBuffer) key.attachment();
      ```

      ```java
      // 先进行拆分，拆分后，存在某段数据仍大于接收的byteBuffer容量，再扩容
      if (byteBuffer.position() == byteBuffer.limit()) {
          ByteBuffer newBuffer = ByteBuffer.allocate(bytebuffer.capacity()*2);
          byteBuffer.flip();
          newBuffer.put(byteBuffer);
          key.attach(newBuffer);
      }
      ```

      



#### 客户端流程

- 获取通道

  ```java
  SocketChannel sChannel = SocketChannel.open(new InetSocketAddress("127.0.0.1",8080));
  ```

- 切换非阻塞模式

  ```java
  sChannel.configureBlocking(false);
  ```

- 分配指定大小的缓冲区

  ```java
  ByteBuffer buf = ByteBuffer.allocate(1024);
  ```

- 发送数据给服务端

  ```java
  Scanner scanner = new Scanner(System.in);
  while(scanner.hasNext()){
      System.out.println("请输入：");
      String str = scanner.nextLine();
      buf.put((new SimpleDateFormat("yyyy/MM/dd HH:mm:ss").format(System.currentTimeMillis())+"/n"+str).getBytes());
      buf.flip();
      sChannel.write(buf);
      buf.clear();
  }
  ```





## Netty

### 快速入门

- 引入依赖

  ```xml
  <dependency>
      <groupId>io.netty</groupId>
      <artifactId>netty-all</artifactId>
      <version>4.1.95.Final</version>
  </dependency>
  ```

- Server

  ```java
  // 启动器，负责组装 netty 组件，启动服务器
  new ServerBootstrap()
      // BossEventLoop, WorkerEventLoop(selector, thread), group 组
      .group(new NioEventLoopGroup())
      // 选择服务器的 ServerSocketChannel 实现
      .channel(NioServerSocketChannel.class)
      // boss 负责处理连接; worker(child) 负责处理读写
      // handler 规定了 worker(child) 执行的操作
      .childHandler(
      // 是一个用来初始化的 handler，负责添加别的 handler
      new ChannelInitializer<NioSocketChannel>() {
          @Override
          protected void initChannel(NioSocketChannel nsc) throws Exception {
              // 添加具体的 handler
              // 将 ByteBuf 转换为字符串
              nsc.pipeline().addLast(new StringDecoder());
              // 自定义 handler
              nsc.pipeline().addLast(new ChannelInboundHandlerAdapter() {
                  @Override
                  // 读事件处理方案
                  public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception {
                      // 打印上一步转换好的字符串
                      log.info("接收到信息：【{}】", msg);
                  }
              });
          }
      })
      .bind(8080);
  ```

- Client

  ```java
  new Bootstrap()
      // 添加 EventLoop
      .group(new NioEventLoopGroup())
      // 选择客户端 channel 实现
      .channel(NioSocketChannel.class)
      // 添加处理器
      .handler(new ChannelInitializer<NioSocketChannel>() {
          @Override
          protected void initChannel(NioSocketChannel nioSocketChannel) throws Exception {
              nioSocketChannel.pipeline().addLast(new StringEncoder());
          }
      })
      // 异步非阻塞，main 线程调用该方法，但实际执行 连接操作 的是 EventLoopGroup 中的线程
      .connect(new InetSocketAddress("localhost", 8080))
      // main 线程阻塞，直到其他线程建立完连接
      .sync()
      .channel()
      .writeAndFlush("你好，世界！");
  ```
  
  

### 组件

#### EventLoop

> EventLoop 本质是一个单线程线程池（同时维护了一个 Selector），里面有 run 方法处理 Channel 上源源不断的 io 事件

> 它的继承关系比较复杂
>
> > 一条是继承自 J.U.C.ScheduledExecutorService，因此可执行定时任务
>
> > 另一条是继承自 netty 自己的 OrderedEventExecutor

- 创建 EventLoopGroup

  ```java
  // 可处理 io事件，普通任务，定时任务
  // 若不指定创建的 EventLoop 数，默认创建 核心数*2 个
  EventLoopGroup group = new NioEventLoopGroup(2);
  
  // 可处理 普通任务，定时任务
  EventLoopGroup group = new DefaultEventLoopGroup();
  ```

- 获取下一个 EventLoop

  ```java
  // 若指定 group 为2个 EventLoop
  EventLoop eventLoop1 = group.next();
  EventLoop eventLoop2 = group.next();
  EventLoop eventLoop3 = group.next();
  log.info("是否为同一个对象：{}", eventLoop1 == eventLoop3); // true
  ```

- 执行任务

  - 普通任务

    > group.next().submit(Runnable task)

    > group.next().execute(Runnable task)

  - 定时任务

    > group.next().scheduleAtFixedRate(Runnable task, int initialDelay, int period, TimeUnit unit)

  - IO任务

    ```java
    new ServerBootstrap()
        .group(new NioEventLoopGroup())
        .channel(NioServerSocketChannel.class)
        .childHandler(
        new ChannelInitializer<NioSocketChannel>() {
            @Override
            protected void initChannel(NioSocketChannel nsc) throws Exception {
                // 自定义 handler
                nsc.pipeline().addLast(new ChannelInboundHandlerAdapter() {
                    @Override
                    // 读事件处理方案
                    public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception {
                        // 处理IO任务
                        ByteBuf byteBuf = (ByteBuf) msg;
                        String str = byteBuf.toString(StandardCharsets.UTF_8);
                        log.info("收到的信息：【{}】", str);
                    }
                });
            }
        })
        .bind(8080);
    ```

- eventLoop 分工细化

  - 细分1：职责划分

    > boss 只负责 ServerSocketChannel 上的 accept 事件

    > worker 只负责 SocketChannel 上的 读写 事件

    ```java
    new ServerBootstrap()
        // 指定 boss 和 worker 各自的 group
        .group(new NioEventLoopGroup(1), new NioEventLoopGroup())
        . ...
    ```

  - 细分2：创建一个独立的 EventLoopGroup 用来处理一些耗时操作

    ```java
    // 创建一个独立的 group
    EventLoopGroup group = new DefaultEventLoopGroup(2);
    
    new ServerBootstrap()
        .group(new NioEventLoopGroup(), new NioEventLoopGroup(2))
        .channel(NioServerSocketChannel.class)
        .childHandler(
        new ChannelInitializer<NioSocketChannel>() {
            @Override
            protected void initChannel(NioSocketChannel nsc) throws Exception {
                // 自定义 handler1
                nsc.pipeline().addLast("handler1", new ChannelInboundHandlerAdapter() {
                    @Override
                    public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception {
                        ByteBuf byteBuf = (ByteBuf) msg;
                        String str = byteBuf.toString(StandardCharsets.UTF_8);
                        log.info("收到的信息：【{}】", str);
                        // 再将消息传递给下一个 handler 进行处理
                        ctx.fireChannelRead(msg);
                    }
                });
                
                // 该 handler 所指定的任务，交由独立出的 group 里的线程进行处理
                nsc.pipeline().addLast(group, "handler2", new ChannelInboundHandlerAdapter() {
                    @Override
                    public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception {
                        log.info("处理一些耗时操作");
                    }
                });
            }
        })
        .bind(8080);
    ```

  



#### Channel

- 常用方法

  - close()：关闭 channel
  - pipeline()：添加处理器
  - write()：将数据写入
  - writeAndFlush()：将数据写入并刷出
  - closeFuture()：获得 CloseFuture 对象

- ChannelFuture

  ```java
  ChannelFuture channelFuture = new Bootstrap()
                  .group(...)
                  .channel(...)
                  .handler(...)
      // 异步非阻塞，main 线程调用 connect()，但实际执行 连接操作 的是 EventLoopGroup 中的线程
                  .connect(...);
  ```

  - sync()：作用是同步等待连接完成

    ```java
    // 异步转同步。main线程阻塞，等待其他线程建立完连接
    ChannelFuture channelFuture = channelFuture.sync();
    
    // main 线程阻塞结束后，开启通道，传递数据
    Channel channel = channelFuture1.channel();
    channel.writeAndFlush("你好，世界！");
    ```

  - addListener()：是异步等待连接完成

    ```java
    // mian 线程不阻塞，由其他线程建立完连接后开启通道，传递数据
    channelFuture.addListener(new ChannelFutureListener() {
        @Override
        public void operationComplete(ChannelFuture channelFuture) throws Exception {
            Channel channel = channelFuture.channel();
            channel.writeAndFlush("你好，世界！");
        }
    });
    ```

- closeFuture()：用来处理 channel 的关闭

  ```java
  ChannelFuture closeFuture = channel.closeFuture();
  // channel 的关闭也是一个异步操作，由 main 线程调用，由其他线程真正执行关闭
  channel.close();
  ```

  - sync()：作用是同步等待 channel 关闭

    ```java
    // 异步转同步
    closeFuture.sync();
    log.info("执行后续操作");
    ```

  - addListener()：是异步等待 channel 关闭

    ```java
    closeFuture.addListener(new ChannelFutureListener() {
        @Override
        public void operationComplete(ChannelFuture channelFuture) throws Exception {
            log.info("执行后续操作");
        }
    });
    ```

- 完全停止客户端

  > channel 真正关闭后，客户端程序仍无法停止，原因是 EventLoopGroup 中仍有线程在执行，可调用 EventLoopGroup 对象的 shutdownGracefully() 方法优雅停止线程（拒绝新任务，执行完已有任务）





#### Future Promise

> netty Future 继承 jdk Future

> netty Promise 继承 netty Future

-  jdk Future
  - cancel()：取消任务
  - isCanceled()：任务是否取消
  - isDone()：任务是否完成，不能区分成功失败
  - get()：获取任务结果，阻塞等待
- netty Future
  - getNow()：获取任务结果，若还未产生，返回null
  - sync()：等待任务结束，如果任务失败，抛出异常
  - await()：等待任务结束，如果任务失败，不会抛出异常，而通过 isSuccess() 判断
  - isSuccess()：判断任务是否成功
  - cause()：获取失败信息，非阻塞，如果尚未失败，返回null
  - addLinstener()：添加回调
- netty Promise\<T>：一个存放结果的容器
  - setSuccess(T t)：设置成功结果
  - setFailure(Throwable cause)：设置失败结果





#### Handler

> ChannelHandler 用来处理 Channel 上的各种事件，分为入站、出站两种。所有 ChannelHandler 被连成一串，就是 Pipeline

> 入站Handler 通常是 ChannelInboundHandlerAdapter 的子类，主要用来读取客户端数据，写回结果

> 出站Handler 通常是 ChannelOutBoundhandlerAdapter 的子类，主要对写回结果进行加工

```java
new ServerBootstrap()
    .group(...)
    .channel(...)
    .childHandler(
    new ChannelInitializer<NioSocketChannel>() {
        @Override
        protected void initChannel(NioSocketChannel nsChannel) throws Exception {
            // 获得 pipeline
            ChannelPipeline pipeline = nsChannel.pipeline();
            
            // 添加处理器
            // 处理顺序（双向链表）：head <=> h1 <=> h2 <=> h3 <=> h4 <=> tail
            // 入站顺序：head -> handler1 -> handler2 -> tail
            // 出站顺序：tail -> handler4 -> handler3 -> head
            pipeline.addLast("handler1", new ChannelInboundHandlerAdapter() {
                @Override
                public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception {
                    // 使用pipeline的channel会从tail处理器向前找出站处理器进行处理
                    nsChannel.writeAndFlush(...);
                    // 使用handler的channel会从当前处理器向前找出站处理器进行处理
                    ctx.writeAndFlush(...);
                    
                    // 再将消息传递给下一个 handler 进行处理
                    ctx.fireChannelRead(msg); // super.channelRead(ctx, msg);
                }
            });
            pipeline.addLast("handler2", 入站handler2);
            pipeline.addLast("handler3", 出站handler3);
            pipeline.addLast("handler4", 出站handler4);
        }
    })
    .bind(...);
```

- 基础 Handler

  - 通用处理器：ChannelInboundHandlerAdapter

  - 专注处理器：SimpleChannelInboundHandler\<ByteBuf>

    > Object msg 的实际类型是 ByteBuf 的，会进入该处理器

  - 日志处理器：new LoggingHandler(LogLevel.INFO)



#### ByteBuf

- 创建

  ```java
  // 创建直接内存ByteBuf，若不指定容量，默认为256
  ByteBuf buffer = ByteBufAllocator.DEFAULT.buffer();
  ByteBuf buffer = ByteBufAllocator.DEFAULT.buffer(int capacity);
  ByteBuf buffer = ByteBufAllocator.DEFAULT.buffer(int capacity, int maxCapacity);
  
  // 创建堆内存、直接内存ByteBuf，若不指定容量，默认为256
  ByteBuf byteBuf = ByteBufAllocator.DEFAULT.heapBuffer(int capacity);
  ByteBuf byteBuf = ByteBufAllocator.DEFAULT.directBuffer(int capacity);
  
  System.out.println(byteBuf.getClass());
  ```

  - 池化：可以重用 ByteBuf

  - 启停：

    - 使用代码：Unpooled.buffer();

    - 配置参数：-Dio.netty.allocator.type=unpolled/polled

    - 4.1 前，池化功能不成熟，默认是非池化

    - 4.2 后，非Android平台默认启用池化

- 指针

  - 读指针
  - 写指针

  > 读指针 到 写指针 间可读
  >
  > 写指针 到 剩余部分边界 可写

- 部分方法

  - readInt()：一次性读取4个字节，并转换为 int

  - writeBytes(byte[] src)：写入 byte[]

  - int writeCharSequence(CharSequence s, Charset charset)

    > CharSequence 是 String 的父类，写入字符串时需要指定字符集

- 扩容

  - ByteBuf 在容量不够时，会自动扩容

    - 如果写入后的数据大小未超过512，则会选择扩容到下一个16的整数倍，如写入后是17，若扩容，会扩容到32

    - 如果写入后的数据大小超过512，则会选择下一个2^n^

    - 扩容不能超过指定的 maxCapacity，否则会报错

- 释放

  - 释放原理

    - 每个 ByteBuf 对象的初始计数为 1
    - 调用 release 方法后计数减1，如果计数为0，ByteBuf内存被回收
    - 调用 retain 方法后计数加1，调用该方法后，其他线程调用 release 也不会造成回收
    - 当计数为 0 时，底层内存被回收，这时即使 ByteBuf 对象还在，各方法也无法正常使用

  - 释放时机

    - head handler 会在出站；tail hanler 会在入站时，对 ByteBuf 对象进行尝试释放处理

    - 但仍应该在最后一个使用ByteBuf对象的handler中进行释放处理

      > 如：head 和 tail 间若有 handler 将实际为ByteBuf的 Object msg 转变为了实际为String 的 Object msg后继续向下传递，该msg传递到终点处理器时会判断 <font color=red><strong>`msg instanceof ReferenceCounted`</strong></font>，若不是，终点处理器无法强转并释放

- slice()（切片）：零拷贝切片（切片和原始的ByteBuf共享同一块内存）

  ```java
  ByteBuf buffer = ByteBufAllocator.DEFAULT.buffer(6);
  buffer.writeBytes(new byte[]{'a', 'b', 'c', 'd', 'e', 'f'});
  
  // 在切片的过程中，并没有数据的复制
  ByteBuf slice1 = buffer.slice(0, 3);
  slice1.retain(); // 加的是 buffer 的 referenceCount
  ByteBuf slice2 = buffer.slice(0, 3);
  
  buffer.release();
  log.info("从切片1中读出一个字节，字节为：{}", (char) slice1.readByte());
  slice1.release(); // 减的是 buffer 的 referenceCount
  // 此时 buffer 的 referenceCount 已减为零，不能再调用 slice2.release();
  // slice2.release();
  ```

  - 切片后，将对切片进行容量限制

  - 原始ByteBuf对象 的 release 将对切片造成影响

    - 调用切片的 retain 方法。

      > 无论是调用 源ByteBuf 还是 切片 的release、retain方法，计算的都是 源ByteBuf 的引用计数

    - 将 切片 内存转化为非共享的内存

      ```java
      ByteBuf slice1 = buffer.slice(0, 3);
      ByteBuf byteBuf = ByteBufAllocator.DEFAULT.buffer().writeBytes(slice1);
      ```

- duplicate()：零拷贝复制（复制出的ByteBuf与原始的ByteBuf完全共用一块内存，没有容量限制）

- copy()：深拷贝（数据复制）





#### Option

- 配置参数

  - 客户端

    ```java
    new ServerBootstrap()
        // 给 ServerSocketChannel 配置参数
        .option()
        // 给 SocketChannel 配置参数
        .childOption()
        . ...
    ```

  - 服务器端

    ```java
    new ServerBootstrap()
        .option()
        . ...
    ```

- 常用参数（ChannelOption.参数名）

  - CONNECT_TIMEOUT_MILLIS
    - 属于 SocketChannal 参数
    - 客户端在建立连接时，若在指定毫秒内无法连接，会抛出 timeout 异常
    - SO_TIMEOUT 主要用在阻塞IO中，阻塞IO的accept、read都是无限等待的，如果不希望永远阻塞，可配置此超时时间
    - 原理：利用线程池定时任务，延期 timeout 执行导致抛出超时异常的任务，若连接上，取消该任务
      - 实际上客户端调用 sync() 方法后，阻塞等待promise结果；
      - 到达超时时间时，在定时任务中向 promise 添加timeout异常结果，sync() 阻塞结束
  - SO_BACKLOG
    - 属于 ServerSocketChannel 参数
    - tcp 3次交互：为了让自己和对方都意识到自己的接收和发送都没问题
      - 半连接队列：尚为完成3次交互的会记录在半连接队列中
        - 上限通过 linux 目录 /proc/sys/net/ipv4/tcp_max_syn_backlog 指定，在 syncookies 启用的情况下，逻辑上没有最大值限制
      - 全连接队列：成功建立连接的会记录在全连接队列中，如果队列满了，server 将发送Connection refused拒绝连接的错误信息到 client
        - 操作系统层限制：上限通过 linux 目录 /proc/sys/net/core/somaxconn 指定
        - 代码层限制：
          - NIO：bind(port: 8080, backlog: 4069)
          - Netty：配置 SO_BACKLOG
  - TCP_NODELAY：默认关闭不延迟，即开启nagle
    - 属于 SocketChannel 参数
    - nagle 算法
      - 将多个小数据合并为一个大数据，再一起发送
      - 会导致数据延迟发送

  











### 协议

#### 黏包半包

- 黏包

  - 现象：分别发送abc、def，接收到的却是 abcdef

  - 原因
    - 应用层：接收方的 ByteBuf 设置太大
    - 滑动窗口：假设发送方 256 bytes表示一个完整的报文，但由于接收方处理不及时，且窗口大小足够大，这 256bytes 字节就会缓冲在接收方的滑动窗口中，当滑动窗口中缓冲了多个报文就会黏包
    - Nagle算法

- 半包

  - 现象：发送 abcdef ，接收到的是 abc、def
  - 原因
    - 应用层：接收放 ByteBuf 小于实际发送数据量
    - 滑动窗口：接收方窗口只剩 128b ，发送方发送超过 129b 数据，会先发送 128b ，再发送 1b，造成半包
    - MSS限制：Maximum Segment Size，最大报文长度，TCP payload的最大值，TCP协议定义的一个选项，MSS是TCP用来限制应用层最大的发送字节数

- 解决方式

  - 短链接法

    - 客户端若要发送多次消息时，发送一次消息后与服务器断开连接，再建立连接，再发送下一条消息
    - 服务段接收到客户端断开连接后，不会将本次消息与下一次重新连接的客户端发送消息进行粘接

  - 添加 定长消息解码器 FixedLengthFrameDecoder

    - 客户端发送固定长度的消息，不足该长度的，补齐

    - 服务端添加 定长消息解码器

      ```java
      ch.pipeline().addLast(new FixedLengthFrameDecoder(fixedLength: 10));
      ```

  - 分隔符

    - LineBasedFrameDecoder：能解析到 windows 和 linux 的换行符，并作为分隔条件

      > 需要指定一个 maxLength ，若解析消息时，超过该长度，仍未解析到换行符，则报 TooLongFrameException

      - 客户端在发送多条消息后，在每一条消息后加入换行符 '\n' or '\r\n'

      - 服务端添加 解码器

        ```
        ch.pipeline().addLast(new FixedLengthFrameDecoder(maxLength: 1024));
        ```

    - DelimiterBasedFrameDecoder：指定分隔符

  - LengthFieldBaseFrameDecoder

    - 构造方法参数
      - maxFrameLength：最大总长度，单次信息超出该长度报错
      - lengthFieldOffset：长度部分第一个字节位置
      - lengthFieldLength：长度部分的长度
      - lengthAdjustment：长度调节，长度部分后多少个字节才到真正的内容
      - initialBytesToStrip：解析内容时，跳过开头后面多少个字节

    ```java
    // 嵌入式Channel，可用来模拟处理器链处理过程
    EmbeddedChannel channel = new EmbeddedChannel(
        // 若不想解析长度和版本号，initialBytesToStrip 设置为 4+4=8
        new LengthFieldBasedFrameDecoder(1024, 0, 4, 4, 8),
        new ChannelInboundHandlerAdapter() {
            @Override
            public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception {
                if (msg instanceof ByteBuf) {
                    ByteBuf byteBuf = (ByteBuf) msg;
                    log.info("收到的信息是：【{}】", byteBuf.readCharSequence(byteBuf.readableBytes(), StandardCharsets.UTF_8));
                }
                // 若每次接收到的都是新划分的ByteBuf，需要释放
                if (msg instanceof ReferenceCounted)
                    ((ReferenceCounted) msg).release();
            }
        }
    );
    
    AtomicInteger stamp = new AtomicInteger(1);
    Consumer<String> send = (String s) -> {
        ByteBuf byteBuf = ByteBufAllocator.DEFAULT.directBuffer();
        byte[] bytes = s.getBytes(StandardCharsets.UTF_8);
        // 一个Int占四个字节，所以 lengthFieldLength 为4
        byteBuf.writeInt(bytes.length);
        // 模拟在长度部分后，添加一个 Int 的版本。lengthAdjustment 设为4
        byteBuf.writeInt(stamp.getAndIncrement());
        byteBuf.writeBytes(bytes);
        channel.writeInbound(byteBuf);
    };
    
    send.accept("Hello, world!");
    send.accept("你好，世界！");
    ```
    





#### 自定义协议

- 常见协议

  - Redis 协议：以 SET name zhangsan 为例

    ```aof
    *3
    $3
    SET
    $4
    name
    $8
    zhangsan
    ```

  - Http 协议

    ```java
    // Http协议的处理器。HttpServerCodec：HttpRequestDecoder + HttpResponseEncoder
    pipeline.addLast(new HttpServerCodec());
    pipeline.addLast(new ChannelInboundHandlerAdapter() {
        @Override
        public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception {
            log.info("类型为：{}", msg.getClass());
            if (msg instanceof HttpRequest) {
                DefaultFullHttpResponse httpResponse =
                    new DefaultFullHttpResponse(HttpVersion.HTTP_1_0, HttpResponseStatus.OK);
                byte[] bytes = "<h1>Hello!<h1>".getBytes(StandardCharsets.UTF_8);
                httpResponse.headers().setInt(HttpHeaderNames.CONTENT_LENGTH, bytes.length);
                httpResponse.content().writeBytes(bytes);
                nioSocketChannel.writeAndFlush(httpResponse);
            }
            if (msg instanceof LastHttpContent) log.info("LastHttpContent");
            super.channelRead(ctx, msg);
        }
    });
    ```

- <a href="https://www.bilibili.com/video/BV1py4y1E7oA?p=101&vd_source=25ad2de4838bd28372a4956bac63c618">自定义协议</a>

  - 组成部分

    - 魔数：用来第一时间判断是否为无效数据包
    - 版本号：可以支持协议的升级
    - 序列化算法：支持正文到底采用哪种序列化反序列化方式，如json
    - 请求类型：是登录、注册、...
    - 请求序号：用于双工通信下，确定多个请求的顺序
    - 正文长度
    - 正文

  - 消息

    ```java
    @Data
    public abstract class MyMessage implements Serializable {
        private int messageType;
        priavte int sequenceId;
        
        // 定义子类的一些细分类型，供子类返回
        public static final int LoginRequestMessage = 0;
        public static final int LoginResponseMessage = 1;
        public static final int ChatRequestMessage = 3;
        public static final int ChatResponseMessage = 4;
        
        // 子类实现该方法，并返回自己的类型
        public abstract int getMessageType();
        
        private static final Map<Integer, Class<?>> messageClasses = new HashMap<>();
        
        static {
            messageClasses.put(LoginRequestMessage, LoginRequestMessage.class);
            messageClasses.put(LoginResponseMessage, LoginResponseMessage.class);
            ......
        }
        
        public static Class<?> getMessageClass(int messageType) {
            return messageClasses.get(messageType);
        }
    }
    ```
  
  - 处理器编码
  
    ```java
    @Sharable
    public class MyProtocolCodec extends ByteToMessageCodec<MyMessage> {
        @Override
        protected void encode(ChannelHandlerContext chc, MyMessage msg, ByteBuf byteBuf) throws Exception {
            // 将 魔数、版本号。。。msg 写入到 ByteBuf 中
        }
    
        @Override
        protected void decode(ChannelHandlerContext chc, ByteBuf byteBuf, List<Object> list) throws Exception {
            // 将 ByteBuf 转为 魔数、版本号。。。msg
        }
    }
    ```
    
    - @ Sharable 注解：添加在类上，表示该处理器可以被共享
      - LoggingHandler：没有记录状态信息，可以被共享
      - LengthFieldBasedFrameDecoder：由于记录了半包数据等状态信息，不能被多线程共享
    
  - 拓展序列化算法
  
    ```java
    public interface Serializer {
        <T> byte[] serialize(T t);
    
        <T> T deserialize(Class<T> clazz, byte[] bytes);
    
        enum Algorithm implements Serializer{
            JDK {
                @Override
                public <T> byte[] serialize(T t) {
                    return new byte[0];
                }
    
                @Override
                public <T> T deserialize(Class<T> clazz, byte[] bytes) {
                    return null;
                }
            },
            JSON {
                ......
            }
        }
    }
    ```





#### RPC

- RpcRequestMessage

  ```java
  @Getter
  public class RpcRequestMessage extends MyMessage {
      // 调用的接口全限定名，服务端根据它找到实现
      private String interfaceName;
      // 调用接口中的方法名
      private String methodName;
      // 方法返回类型
      private Class<?> returnType;
      // 方法参数类型数组
      private Class[] parameterTypes;
      // 方法参数值数值
      private Object[] parameterValue;
      
      public RpcRequestMessage(...){...}
      
      @Override
      public int getMessageType() {
          return RPC_MESSAGE_TYPE_REQUEST;
      }
  }
  ```









# JUC



## 常用API

### Thread

| 方法名                 | 说明                                                         |
| ---------------------- | ------------------------------------------------------------ |
| start()                | 启动一个新线程                                               |
| run()                  | 启动新线程后，新线程调用的方法                               |
| join()                 | 调用该方法的线程等待该方法所属线程运行结束                   |
| join(long n)           | 最多等待 n 毫秒                                              |
| getId()                | 获得线程 long 型的唯一id                                     |
| getName()              | 获取线程名                                                   |
| setName(String)        | 修改线程名                                                   |
| getPriority()          | 获取线程优先级                                               |
| setPriority(int)       | 修改线程优先级                                               |
| getState()             | 获取线程状态：new runnable blocked waiting timed_waiting treminated |
| setDaemon              | 是否将所属线程设置为守护线程                                 |
| isAlive()              | 线程是否存活                                                 |
| interrupt()            | 打断所属线程，如果被打断线程正在 sleep、wait、join 会导致被打断的<br/>线程抛出InterruptedException ，并清除打断标记；如果被打断的线程<br/>正在运行，则会为被打断的线程设置打断标记，不会直接打断线程 |
| isInterrupted()        | 获取所属线程是否被设置打断标记，获取后不会清除打断标记       |
| static interrupted()   | 获取调用线程是否被设置打断标记，获取后会清除打断标记         |
| static currentThread() | 获取当前正在运行的线程                                       |
| static sleep(long n)   | 休眠 n 毫秒，休眠期间让出CPU资源                             |
| static yield()         | 提示线程调度器让出调用线程对CPU的使用                        |

- 两阶段终止模式

  ```java
  @Slf4j
  public class InterruptTest {
      public static void main(String[] args) throws InterruptedException {
          Thread thread = new Thread(() -> {
              while (true) {
                  if (Thread.interrupted()) {
                      log.info("释放资源、锁等");
                      break;
                  }
                  log.info("执行循环任务");
                  try {
                      Thread.sleep(2000);
                  } catch (InterruptedException e) {
                      log.warn("休眠期间被打断");
                      Thread.currentThread().interrupt();
                  }
              }
          });
          thread.start();
          Thread.sleep(5000);
          thread.interrupt();
      }
  }
  ```





### Stack

| 常用方法             | 作用                                     |
| -------------------- | ---------------------------------------- |
| boolean empty()      | 判断栈是否为空                           |
| E peek()             | 返回栈顶部的对象，但不从栈中移出         |
| E pop()              | 返回栈顶部的对象，并从栈中移出           |
| E push(E item)       | 把对象压入栈中                           |
| int search(Object o) | 返回对象在堆栈中的位置，若不存在则返回-1 |



### Queue

| 常用方法           | 作用                                                 |
| ------------------ | ---------------------------------------------------- |
| boolean add(E e)   | 在队列尾部插入一个元素，若队列已满，抛出异常         |
| boolean offer(E e) | 在队列尾部插入一个元素，若队列已满，只返回false      |
| E element()        | 返回队列头部的对象，但不从队列中移出，若空，抛异常   |
| E peek()           | 返回队列头部的对象，但不从队列中移出，若空，返回null |
| E remove()         | 返回队列头部的对象，并从队列中移出，若空，抛异常     |
| E poll()           | 返回队列头部的对象，并从队列中移出，若空，返回null   |



### BlockingQueue

- 放入数据

  - offer(anObject):表示如果可能的话,将anObject加到BlockingQueue里,即如果BlockingQueue可以容纳,则返回true,否则返回false.（本方法不阻塞当前执行方法的线程）；　　　　　　 

  - offer(E o, long timeout, TimeUnit unit)：可以设定等待的时间，如果在指定的时间内，还不能往队列中加入BlockingQueue，则返回失败。

  - put(anObject):把anObject加到BlockingQueue里,如果BlockQueue没有空间,则调用此方法的线程被阻断直到BlockingQueue里面有空间再继续.

- 获取数据

  - poll(time):取走BlockingQueue里排在首位的对象,若不能立即取出,则可以等time参数规定的时间,取不到时返回null;
  - poll(long timeout, TimeUnit unit)：从BlockingQueue取出一个队首的对象，如果在指定时间内，队列一旦有数据可取，则立即返回队列中的数据。否则知道时间超时还没有数据可取，返回失败。
  - take():取走BlockingQueue里排在首位的对象,若BlockingQueue为空,阻断进入等待状态直到BlockingQueue有新的数据被加入; 
  - drainTo():一次性从BlockingQueue获取所有可用的数据对象（还可以指定获取数据的个数），通过该方法，可以提升获取数据效率；不需要多次分批加锁或释放锁。



### CompletableFuture

- 四种静态方法

  ```java
  // 默认使用 ForkJoin 线程池，ForkJoin 线程池创建的线程是守护线程
  CompletableFuture<Void> static runAsync(Runnable r)
  CompletableFuture<T> static supplyAsync(supplier<T> s)
  
  CompletableFuture<Void> static runAsync(Runnable r, Executor e)
  CompletableFuture<T> static supplyAsync(supplier<T> s, Executor e)
  ```

- 异步调用

  ```java
  completableFuture.get();
  completableFuture
      // 无论是否报错，获得结果后都会进入这个分支
      .whenComplete((t, throwable) -> {
          log.info(t.toString());
      })
      // 报错后还会进入这个分支
      .exceptionally(throwable -> {
          throwable.printStackTrace();
          return t;
      });
  ```



### Cyclicbarrier

```java
AtomicInteger times = new AtomicInteger(1);
CyclicBarrier cyclicBarrier = new CyclicBarrier(2, () -> {
    log.info("第 {} 轮执行完毕", times.getAndIncrement());
});
Runnable r = () -> {
    try {
        int costTime = new Random().nextInt(3);
        TimeUnit.SECONDS.sleep(costTime);
        log.info("执行结束，耗时：{} 秒", costTime);
        cyclicBarrier.await();
    } catch (InterruptedException | BrokenBarrierException e) {
        throw new RuntimeException(e);
    }
};
ExecutorService threadPool = Executors.newFixedThreadPool(2);
for (int i = 0; i < 3; i++) {
    threadPool.submit(r);
    threadPool.submit(r);
}
```

```log
[INFO ] 12:26:39:693   pool-1-thread-1 --->    执行结束，耗时：1 秒
[INFO ] 12:26:40:704   pool-1-thread-2 --->    执行结束，耗时：2 秒
[INFO ] 12:26:40:704   pool-1-thread-2 --->    第 1 轮执行完毕
[INFO ] 12:26:41:719   pool-1-thread-1 --->    执行结束，耗时：1 秒
[INFO ] 12:26:42:715   pool-1-thread-2 --->    执行结束，耗时：2 秒
[INFO ] 12:26:42:715   pool-1-thread-2 --->    第 2 轮执行完毕
[INFO ] 12:26:43:717   pool-1-thread-2 --->    执行结束，耗时：1 秒
[INFO ] 12:26:43:717   pool-1-thread-1 --->    执行结束，耗时：1 秒
[INFO ] 12:26:43:717   pool-1-thread-1 --->    第 3 轮执行完毕
```



### ConcurrentHashMap

```java
ConcurrentHashMap<String, Integer> map = new ConcurrentHashMap<>();

// 错误用法
while ((str = bufferedReader.readLine()) != null && !str.isBlank()) {
    Integer integer = map.get(str);
    integer = integer == null ? 1 : integer + 1;
    map.put(str, integer);
}


while ((str = bufferedReader.readLine()) != null && !str.isBlank()) {
    map.computeIfAbsent(str, s -> 0);
    map.computeIfPresent(str, (s, integer) -> integer+1);
}
// 利用累加器
ConcurrentHashMap<String, LongAdder> map = new ConcurrentHashMap<>();
while ((str = bufferedReader.readLine()) != null && !str.isBlank()) {
    map.computeIfAbsent(str, s -> new LongAdder());
    map.get(str).increment();
}
```











## 共享模型

### 线程安全

常见的线程安全类：String、Integer、StringBuffer、Random、Vector、Hashtable、java.util.concurrent包下的类

```java
@RestController
public class MyController {
    // HashMap 线程不安全，Hashtable 线程安全
    Map<String,Object> map = new Hashmap<>();
    
    @Autowire
    private MyService myService;
}

@Service
public class MyAservice {
    private Integer insertCount = 0;
    
    // 线程不安全
    public void insert() {
        // insert 操作
        inserCount++;
    }
}
```

```java
// 线程安全，因为 service 中的 MyDao 私有，无法修改
@RestController
public class MyController {
    @Autowire
    private MyService myService;
}

// 线程安全，因为 MyDao 中没有成员变量
@Service
public class MyAservice {
    @Autowire
    private MyDao myDao;
}

@Service
public class MyDao {
    @Select
    ....
}
```



### <a href="https://www.bilibili.com/video/BV16J411h7Rd?p=84&spm_id_from=pageDriver&vd_source=25ad2de4838bd28372a4956bac63c618">Synchronized</a>

- 偏向锁：当第一个线程通过 Synchronized 代码块，并且没有其他线程通过该代码块时，锁是偏向锁
- 轻量级锁：当偏向锁有第二个线程错过第一个线程执行代码块，会升级为轻量级锁

- 重量级锁：Monitor

  ![Monitor](D:\picture\typora\java2\Monitor.png)

- 批量重偏向：当撤销偏向锁超过阈值20次，会由偏向A线程变更为偏向B线程
- 批量撤销：当撤销偏向锁超过阈值40次，会撤销偏向锁变为不可偏向锁
- 锁撤销：即时编译器可以对不需要加锁的流程撤销锁
- 锁粗化：可以将多个连续的小锁合并成一个大锁，从而减少锁的竞争次数，提高程序性能。
- obj.wait()：让进入object 监视器的线程到 waitSet 中等待
- obj.notify()：从 waitSet 中挑一个唤醒



### 线程间通讯

- synchronized

  ```java
  public class CommunicationTest {
      public static void main(String[] args) {
          new Thread(() -> {while (true) Message.createBun();}, "生产者1").start();
          new Thread(() -> {while (true) Message.sellBun();}, "消费者1").start();
          new Thread(() -> {while (true) Message.createBun();}, "生产者2").start();
          new Thread(() -> {while (true) Message.sellBun();}, "消费者2").start();
      }
  
  }
  
  @Slf4j
  class Message {
      private static Queue<String> msgQueue = new PriorityQueue<>();
      private static AtomicInteger id = new AtomicInteger();
  
      public static synchronized void createBun() {
          String str = "消息"+("M"+id.incrementAndGet());
          msgQueue.offer(str);
          log.info("向消息队列中添加消息：{}，消息队列：{}", str, msgQueue);
          Message.class.notifyAll();
          try {
              Message.class.wait();
          } catch (InterruptedException e) {
              throw new RuntimeException(e);
          }
      }
  
      public static synchronized void sellBun(){
          if (msgQueue.size() > 0) {
              log.info("取出消息：{}，消息队列：{}", msgQueue.poll(), msgQueue);
          }
          Message.class.notifyAll();
          try {
              Message.class.wait();
          } catch (InterruptedException e) {
              throw new RuntimeException(e);
          }
      }
  }
  ```
  
- Lock 接口

  ```java
  private Lock lock = new ReentrantLock();
  private Condition condition = lock.newCondition();
  public void test() throws RuntimeException {
      lock.lock();
      condition.await();
      condition.signalAll();
      lock.unlock();
  
  }
  ```

- 注意：<font color=red>**线程在哪里进入等待，下次被唤醒将在哪里继续执行**</font>

- 保护性暂停：wait

  ```java
  public class FutureTest {
      public static void main(String[] args) {
          Future future = new Future();
          new Thread(() -> future.calculate(), "计算线程").start();
          Thread.currentThread().setName("结果线程");
          future.getResult();
      }
  }
  
  @Slf4j
  class Future {
      private Object result;
  
      // 因为要通过锁被calculate()唤醒，所以要加和calculate()方法一样的锁
      public synchronized Object getResult() {
          log.info("准备获取结果");
          if (result == null) {
              log.info("尚未得到结果，进入等待");
              try {
                  this.wait();
              } catch (InterruptedException e) {
                  log.info("受到打断请求，但不进行打断操作");
              }
          }
          log.info("得到结果");
          return result;
      }
  
      public synchronized void calculate() {
          try {
              TimeUnit.SECONDS.sleep(1);
          } catch (InterruptedException e) {
              throw new RuntimeException(e);
          }
          result = new Object();
          log.info("已计算出结果");
          this.notifyAll();
      }
  }
  ```
  
- 保护性暂停：pack

  ```java
  public class FutureTest {
      public static void main(String[] args) {
          Future2 future2 = new Future2();
          Thread getResultThread = Thread.currentThread();
          new Thread(() -> future2.calculate(getResultThread), "计算线程").start();
          getResultThread.setName("结果线程");
          // 该线程干了些别的事，可能耗费了比计算结果要更长的时间后，再获取结果
          TimeUnit.SECONDS.sleep(new Random().nextInt(3));
          future2.getResult();
      }
  }
  
  @Slf4j
  class Future2 {
      private Object result;
  
      // 查询线程不需要被锁唤醒，因此也不需要加锁
      public Object getResult() {
          log.info("准备获取结果");
          // 若有锁，park暂停时不会释放锁，因此不能加与calculate()相同的锁
          LockSupport.park();
          log.info("得到结果");
          return result;
      }
  
      public synchronized void calculate(Thread thread) {
          log.info("开始计算");
          try {
              TimeUnit.SECONDS.sleep(1);
          } catch (InterruptedException e) {
              throw new RuntimeException(e);
          }
          result = new Object();
          log.info("已计算出结果");
          // unpark 该线程后，回唤醒该线程park状态，并且即使之后被park，也不会停止
          LockSupport.unpark(thread);
      }
  }
  ```

  - <font color=red>**park 不会释放锁，或者说 park 和 锁 是不相关的，park 是线程上的属性，锁是作为锁的对象上的属性**</font>
  - <font color=red>**unpark 某条正在运行的线程后，会唤醒该线程park状态，若该线程未被park，则下一次park不会停止**</font>
  - <font color=red>**interrupt 可以打断所属线程的park状态，打断后，打断标记为true，打断标记为true时，该线程将无法再被park**</font>



### ReentranLock

- 使用

  ```java
  ReentrantLock reentrantLock = new ReentrantLock();
  reentrantLock.lock();
  try {
      log.info("获取到锁，执行临界区代码")
  } finally {
      reentrantLock.unlock();
  }
  ```

- 可打断锁

  ```java
  try {
      // reentrantLock.lock(); 无法接收打断信号
      reentrantLock.lockInterruptibly();
  } catch (InterruptedException e) {
      log.info("收到打断信号，打断阻塞状态");
      return;
  }
  ```

- 可设置超时时间

  ```java
  if (!reentrantLock.tryLock()){
      log.info("未获取到锁，结束");
      return;
  }
  
  // 支持打断
  try {
      if (!reentrantLock.tryLock(2, TimeUnit.SECONDS)){
          log.info("未获取到锁，结束");
          return;
      }
  } catch (InterruptedException e) {
      log.info("收到打断信号，打断阻塞状态");
      return;
  }
  ```

- 可设置公平锁

  ```java
  // 构造方法中传递是否开启公平锁
  ReentrantLock reentrantLock = new ReentrantLock(true);
  ```

- 支持多个条件变量：可理解为将 WaitSet 分成了多个休息室，线程可以进入指定的休息室等待，也可以唤醒指定休息室的线程

  ```java
  Condition condition1 = reentrantLock.newCondition();
  Condition condition2 = reentrantLock.newCondition();
  
  condition1.await();
  condition.await(1, TimeUnit.SECONDS);
  condition.awaitNanos(10000000);
  condition.awaitUninterruptibly();
  condition.awaitUntil(new Date());
  
  condition1.signal();
  condition1.signalAll();
  ```

- Lock 与 synchronized 的区别

  - Lock 是一个接口；synchronized 是一个关键字
  - synchronized 在发生异常时，会自动释放线程所占有的锁；而 Lock 在发生异常事，如果不主动使用 unlock() 去释放锁，则可能造成死锁现象
  - Lock 的性能优于 synchronized



### 不可变

- 不可变类设计：类和类中的属性都用 final 修饰

  - 属性用 final 修饰，保证了该属性是只读的，不能修改
  - 类用 final 修饰，保证了该类中的方法不能被覆盖，防止子类无意间破坏不可变性

  ```java
  public final class String 
      implements java.io.Serializable, Comparable<String>, CharSequence {
      private final char[] value;
      
      // 私有，外界无法更改
      private int hash;
  }
  ```

- 无状态设计：不设置成员变量

- 保护性拷贝

- 享元模式



### ThreadLocal

- 初始化

  ```java
  class MyStore{
      // 建议使用 static 修饰
      static ThreadLocal count = new ThreadLocal() {
          @Override
          protected Integer initialValue() {
              return 0;
          }
      };
      static ThreadLocal<Integer> count = ThreadLocal.withInitial(() -> 0);
      
      public void sell() {
          count.set(1+count.get());
      }
  }
  ```
  
- 使用

  ```java
  MyStore myStore = new MyStore();
  new Thread(() -> {
      try {
          
      } finally {
          // 线程结束时释放，以防内存泄露
          myStore.count.remove();
      }
  }).start();
  ```

- 内存泄露

  - 引用：内存回收后，引用会被放入指定的ReferenceQueue中
    - 强引用 Reference
    - 软引用 SoftReference：内存充足时不会进行垃圾收集，内存回收；内存不充足时会进行
    - 弱引用 WeakReference：只要垃圾回收机制运行，就会回收该对象占用的内存
    - 虚引用 PhantomReference：虚引用不会决定对象的生命周期，调用get()返回的是null

  - Thread 聚合 ThreadLocal，ThreadLocal 中有一个 ThreadLocalMap 的内部类。调用 ThreadLocal 的 set(value) 方法实际上是将 <font color=red>ThreadLocal 弱引用对象作为 key，value 作为值从而形成的Entry对象</font>存入 ThreadLocalMap 中。
    - 两条引用
      - 线程中 `ThreadLocal tl = new ThreadLocal()` tl指向这个对象是强引用
      - 调用 set() 方法后，新建一个 Entry 对象，Entry对象里的key是弱引用指向这个 ThreadLocal 对象

    - 当第一个中的强引用失效时（如设tl=null），ThreadLocal 对象只剩下弱引用，就会被回收，此时就会形成 Entry 中 key 为 null 而 值依旧存在的状况，此时的值无意义，但有引用无法回收
      - 调用 threadLocal 的 set()、get()、remove() 方法时，都会调用 expungeStaleEntry() 方法，将key为null的值全部置为null从而回收值的内存；其中remove先将key置为null在调用该方法






## 拓展

### JMM

- jvm 规范中试图定义一种 java 内存模型（java memory model）来<font color=red>屏蔽各种硬件和操作系统的内存访问</font>，用以实现 java 程序在各种平台下都<font color=red>能达到一致的内存访问效果</font>
  - 描述的是一组约束和规范，定义了程序（尤其是多线程）各个变量的读写访问方式并决定一个线程对共享变量的写入何时以及如何变为对另一个线程可见
  - 三大特性
    - 原子性
    - 可见性
    - 有序性
- happens-before：先行发生
  - 如果一个操作 happens-before 另一个操作，那么第一个操作的执行结果将对第二个操作可见，而且第一个操作的执行顺序排在第二个操作之前
  - 两个操作之间存在 happens-before 关系，并不意味着一定要按照 happens-before 原则制定的顺序来执行。如果重排序之后的执行结果与按照 happens-before 关系执行的结果一致，那么这种重排序并不非法
  - 8条规则
    - 次序规则：一个线程内，写在前面的操作先行发生于写在后面的操作
    - 锁定规则：unlock操作先行发生于
    - volatile 变量规则：对一个 volatile 变量的写操作先行发生于**后面**对这个变量的读操作
    - 传递规则：A 先行发生于 B，B 先行发生于 C，则 A 先行发生于 C
    - 线程启动规则：线程对象的 start() 方法先行发生于此线程中的每个操作
    - 线程中断规则：对线程 interrupt() 方法的调用先行发生于被中断线程的代码检测到中断的发生
    - 线程终止规则：线程中的所有操作都先行发生于对终止线程的终止检测，如可用 isAlive() 检测是否终止
    - 对象终结规则：一个对象的初始化完成（构造函数的执行结束）先行发生于它的 finalize() 方法



### <a href="https://www.bilibili.com/video/BV1ar4y1x727?p=63&vd_source=25ad2de4838bd28372a4956bac63c618">volatile</a>

- 可见性

  ```java
  public class VisiableTest {
      static volatile boolean flag = true;
      public static void main(String[] args) throws InterruptedException {
          System.out.println("start");
          // 循环体中有sout打印语句，不加volatile也可以保证可见性
          new Thread(() -> {while(flag) {}}).start();
          Thread.sleep(2000);
          System.out.println("设置为false");
          flag = false;
      }
  }
  ```

  - 锁对于其加锁的代码部分，既可以保证原子性，也可以保证可见性
  - 锁对于其加锁的代码部分，保证只有一个线程执行，根据先行发生happens-before原则下的次序规则：一个线程内，写在前面的操作先行发生于写在后面的操作，而先行发生虽然不能保证不发生指令重排，但其保证是否发生指令重排对结果不影响，因此锁也可以保证有序性

- 有序性

  ```java
  public class Singleton {
      private Singleton(){};
      private static Singleton instance = null;
      
      public static Singleton getInstance() {
          if (instance == null) {
              synchronized (Singleton.class) {
                  if (instance == null) {
                      
                      instance = new Singleton();
                      // new：创建对象，将对象引用入栈
                      // dup：复制一份对象引用
                      // invokespecial：创建实例关联对象引用
                      // putstatic :将对象引用赋值给 static instance 
                  }
              }
          }
          return instance;
      }
  }
  ```

  - 若 invokespecial 和 putstatic 指令重排，另一个线程返回的可能是未初始完的实例对象

- 原理：底层实现的原理是内存屏障

  - 对 volatile 变量的写指令后会加入写屏障，写屏障保证在该屏障之前的、对共享变量的改动，都同步到主存中；写屏障之前的代码不会被指令重排的写屏障之后
  - 对 volatile 变量的读指令前会加入读屏障，读屏障保证在该屏障之后的、对共享变量的读取，加载的是主存中最新的数据；读屏障之前的代码不会被指令重排到读屏障之前



### 内存布局

- 对象的堆内存中的存储布局

  - 对象头

    - 对象标记（Mark Word）

      <table>
          <caption>64位虚拟机</caption>
          <tr>
              <td rowspan="2">锁状态</td>
              <td colspan="4">56bit</td>
              <td rowspan="2">1bit</td>
              <td rowspan="2">4bit</td>
              <td rowspan="2">1bit<br/>(是否是偏向锁)</td>
              <td rowspan="2">1bit<br/>(锁标记位)</td>
          </tr>
          <tr>
              <td colspan="2">25bit</td>
              <td colspan="2">31bit</td>
          </tr>
          <tr>
              <td>无锁</td>
              <td colspan="2">unused</td>
              <td colspan="2">对象 hashCode</td>
              <td>Cms_free</td>
              <td>对象分代年龄</td>
              <td>0</td>
              <td>01</td>
          </tr>
          <tr>
              <td>偏向锁</td>
              <td colspan="3">threadId(54bit)</td>
              <td colspan="1">Epoch(2bit)</td>
              <td>Cms_free</td>
              <td>对象分代年龄</td>
              <td>1</td>
              <td>01</td>
          </tr>
          <tr>
              <td>轻量级锁</td>
              <td colspan="7">指向栈中的记录的指针</td>
              <td>00</td>
          </tr>
          <tr>
              <td>重量级锁</td>
              <td colspan="7">指向重量级锁的指针</td>
              <td>10</td>
          </tr>
          <tr>
              <td>GC标志</td>
              <td colspan="7">空</td>
              <td>01</td>
          </tr>
      </table>

    - 类元信息（类型指针、klass Pointer）：指向方法区中某个类的Klass类元信息

    - 长度（length）：数组对象拥有

  - 实例数据（instance data）：存放类的属性（Field）数据信息，包括父类的属性信息

  - 对齐填充（padding）：保证对象存储大小为8个字节的倍数

- 问题

  - `Object o = new Object()`中各部分存储位置
    - Object是方法区中的类元信息；o是栈内存中的引用；new Object()在堆内存中
  - new 一个对象占多少内存大小
    - 64位操作系统中，Mark Word 占8个字节，类型指针占8个字节，对象头一共16个字节。所以一个对象最小16个字节
      - 默认开启了压缩指针，一个对象最小 12+4(对齐填充) 个字节
    - 若包含属性`int id`、`boolean flag`，实例数据 4+1 个字节
    - 对齐填充会填充3个字节到24个字节
  - 为什么新生区对象经过15次垃圾回收到养老区
    - 对象标记中对象分代年龄由 4bit 记录，最大 1111 即为15



### AQS

- AQS使用一个 `volatile int state` 的成员变量来表示同步状态，通过内置的 FIFO 队列来完成资源获取的排队工作，将每条要去抢占资源的线程封装成一个静态内部类Node的节点对象来实现锁的分配，通过CAS完成对state值的修改

  ![AQS](D:\picture\typora\java2\AQS.png)

- 源码分析

  - 结构

    - ReentrantLock 类中有三个静态内部类，分别是：抽象类Sync，Sync的子类NonfairSync、FairSync

    - 抽象类Sync继承AbstractQueuedSynchro

    - AbstractQueuedSynchro 中有一个静态内部类Node

    - AbstractQueuedSynchro 中定义了多个模板方法，常用的是加锁时的acquire()和释放锁时的release()

  - 流程
  
    - lock() 方法会调用模板方法 asq.acquire(1)
  
      ```java
      public final void acquire(int arg) {
          // AQS类定义了多个方法供子类实现或覆盖
          if (!tryAcquire(arg) &&
              acquireQueued(addWaiter(Node.EXCLUSIVE), arg))
              selfInterrupt();
      }
      ```
  
      - 首先调用 tryAcquire() 尝试抢占资源
      - 抢占失败，调用 addWaiter() 将新节点加入队列
        - 创建一个虚拟占位空节点放在head，虚拟头阶段的thread属性为null
        - 后续加入的包含线程的节点依次放在head的后面
      - 将加入队列的节点的waitstate设置为-1
        - 先判断当前节点的前一个节点是否为虚拟节点，再 tryAcquire() 尝试抢占资源
          - 若抢占成功，将头节点设置为当前抢占成功的阶段，虚拟节点的next 置为null
        - 若失败，则判断waitstate的值
          - 若为0，将值改为-1，返回flase。进入第二次循环，回到上一步
          - 若为-1，返回true，在执行 LockSupport.park(this) 进入等待
  
    - unlock() 方法会调用模板方法 asq.release(1)
  
      ```java
      public final boolean release(int arg) {
          if (tryRelease(arg)) {
              Node h = head;
              if (h != null && h.waitStatus != 0)
                  unparkSuccessor(h);
              return true;
          }
          return false;
      }
      ```
  
  - NonfairSync 和 FairSync 都实现了 tryAcquire() 方法，区别在于非公平锁获取锁时比公平锁中少一个判断 !hasQueuedPredecessors()；hasQueuedPredecessors() 中判断了FIFO中是否有非空Node（是否需要排队）
  
    ```java
    // 此处为公平锁的 tryAcquire 方法实现
    protected final boolean tryAcquire(int acquires) {
        final Thread current = Thread.currentThread();
        int c = getState();
        if (c == 0) {
            // 公平锁会去检查FIFO中是否有等待的节点，若有，则不会去执行compareAndSetState
            if (!hasQueuedPredecessors() &&
                compareAndSetState(0, acquires)) {
                setExclusiveOwnerThread(current);
                return true;
            }
        }
        // 如果已经获得了锁，线程还是当前线程，表示发生了锁重入
        else if (current == getExclusiveOwnerThread()) {
            // state ++
            int nextc = c + acquires;
            if (nextc < 0)
                throw new Error("Maximum lock count exceeded");
            setState(nextc);
            return true;
        }
        return false;
    }
    ```
  
  - AQS类已经实现了addWaiter()
  
    ```java
    private Node addWaiter(Node mode) {
        // mode：Node.EXCLUSIVE 排他模式
        // 创建一个封装当前线程的新node，新node的waitState属性值为0
        Node node = new Node(mode);
    
        for (;;) {
            Node oldTail = tail;
            if (oldTail != null) {
                node.setPrevRelaxed(oldTail);
                if (compareAndSetTail(oldTail, node)) {
                    oldTail.next = node;
                    return node;
                }
            } else {
                // 初始化队列。new一个空节点作为虚拟节点，head = tail = new Node()
                initializeSyncQueue();
            }
        }
    }
    ```
  
  - AQS类已经实现了acquiredQueued()
  
    ```java
    // 不可打断模式：当线程抢到锁时，才会跳出循环，返回打断标记，再打断
    final boolean acquireQueued(final Node node, int arg) {
        try {
            boolean interrupted = false;
            for (;;) {
                // 获得node前一个节点，若前一个节点为null，报错
                final Node p = node.predecessor();
                if (p == head && tryAcquire(arg)) {
                    // node设置为头节点，node的thread、prev属性置为null
                    setHead(node);
                    // 此时原先的虚拟头节点无引用指向，将被回收；node节点将成为新的虚拟头节点
                    p.next = null; // help GC
                    // 当线程抢到锁时，才会跳出循环，返回打断标记
                    return interrupted;
                }
                // 若p节点的waitstate为0，则设置为-1并返回false；若为-1，则返回true
                if (shouldParkAfterFailedAcquire(p, node) &&
                    // 调用 LockSupport.park(this)
                    parkAndCheckInterrupt())
                    interrupted = true;
            }
        } catch (Throwable t) {
            cancelAcquire(node);
            throw t;
        }
    }
    ```
    
    ```java
    private final boolean parkAndCheckInterrupt() {
        LockSupport.park(this);
        // 返回为当前线程在park时是否被打断过，并清除打断标记
        return Thread.interrupted();
    }
    ```
  
  - tryRelease(int releases)
  
    ```java
    protected final boolean tryRelease(int releases) {
        // 若是重入锁，释放是 state--
        int c = getState() - releases;
        if (Thread.currentThread() != getExclusiveOwnerThread())
            throw new IllegalMonitorStateException();
        boolean free = false;
        if (c == 0) {
            free = true;
            setExclusiveOwnerThread(null);
        }
        setState(c);
        return free;
    }
    ```
  
- 问题

  - 锁重入原理：通过查看tryAcquire和tryRelease方法可知，利用state的++和--实现

  - 可打断原理：lock.lockInterruptible() 调用的是 aqs.doAcquireInterruptibly() 方法

    ```java
    public void lockInterruptibly() throws InterruptedException {
        sync.acquireInterruptibly(1);
    }
    ```

    ```java
    private void doAcquireInterruptibly(int arg)
        throws InterruptedException {
        final Node node = addWaiter(Node.EXCLUSIVE);
        try {
            for (;;) {
                final Node p = node.predecessor();
                if (p == head && tryAcquire(arg)) {
                    setHead(node);
                    p.next = null; // help GC
                    return;
                }
                if (shouldParkAfterFailedAcquire(p, node) &&
                    parkAndCheckInterrupt())
                    // 与不可打断相比，这里在被打断时，直接抛出异常，不会在进入下一次循环
                    throw new InterruptedException();
            }
        } catch (Throwable t) {
            cancelAcquire(node);
            throw t;
        }
    }
    ```

  - 公平锁原理：通过tryAcquire方法可知，公平锁会去检查FIFO中是否有等待的节点

  - <a href="https://www.bilibili.com/video/BV16J411h7Rd?p=245&vd_source=25ad2de4838bd28372a4956bac63c618">await 和 singal 原理</a>




### 读写锁

- ReentrantReadWriteLock使用

  - 读锁不支持条件变量
  - 重入时不支持升级：即持有读锁的情况下去获取写锁，会导致获取写多永久等待
  - 重入时支持降级：即持有写锁的情况下可以获取读锁

  ```java
  class CacheData {
      Object data;
      // 判断数据是否有效，如果为false，说明要更新数据
      volatile boolean cacheValid;
      final ReentrantReadWriteLock rwl = new ReentrantReadWriteLock();
      
      void processCachedData() {
          rwl.readLock().lock();
          if (! cacheValid) {
              // 获取写锁前必须释放读锁
              rwl.readLock().unlock();
              rwl.writeLock().lock();
              try {
                  // double check
                  if (! cacheValid) {
                      data = ...; // 更新数据操作
                      cacheValid = true;
                  }
                  // 将写锁降级为读锁，释放写锁
                  rwl.readLock().lock();
              } finally {
                  rwl.writeLock().unlock();
              }
          }
          // 使用完数据后释放读锁
          try {
              use(data);
          } finally {
              rwl.readLock().unlock();
          }
      }
  }
  ```

- ReentrantReadWriteLock原理

  - 读写锁用的是同一个Sycn同步器，因此等待队列、state等也是同一个
  - state 的低16位供写锁使用，高16位供读锁使用

- StampedLock 读写锁

  ```java
  @Slf4j
  class DataContainer {
      private int data = 0;
      private final StampedLock lock = new StampedLock();
  
      public int optimisticRead() throws InterruptedException {
          long stamp = lock.tryOptimisticRead();
          log.info("乐观读锁添加成功，stamp：{}", stamp);
          TimeUnit.MILLISECONDS.sleep(1000);
          if(lock.validate(stamp)) {
              log.info("乐观读锁未升级，stamp：{}", stamp);
              return data;
          }
          log.info("乐观读锁升级，stamp：{}", stamp);
          try {
              stamp = lock.readLock();
              log.info("读锁添加成功，stamp：{}", stamp);
              TimeUnit.MILLISECONDS.sleep(1000);
              return data;
          }finally {
              log.info("释放读锁，stamp：{}", stamp);
              lock.unlockRead(stamp);
          }
      }
  
      public void write() throws InterruptedException {
          TimeUnit.MILLISECONDS.sleep(500);
          long stamp = lock.writeLock();
          log.info("写锁添加成功，stamp：{}", stamp);
          data ++;
          TimeUnit.MILLISECONDS.sleep(2000);
          lock.unlockWrite(stamp);
          log.info("释放写锁，stamp：{}", stamp);
      }
  }
  ```

  ```log
  [INFO ] 12:05:56:426   Thread-0   --->    乐观读锁添加成功，stamp：256
  [INFO ] 12:05:56:936   Thread-1   --->    写锁添加成功，stamp：384
  [INFO ] 12:05:57:437   Thread-0   --->    乐观读锁升级，stamp：256
  [INFO ] 12:05:58:943   Thread-1   --->    释放写锁，stamp：384
  [INFO ] 12:05:58:943   Thread-0   --->    读锁添加成功，stamp：513
  [INFO ] 12:05:59:954   Thread-0   --->    释放读锁，stamp：513
  ```

  - 乐观读锁不会修改stamp值
  - 读锁和写锁会修改stamp值









# JVM

> The Java Virtual Machine

> 虚拟机参数：-XX:+PrintFlagsFinal（执行前，打印所有虚拟机参数及状态）

## 基础

### 字节码文件

- 基本信息：魔数、字节码文件对应的 java 版本号、访问标识（public final 等等）、父类和接口

  - Magic魔数

    - 文件不能通过文件扩展名来确定文件类型

    - 软件使用文件的头几个字节（文件头）来校验文件的类型，如果软件不支持该种类型就会报错

      | 文件类型   | 字节数 | 文件头                     |
      | ---------- | ------ | -------------------------- |
      | JPEG       | 3      | FFD8FF                     |
      | PNG        | 4      | 89504E47（文件尾也有要求） |
      | bmp        | 2      | 424D                       |
      | XML        | 5      | 3C3F786D6C                 |
      | AVI        | 4      | 41564920                   |
      | JAVA字节码 | 4      | CAFEBABE                   |

  - 版本号：jdk1.2后，主版本号-44 为字节码jdk版本

- 常量池：保存了字符串常量、类或接口名、字段名（主要在字节码指令中使用）

- 字段：当前类或接口中声明的字段信息

- 方法：当前类或接口声明的方法信息（字节码指令）

  - 操作数栈（临时存放）

  - [局部变量表数据](#局部变量表)（局部变量存放位置）

    ```java
    public static void main(String args) {
        int i = 0;
        int j = i+1;
    }
    ```

    | 索引 | 0    | 1    | 2    |
    | ---- | ---- | ---- | ---- |
    | 数组 | args | i    | j    |

  - 实例

    > i++ 与 ++i 的区别
    >
    > > i++：会先让栈中保留一份原始值，再计算
    > >
    > > ++i：会先计算，在让栈中保留一份计算后的值

    ```java
    public static void main(String args) {
        int i = 0;
        i = i++;
        // System.out.println(i) // 0
    }
    
    // 指令
    iconst_0     // 将0存到操作数栈中           栈：->[0] 数组：[args, i]
    istore_1     // 从栈中取出一个存到数组1号位   栈：->[] 数组：[args, i=0]
    iload_1      // 将数组1号位的值加载入栈      栈：->[0] 数组：[args, i=0]
    iinc 1 by 1  // 对数组1号位的值加1          栈：->[0] 数组：[args, i=1]
    istore_1     // 从栈中取出一个存到数组1号位   栈：->[] 数组：[args, i=0]
    return
    ```

    ```java
    public static void main(String args) {
        int i = 0;
        i = ++i;
        // System.out.println(i) // 1
    }
    
    // 指令
    iconst_0     // 将0存到操作数栈中           栈：->[0] 数组：[args, i]
    istore_1     // 从栈中取出一个存到数组1号位   栈：->[] 数组：[args, i=0]
    iinc 1 by 1  // 对数组1号位的值加1          栈：->[] 数组：[args, i=1]
    iload_1      // 将数组1号位的值加载入栈      栈：->[1] 数组：[args, i=1]
    istore_1     // 从栈中取出一个存到数组1号位   栈：->[] 数组：[args, i=1]
    return
    ```

    ```java
    private static int number = 3;
    public static void add1() {
        return number++;
    }
     // 先复制 dup，后计算
    getstatic #1   // #1处静态字段值入栈      栈：->[3]       数组：[]
    dup            // 复制栈顶部数据          栈：->[3, 3]    数组：[]
    iconst_1       //                      栈：->[1, 3, 3] 数组：[]
    iadd           // 让栈顶部两个数相加      栈：->[4, 3]    数组：[]
    putstatic #1   // 将栈顶部值存到#1处      栈：->[3]       数组：[]
    ireturn        // 返回栈顶部值           栈：->[]        数组：[]
    ```

    ```java
    private static int number = 3;
    public static void add1() {
        return ++number;
    } 
         
     // 先计算，后复制dup
    getstatic #1   // #1处静态字段值入栈      栈：->[3]       数组：[]
    iconst_1       //                      栈：->[1, 3]    数组：[]
    iadd           //                      栈：->[4]       数组：[]
    dup            // 复制栈顶部数据          栈：->[4, 4]    数组：[]
    putstatic #1   // 将栈顶部值存到#1处      栈：->[4]       数组：[]
    ireturn        // 返回栈顶部值           栈：->[]        数组：[]
    ```

    效率：

    ```java
    public static void add6() {
    int i = 0, j = 0, k = 0, l = 0, m = 0;
    i++;          // iinc 0 by 1
    j = j+1;      // iload_1  iconst_1  iadd  istore_1
    k+=1;         // iinc 2 by 1
    ++l;          // iinc 3 by 1
    m+=3;         // iinc 4 by 3   效率最高
    }
    ```

- 属性：类的属性，比如源码的文件名，内部类的列表等





### Arthas

> [Arthas 是一款线上监控诊断的产品](https://arthas.aliyun.com/doc/)

- 启动

  ```shell
  java -jar arthas-boot.jar
  ```

- 常用指令
  
  - 参数使用说明
  
    - class-pattern：表示 **`指令 类的全路径限定名`**
    - [i:]：表示 **`指令 -i 值`**
    - [a]：表示 **`指令 -a`**
  
  - memory：查看JVM内存信息
  
  - dashboard ：显示当前系统的实时数据面板
    - [i:]：刷新实时数据的时间间隔（ms），默认5000ms
    - [n:]：刷新实时数据的次数
  
  - dump：将已加载类的字节码文件输出到特定目录
    - class-pattern：类的全路径限定名（cn.eli.SpringApp)
    - [d:]：指定目录
  
  - jad：反编译已加载类的源码
    - class-pattern：类的全路径限定名
  
  - classloader：查看 classloader 的继承树，urls，类加载信息
  
    - [l]：按类加载的实例进行统计
    - [t]： 打印所有 ClassLoader 的继承树
    - [a]：列出所有 ClassLoader 加载的类，请谨慎使用
    - [c:]：加上指定 ClassLoader 的 hashcode，可查看指定classloader的信息
  
  - sc：查看 JVM 已加载的类信息
  
    - class-pattern
    - [d]：输出当前类的详细信息，包括这个类所加载的原始文件来源、类的声明、加载的 ClassLoader 等详细信息。如果一个类被多个 ClassLoader 所加载，则会出现多次
  
  - mc：将 .java 文件编译为 .class 文件
  
    > 注意，mc 命令有可能失败。如果编译失败可以在本地编译好`.class`文件，再上传到服务器。具体参考[retransform](https://arthas.aliyun.com/doc/retransform.html)命令说明。
  
    - menu/OneJavaPro.java：目录/文件名.java
    - [d:]：指定输出目录
    - [c:]：加上指定 ClassLoader 的 hashcode（一个java程序往往还用到了其他类，如果不结合其他类共同编译，往往会失败，而ClassLoader可以得到其他类的信息，因此，如果该java程序来自部署的class反编译，还要加上原本加载这个java程序的ClassLoader。如果对反编译的java程序进行修改，新添加的代码可能用到了该ClassLoader中未存储的类，可能导致编译失败）
  
  - retransform：加载外部的`.class`文件，替换内存中 jvm 已加载的类（热部署）
  
    - menu/OneJavaPro.class：目录/文件名.class
    - 问题
      - 重启会失效
      - 不能添加方法或者字段、也不能更新正在执行的方法
  





### 类的生命周期

- <span id="加载">加载</span>

  - 首先，类加载器根据类的全限定名通过不同渠道以二进制流的方式获取字节码信息
    - 本地文件中的类
    - 动态代理生成的类
    - 通过网络传输的类
  - 类加载器在加载完类之后，java虚拟机会将<font color=red>字节码中的信息保存到[方法区](#方法区)中</font>：生成一个 InstanceKlass 对象，保存类的所有信息（如基本信息、常量池、字段、方法等），还包含实现特定功能比如多态的信息（虚方法表）
  - java虚拟机<font color=red>还会在堆中生成一份与方法区中数据类似的 java.lang.Class 对象</font>，作用是在 java代码中去获取类的信息以及存储静态字段的数据（如反射）（jdk8及之后静态字段数据存放在堆中的类信息中）
  - 方法区中的类数据 和 堆区中的类数据 相关联
  - 为什么在方法区中和堆中都生成一份类数据
    - 方法区中的是由c++生成的，不便操作
    - 方法区中的类的信息包含了一些不需要开发者使用的数据（安全性和便携性）

- 连接

  - 验证：验证内容是否满足《java虚拟机规范》

    - 魔数的校验，文件是否以0xCAFEBABE开头
    - 元信息的验证，如类必须有父类
    - 验证程序执行指令的语义，如 goto 10  跳转的10号指令是否存在
    - 字节码版本与jdk版本校验

  - 准备：给静态变量赋初始值（如果静态变量被final修饰，则在准备阶段就赋上指定值）

    | 数据类型 | 初始值   | 数据类型     | 初始值 |
    | -------- | -------- | ------------ | ------ |
    | int      | 0        | byte         | 0      |
    | long     | 0L       | boolean      | false  |
    | short    | 0        | double       | 0.0    |
    | char     | '\u0000' | 引用数据类型 | null   |

  - 解析：将常量池中的符号引用（如#2）替换为指向内存的直接引用

- 初始化：执行静态代码块中的代码，为静态变量赋值

  ```java
  public class Demo {
      static {
          value = 2;
      }
      public static int value = 1;
      public static void main(String[] args) {
          System.out.println(value); // 值为1，static自上而下执行，但main方法最后执行
      }
  }
  
  // 方法
  // [0] <init> 构造方法
  // [1] main
  // [2] <clinit> 该方法不一定存在。表示初始化阶段执行的操作
  //      iconst_2;  putstatic #2;  iconst_1;   putstatic #2;   return;
  ```

  - 以下几种方式会导致类的初始化

    > 添加  **-XX:+TranceClassLoading** 参数可以打印出加载并初始化的类

    - 访问一个类的静态变量或静态方法，<font color="red">如果变量是final修饰的，并且等号右边是常量不会触发初始化</font>

      ```java
      private static final int a = 1; // 访问该变量不会触发初始化
      private static final LocalDateTime dateTime = LocalDateTime.now(); // 会
      ```

    - 调用 Class.forName(String className) 

    - new 一个该类的对象

    - 执行 Main 方法的当前类

      ```java
      // 打印顺序 D A C B C B
      public class OneClass {
          public static void main(String[] args) {
              System.out.println("A");
              new OneClass();
              new OneClass();
          }
          public OneClass() {
              System.out.println("B");
          }
          
          // 实例代码块会与构造方法混合，在构造方法前执行，多个实例代码块自上而下执行
          {
              System.out.println("C");
          }
          static {
              System.out.println("D");
          }
      }
      ```

    - 数组的创建不会导致数组中元素的类的初始化

      ```java
      OneClass[] arr = new OneClass[10]; // 不会初始化 OneClass 类
      ```

    - 存在继承关系的初始化

      - 直接访问父类静态变量，不会触发子类的初始化
      - 子类的初始化\<clinit>调用前，会先调用父类的\<clinit>初始化方法

      ```java
      public class OneClass {
          public static void main(String[] args) {
              A a = new B();
              // B类中不定义a变量，结果为：3  3  3
              // B类中定义a变量，结果为：1  1  3
              System.out.println(a.a+" "+A.a+" "+B.a);
          }
      
          static class A {
              static {
                  a = 2;
                  System.out.println("A 类初始化");
              }
              static int a = 1;
          }
      
          static class B extends A {
              // static int a = 4;
              static  {
                  a = 3;
                  System.out.println("B 类初始化");
              }
          }
      }
      ```

- 使用

- 卸载





### 类加载器

> 是java虚拟机提供给应用程序去实现获取类和接口的字节码技术

#### 类加载器的分类

> jdk8 及 之前版本的类加载器

- 根据定义位置分类

  - 一类是 Java代码中实现的（如拓展类加载器、应用程序类加载器、自定义加载器）

    - jdk 中默认提供或者自定义
    - 都继承自抽象类 ClassLoader

  - 另一类是 Java虚拟机底层源码实现的（启动类加载器）

    - 源代码位于 Java虚拟机的源码中，实现语言与虚拟机底层语言一致，比如 Hotspot 使用的C++

    - 作用是加载程序运行时的基础类，如 java.lang.String，确保其可靠性

    - 通过该加载器加载的类获取类加载器时，会返回null

      ```java
      System.out.println(String.class.getClassLoader() == null); // true
      ```

- 根据作用分类

  - BootstrapClassLoader（启动类加载器）：加载 java 中最核心的类

    > 添加  -Xbootclasspath/a:<font color=blue>jar包目录</font>/<font color=blue>jar包名</font>  启动参数，可以指定该jar包中的类由启动类加载器加载 

    - 默认加载java安装目录下的 /jre/lib 下的类文件

  - ExtClassLoader（拓展类加载器）：允许扩展 java 中比较通用的类

    > 添加 -Djava.ext.dirs=<font color=blue>jar包目录</font>  启动参数，可以指定该jar包中的类由拓展类加载器加载 
    >
    > > 该参数默认后覆盖掉原始加载目录(/jre/lib/ext)，可以用 **对应的分隔符** 分隔多个路径，再追加原始加载目录
    > >
    > > > windows用 <font color=red>**;**</font> 
    > > >
    > > > macos/linex用 <font color=red>**:**</font> 

    - 默认加载java安装目录下的 /jre/lib/ext 下的类文件

  - AppClassLoader（应用程序类加载器）：加载应用使用的类

    - 该加载器加载的类范围覆盖了启动类加载器和拓展类加载器

  - 。。。。。。等等



#### 双亲委派机制

- 作用
  - 避免恶意代码替换 JDK 中的核心类库，如自定义的String类无法替换jdk中的String类，确保核心类库的完整性和安全性
  - 避免同一个类被多次加载
- 原理：当一个类加载器接收到加载类的任务时，会<font color=red>自底向上查找是否加载过，再自顶向下尝试进行加载（看是否在自己的加载范围内）</font> 
  - 顺序（父子关系）：顶——启动类加载器；中——拓展类加载器；底——应用程序类加载器
  - 当某个类都不在各层类加载器中，会报类找不到错误



#### 打破双亲委派机制

> 打破方法有三种
>
> > 自定义类加载器
> >
> > 线程上下文类加载器
> >
> > Osgi框架的类加载器（允许同级委派，可以实现热部署功能）

##### 自定义类加载器

- 重写 loadClass 方法，破坏双亲委派机制

- ClassLoader 抽象类源码

  - 构造方法

    ```java
    // 继承该类得到的类加载器 可以指定父类加载器
    protected ClassLoader(ClassLoader parent) {
        this(checkCreateClassLoader(), null, parent);
    }
    // 继承该类得到的类加载器 若不指定父类加载器，默认为 应用程序类加载器
    protected ClassLoader() {
        this(checkCreateClassLoader(), null, getSystemClassLoader());
    }
    ```

  - loadClass方法：双亲委派机制

    ```java
    public Class<?> loadClass(String name) throws ClassNotFoundException {
        return loadClass(name, false);
    }
    
    protected Class<?> loadClass(String name, boolean resolve) throws ClassNotFoundException {
        synchronized (getClassLoadingLock(name)) {
            // 首先，检查这个类是否已经被加载（双亲委派机制）
            Class<?> c = findLoadedClass(name);
            if (c == null) {
                long t0 = System.nanoTime();
                try {
                    if (parent != null) {
                        // 先让父类去加载
                        c = parent.loadClass(name, false);
                    } else {
                        c = findBootstrapClassOrNull(name);
                    }
                } catch (ClassNotFoundException e) {
                }
    
                // 如果当前类仍为空，由该类加载器加载
                if (c == null) {
                    long t1 = System.nanoTime();
                    c = findClass(name);
    
                    // this is the defining class loader; record the stats
                    PerfCounter.getParentDelegationTime().addTime(t1 - t0);
                    PerfCounter.getFindClassTime().addElapsedTimeFrom(t1);
                    PerfCounter.getFindClasses().increment();
                }
            }
            // 若传递为flase，则不进行连接，也不会执行到初始化方法<clinit>
            if (resolve) {
                resolveClass(c);
            }
            return c;
        }
    }
    ```

  - findClass方法：由子类去实现，核心逻辑是获得字节码文件并将字节码文件给到defineClass方法

    ```java
    protected Class<?> findClass(String name) throws ClassNotFoundException {
        throw new ClassNotFoundException(name);
    }
    ```

  - defineClass方法：最后会追溯到本地方法，核心逻辑是做一系列检验

    ```java
    protected final Class<?> defineClass(String name, byte[] b, int off, int len, ProtectionDomain protectionDomain) throws ClassFormatError {
        // ......
    }
    ```

  - resolveClass方法：执行类生命周期中的连接阶段

    ```java
    protected final void resolveClass(Class<?> c) {
        if (c == null) {
            throw new NullPointerException();
        }
    }
    ```

  - <font color=red>正常实现一个自定义类加载器，不应该破坏双亲委派机制，应该重写findClass方法，比如从数据库中获得字节码文件传入到defineClass</font>

##### 线程上下文类加载器

> 以jdbc中 DriverManger和第三方数据库驱动Driver类的加载为例

- DirverManger 类位于rt.jar中，由启动类加载

- 引入第三方数据库驱动依赖，DriverManger加载第三方依赖

- 问题1：DriverManger 怎么知道第三方jar包中要加载的驱动在哪？（利用到SPI机制）

  - SPI机制（已jdbc的Driver为例）

    ```java
    package com.mysql.cj.jdbc;
    
    public class Driver enxtends NonRegisteringDriver implements java.sql.Driver {
        public Driver() throws SQLException;
        
        // 只要Driver类被加载，就会执行下面初始化代码，从而完成注册。
        // 因此此时关注该类如何被加载
        static {
            try {
                DriverManger.registerDriver(new Driver());
            }catch(SQLException var1) {
                throw new RuntimeException("Can't register driver!");
            }
        }
    }
    ```

    - 暴露实现类
      - 在ClassPath路径下创建 META-INF/services 的文件夹
      - 该目录下创建文件，以实现类作为文件内容，实现类实现的接口作为文件名（如文件名：java.sql.Driver  文件内容：com.mysql.cj.jdbc.Driver）

    - 使用ServiceLoader加载实现类com.mysql.cj.jdbc.Driver

      ```java
      // 代码中的 Driver.class 是 java.sql.Driver 接口
      // 目的是读取文件名与该接口名一致的文件的内容
      ServiceLoader<Driver> loadedDrivers = ServiceLoader.load(Driver.class);
      
      // 该迭代器存放着对应接口的实现类，与上述文件内容保持一致
      Iterator<Driver> driversIterator = loadedDrivers.iterator();
      ```

  - DriverManger 在初始化代码（static静态代码块）中通过 ServiceLoader 加载Driver类，即可让 Driver 类在初始化阶段完成注册

- 问题2：debug模式下可得到 Driver 类是由应用程序类加载器加载的，而DriverManger 本身是由启动类加载器加载的，它是如何拿到应用程序类加载器的呢？

  - SPI中ServiceLoader加载实现类Driver时，使用的是线程上下文保存的类加载器进行类的加载，这个类加载器默认是应用程序类加载器

    ```java
    public class ServiceLoader {
        // .......
        public static <s> ServiceLoader<S> load(Class<S> service) {
            // 默认是 应用程序类加载器
            ClassLoader cl = Thread.currentThread().getContextClassLoader();
            return ServiceLoader.load(service, cl);
        }
    }
    ```

- 问题3：JDBC案例中真的打破了双亲委派机制吗？

  - 周志明《深入理解Java虚拟机》提到打破了该机制
  - 实际上：没有，无论是DriverManger类的加载还是Driver实现类的加载，都是按该机制流程加载的。只是Driver实现类的加载由指定的类加载器直接加载（区别于访问类的静态变量导致类加载等间接加载方式）



#### Jdk8之后的类加载器

> 由于JDK9引入了module的概念，类加载器在设计上发生了很多变化

- 启动类加载器使用 Java 编写，位于 jdk.internal.loader.ClassLoaders 类中。
  - 启动类加载器由 Bootstrap（c++)   变为   BootClassLoader（java）
  - java中的BootClassLoader继承自BuiltinClassLoader实现从模块中找到要加载的字节码资源文件
  - 启动类加载器依然无法通过java代码获取到，返回的依然是null，保持了统一
- 扩展类加载器被替换为平台类加载器（Platform Class Loader）
  - 平台类加载器遵循模块化方式加载字节码文件，所以从继承 URLClassLoader 变成了 BuiltinClassLoader，BuiltinClassLoader实现了从模块加载字节码文件。
  - 平台类加载器的存在更多的是为了与老版本的设计方案兼容，自身没有特殊的逻辑





### 运行时内存区

#### 线程不共享区

> 每个线程都有各自的数据区，有三块区域
>
> > 程序计数器
> >
> > java虚拟机栈
> >
> > 本地方法栈

- 程序计数器：在代码执行过程中，程序计数器会记录下一行字节码指令的地址。执行完当前指令后，虚拟机的执行引擎根据程序计数器执行下一行指令

  - 控制解释器解释指令的顺序
  - 在多线程执行情况下，java虚拟机需要通过程序计数器记录指令执行到的位置

- java虚拟机栈：采用栈的数据结构来管理方法调用中的基本数据，每个方法的调用使用一个栈帧来保存

  - 栈帧的组成

    - <span id="局部变量表">局部变量表</span>：在运行过程中存放所有的局部变量

      > 栈帧中的局部变量表是一个数组，数组中的每一个位置称之为槽（slot），<font color=red>long和double类型占用两个槽，其他类型占用一个槽</font>

      ```java
      public int add(int i, int j) {
          int k = 2;
          return i+j+k;
      }
      ```

      ```java指令
      0 iconst_2
      1 istore_3
      2 iload_1
      3 iload_2
      4 iadd
      5 iload_3
      6 iadd
      7 ireturn
      ```

      | Nr.  | 起始pc（起始生效位置） | 长度（生效范围） | 序号（槽的编号） | 名字 |
      | ---- | ---------------------- | ---------------- | ---------------- | ---- |
      | 0    | 0                      | 8（0-7）         | 0                | this |
      | 1    | 0                      | 8（0-7）         | 1                | i    |
      | 2    | 0                      | 8（0-7）         | 2                | j    |
      | 3    | 2                      | 6（2-7）         | 3                | k    |

    - 操作数栈：

      - 用来存放中间数据的一小块区域
      - <font color=red>在编译期就可以确定操作数栈的最大深度，从而在执行时正确的分配内存大小</font>

    - 帧数据

      - 动态链接：保存了符号引用与运行时常量池内存地址的映射关系

        - 本类的静态引用会在连接的解析阶段将符号引用变为内存地址引用，但对其他类的静态变量的符号引用暂时不会去解析。
        - 对其他类中的静态变量的符号引用会在运行时通过帧数据中的动态链接进行解析

      - 方法出口：在method2方法入栈前，需要在method2的栈帧中记录method1方法中已执行到的位置，之后method2栈帧出站时，method2将栈帧中记录的method1执行到的位置交给程序计数器

        ```java
        public static void main() {
            method1();
        }
        public static void method1() {
            // ...
            method2();
            // ...
        }
        public static void method2() {
            // ...
        }
        ```

      - 异常表：存放的是代码中异常的处理信息，包含了try代码块和catch代码块执行后跳转到的字节码指令位置

- 本地方法栈

  - 区别于java虚拟机栈，本地方法栈存储的是native本地方法的栈帧
  - 在Hotspot虚拟机中，<font color=red>java虚拟机栈和本地方法栈实现上使用了同一个栈空间</font>



#### 线程共享区

> 所有线程共享的数据区，有两块区域
>
> > 堆
> >
> > 方法区

- 堆（heap space）

  - 说明

    - 一般java程序中堆内存是空间最大的一块内存区域。创建出来的对象都存在堆内存上
    - 栈上的局部变量表中，可以存放堆上对象的引用
    - 静态变量也可以存放堆上对象的引用，通过静态变量就可以实现对象在线程之间的共享
    - java虚拟机<font color=red>还会在类的加载阶段在堆中生成一份与方法区中数据类似的 java.lang.Class 对象</font>，作用是在 java代码中去获取类的信息以及存储静态字段的数据（如反射）（jdk8及之后静态字段数据存放在堆中的类信息中）

  - 使用上可分为三部分

    - used：指的是当前已使用的堆内存
    - total：java虚拟机已经分配的可用堆内存
    - max：java虚拟机可以分配的最大堆内存

  - [作用上可分为：新生代、老年代](#分代GC算法)

  - 测试代码（可用 arthas 的 memory 命令检测）

    ```java
    ArrayList<Object> objects = new ArrayList<>();
    while (true) {
        System.in.read(); // 每按一次回车，提交一次输入
        int bytes = 100*1024*1024;
        objects.add(new byte[bytes]);
        System.out.printf("增加了 %s MB%n", bytes/1024/1024);
    }
    ```

- <span id="方法区">方法区</span>

  > 方法区是《java虚拟机规范》中设计的虚拟概念，每款java虚拟机在实现上都各不相同。

  - Hotspot 方法区设计（可通过 arthas 的 memory 指令查看）
    - <font color=red>JDK7及之间版本</font>将方法区存放在<font color=red>堆区域的永生代空间（ps_perm_gen）</font>，堆的大小由虚拟机参数来控制
    - <font color=red>JDK8及之后版本</font>将方法区存放在<font color=red>元空间（metaspace）</font>中，元空间位于操作系统维护的<font color=red>直接内存</font>中，默认情况下只要不超过操作系统的承受上限，可以一直分配

  - 存放的数据
    - 类的元信息：保存了所有类的基本信息（如基本信息、常量池位置引用、字段、方法位置引用、虚方法表）
    - 运行时常量池：保存了字节码文件中的常量池的内容
    - 字符串常量池（jdk7之前）



#### 特殊的内存区

- 字符串常量池（位于堆中）：保存了字符串常量

  ```java
  // 先创建对象，再加载字符串常量池，再完成String初始化
  // 最后，局部变量表中 s1槽 存储堆中该String对象的内存地址
  String s1 = new String("abc"); 
  // 局部变量表中 s2槽 存储字符串常量池“abc”的内存地址
  String s2 = "abc";
   // 内存地址对比，false
  System.out.println(s1 == s2);
  
  
  
  // 创建String对象,获得其堆引用(1)  操作数栈 ->[(1)]
   0 new #2 <java/lang/String>
  // 复制操作数栈顶部数据   栈->[(1),(1)]
   3 dup
  // 从字符串常量池中读取"abc"引用(2)  栈->[(2),(1),(1)]
   4 ldc #3 <abc> 
  // 调用String初始化方法，将堆中String对象初始化完成    栈->[(1)]
   6 invokespecial #4 <java/lang/String.<init> : (Ljava/lang/String;)V>
  // 将String对象堆引用(1)存储到 s1槽 上
   9 astore_1                   
  10 ldc #3 <abc>
  12 astore_2
  // 此时 s1槽 和 s2槽 存放的是不同的内存地址
  // 。。。。。。
  ```

  - 版本迭代

    - jdk7之前：运行时常量池逻辑包含字符串常量池，跟随方法区位于堆的永久代中
    - jdk7版本：字符串常量池被从方法区拿到了堆中，运行时常量池还在永久代
    - jdk8及之后：字符串常量池还在堆中，永久代空间被移出，运行时常量池跟随方法区移到元空间中

  - String对象的 intern() 方法往常量池中存放数据，并返回常量池中该数据的引用（jdk7之前）

    ```java
    String s1 = "a";
    String s2 = "b";
    String s3 = "ab";
    // 底层调用StringBuilder的拼接方法，返回一个String对象的引用
    String s4 = s1+s2;
    // "ab"在字符串常量池中已存在，不会再重复存放，只返回该引用
    String s5 = (s1+s2).intern();
    System.out.println(s3==s4);  // false
    System.out.println(s3==s5);  // true
    ```

  - 版本迭代

    ```java
    // jdk 11 环境
    // String s0 = "ab";  // 字符串常量池中会存在“ab”字符串
    String s1 = "a";
    String s2 = "b";
    String s3 = s1+s2;
    String s4= s3.intern();
    // jdk7之前：无论有没有第二行代码，都为false
    // jdk7及之后：有第二行代码，返回false；没有第二行代码，返回true
    System.out.println(s3 == s4);
    ```

    - jdk 7 之前：inter()方法会把第一次遇到的字符串实例复制到永久代的字符串常量池中，返回的也是永久代里面这个字符串实例的引用
    - jdk 7 及之后：由于字符串常量在堆中，为节省内存，inter()方法只将第一次遇到的字符串的引用放入字符串常量池（上述代码中 s3 和 s4 均为堆引用）

- 静态变量的存储：JDK7及之后的版本中，静态变量是存放在[堆中的Class对象](#加载)中，脱离的永久代

- 直接内存

  - 直接内存并不在《Java虚拟机规范》中，所以并不属于java运行时内存区域。在JDK1.4中引入了NIO机制，使用了直接内存，主要为了解决以下两个问题
    - Java堆中的对象如果不再使用要回收，回收是会影响对象的创建和使用
    - IO操作比如读文件，需要先把文件读入直接内存（缓冲区）再把数据复制到Java堆中。现在直接放入直接内存即可，同时Java堆上维护了直接内存的地址引用，减少了数据复制的开销。写文件也是类似的思路。
  



#### 内存溢出

> <font color=red>参数设置</font>
>
> > 栈：-Xss栈大小
> >
> > 堆：total 和 max 一般设为相同值
> >
> > > total：-Xms大小
> > >
> > > max：-Xmx大小
> >
> > 方法区：一般需要设置
> >
> > > jdk8之前设置永久代大小：-XX:MaxPermSize=值
> > >
> > > jdk7之后设置元空间打字：-XX:MaxMetaspaceSize=值
> >
> > 直接内存（若使用到NIO，一般需要设置）：-XX:MaxDirectMemorySize=值

- java虚拟机栈内存溢出（StackOverflowError）

  - 栈内存默认大小
    - Linux x86（64位）：1MB
    - Windows：基于操作系统

  - 设置栈内存大小
    - 语法：-Xss栈大小
    - 单位：字节（默认，必须是1024的倍数）、k/K（KB）、m或M（MB）、g或G（GB）
    - 范围：Windows（64位）下的JDK8测试最小值位180K，最大值为1024M

- 堆内存溢出（OutOfMemoryError：Java heap space）

  - 堆内存默认大小

    - max大小默认是系统内存的1/4
    - total大小默认是系统内存的1/64

  - 设置total、max大小

    > 实际生产中，一般将total和max设置为同样的值

    - 设置total大小：-Xms大小（必须大于1M）
    - 设置max大小：-Xmx大小（必须大于2M）
    - 单位：字节（默认，必须是1024的倍数）、k/K（KB）、m或M（MB）、g或G（GB）

  - 是否直到 used=total=max 时，报出堆内存溢出

    > 不是，堆内存溢出的判断条件比较复杂，实际上，used接近max时就可能报出

- 方法区内存溢出（OutOfMemoryError：PermGen space（jdk7）/Metaspace（jdk8））

  > 实际生产中，需要设置元空间最大大小

  - 默认大小
    - jdk7及之间版本：方法区存放在堆中的永久代空间，默认有上限，堆中永久代的大小可通过虚拟机参数 -XX:MaxPermSize=值  来控制
    - jdk8及之后版本：方法区存放在直接内存中，默认无上限。可以使用 -XX:MaxMetaspaceSize=值  将元空间最大大小进行限制
  - 单位：字节（默认，必须是1024的倍数）、k/K（KB）、m或M（MB）、g或G（GB）
  
- 直接内存溢出（OutOfMemoryError：Direct buffer memory）

  > 实际生产中，如果使用到NIO，需要设置直接内存的最大大小

  - 语法：-XX:MaxDirectMemorySize=值
  - 单位：字节（默认，必须是1024的倍数）、k/K（KB）、m或M（MB）、g或G（GB）





### 垃圾回收

#### 概述

- C/C++的内存管理

  - C/C++中没有自动的回收机制，一个对象如果不再使用，需要手动释放，否则就会出现<font color=red>内存泄露</font>

    ```c
    #include "Test.h"
    int main() {
        while(true) {
            Test* test = new Test();
        }
        return 0;
    }
    ```

    ```c
    #include "Test.h"
    int main() {
        while(true) {
            Test* test = new Test();
            delete test; // 手动回收
        }
        return 0l
    }
    ```

  - 内存泄露指的是不再使用的对象所占的内存空间在系统中未被回收，内存泄露的积累可能导致内存溢出

- Java的内存管理：Java中为了简化对象的释放，引入了自动的垃圾回收机制。通过垃圾回收器来对不再使用的对象完成自动的回收，<font color=red>垃圾回收机制主要负责对堆上内存的回收</font>。其他很多现代语言比如C#、Python、Go都拥有自己的垃圾回收器

- 两种垃圾回收机制的对比

  - Java自动垃圾回收的缺点：无法控制垃圾回收的及时性
  - C/C++手动垃圾回收的缺点：编写不当容易出现悬空指针、重复释放、内存泄露等问题



#### 线程不共享区的回收

> 线程不共享的内存部分，往往是伴随着线程的创建而创建，线程的销毁而销毁。而方法的栈帧在执行完方法后就会自动弹出栈并释放掉对应的内存。



#### 方法区的回收

> 虚拟机参数
>
> > 打印类的加载日志：-XX:+TraceClassLoading
> >
> > 打印类的卸载日志：-XX:+TraceClassUnloading

- System.gc()：向虚拟机发送一个垃圾回收的请求，具体是否以及何时进行垃圾回收由Java虚拟机自行判断

- 方法区中能回收的内容主要就是不再使用的类。判定一个类可以被卸载，需要同时满足下面<font color=red>三个条件</font>
  - 此类所有的实例对象都已被回收，在堆中不存在任何该类的实例对象以及子类对象
  - 加载该类的类加载器已经被回收
  - 该类对应的 java.lang.Class 对象没有在任何地方被引用
- 由于平时使用中，大多数类一般由应用程序类加载器加载，该加载器不会被回收，所有类一般不会被卸载



#### 对象回收算法

> 判断对象能否被回收的算法

- 引用计数法

  - 对象能否能被回收，会根据对象是否<font color=red>被引用</font>来决定。

  - 引用计数法会在每个对象维护一个引用计数器，当对象被引用时加1，取消引用时减1

  - 说明
    - 优点：实现简单，C++中的智能指针就采用了引用计数法
    - 缺点：
      - 每次引用和取消引用都需要维护计数器，对系统性能有一定的影响
      - <font color=red>存在循环引用问题。</font>所谓循环引用，就是A对象引用了B对象，B对象右引用了A对象，此时会出现对象内存无法回收的问题

- 可达性算法（Java虚拟机使用）

  - 可达性算法将对象分为两类：垃圾回收的根对象（GC Root）和普通对象，GC Root对象一般不会被回收，对象与对象之间存在引用关系

  - 哪些对象是GC Root对象

    - 线程 Thread 对象，该对象会引用线程栈帧中的方法参数、局部变量等

      ```java
      public void method() {
          A a = new A();
          B b = new B();
          a.b = b;
          b.a = a;
          a = null;
          b = null;
      }
      ```

    - 系统类加载器加载的 java.lang.Class 对象

      ```java
      // sun.misc.Launcher 是GC Root对象，该对象可以找到 AppClassLoader
      // 该类由 AppClassLoader 加载，静态引用变量的内存地址存储在Class对象中
      public class MyClass {
          // 静态变量不会被回收
          private static A a = new A();
      }
      ```

    - 监视器对象（Monitor），用来保存同步锁 synchronized 关键字持有的对象

    - 本地方法调用时使用的全局对象



#### 五种对象引用

- 强引用：最常见的引用，由可达性分析算法来判断

- 软引用：软引用相对于强引用是一种比较弱的引用关系，如果一个对象只有软引用关联到它，<font color=red>当程序内存不足时，就会将软引用中的数据进行回收</font>，在JDK1.2版本后提供了SoftReference类来实现软引用，软引用常用于缓存中

  ```java
  // 添加虚拟机参数 -Xms200m -Xmx200m
  
  byte[] bytes = new byte[100*1024*1024];
  // GC Root强引用软引用对象，软引用对象软引用其内部数据
  SoftReference<byte[]> softReference = new SoftReference<>(bytes);
  bytes = null; // 去掉强引用
  System.out.println(softReference.get()); // 内存足够，不会被回收
  
  byte[] bytes2 = new byte[100*1024*1024];
  System.out.println(softReference.get()); // 内存不足，执行一次垃圾回收，仍不足，回收软引用
  
  byte[] bytes2 = new byte[100*1024*1024]; // OutOfMemoryError: Java heap space
  ```

  - 问题：软引用这个”盒子“里的数据被回收，但”盒子“却是强引用，不会被回收

    ```java
    // 添加虚拟机参数 -Xms200m -Xmx200m
    
    ReferenceQueue<byte[]> queues = new ReferenceQueue<>();
    List<SoftReference<byte[]>> list = new ArrayList<>();
    
    byte[] bytes = new byte[100*1024*1024];
    // 参数传入ReferenceQueue对象，每次盒子内容被回收，对应盒子就会被放入该Queue
    list.add(new SoftReference<>(bytes, queues));
    bytes = null;
    
    byte[] bytes2 = new byte[100*1024*1024];
    list.add(new SoftReference<>(bytes2, queues));
    bytes2 = null;
    
    int count = 0;
    while (list.remove((SoftReference<byte[]>) queues.poll())) {
        count++;
    }
    System.out.printf("本次回收盒子 %s 个\n", count);
    ```

  - 设计一个Student的缓存类

    ![盒子模型](D:\picture\typora\后端2\Student缓存类设计.png)

- 弱引用：弱引用的机制和软引用类似，区别在于弱引用包含的对象在垃圾回收时，不管内存是否够用，都会被直接回收。在JDK1.2版之后提供了WeakReference类来实现弱引用，弱引用主要在ThreadLocal中使用。弱引用对象本身也可以用引用队列进行回收

- 虚引用：不能通过虚引用对象（盒子）获得内部包含的对象（盒子里的内容）。唯一用途是当对象被垃圾回收器回收时可以利用其获得通知。Java中使用PhantomReference实现了虚引用，直接内存中为了及时知道直接内存对象不再使用，从而回收内存，使用了虚引用来实现

  ```java
  ByteBuffer directBuffer = ByteBuffer.allocateDirect(size);
  directBuffer = null;
  
  // 当 directBuffer直接内存中的对象被回收时，需要及时通知JVM释放直接内存还给操作系统
  ```

- 终结器引用：（一般不会使用）指的是在对象需要被回收时，对象将被放置在Finalizer类中的引用队列中，在稍后由一条FinalizerThread线程从列表中获取对象，然后执行对象的finalize方法，在对象第二次被回收时，该对象才真正的被回收。在这个过程可以在finalize方法中再将自己对象使用强引用关联上，但不建议这样做

  



#### 垃圾回收算法

> 虚拟机参数：-verbose:gc （打印出垃圾回收的日志）

> 1960年John McCarthy发布了第一个GC算法：标记-清除算法
>
> 1963年Marvin L. Minsky发布了复制算法
>
> 本质上后续的所有垃圾回收算法，都是在上述两种算法的基础上优化而来的。

- 分类

  - 标记-清除算法（Mark Sweep GC）

  - 复制算法（Copying GC）

  - 标记-整理算法（Mark Compact GC）

  - [分代GC（Generational GC）](#分代GC算法)

- STW（Stop The World）：Java垃圾回收过程会通过单独的GC线程来完成，但是不管使用哪一种GC算法，都会有部分阶段需要停止所有的用户线程。这个过程被称之为 Stop The World 。如果STW时间过长，则会影响用户的使用过程

- 垃圾回收算法的评价标准

  - 吞吐量：指的是CPU用于执行用户代码的时间与CPU总执行时间的比值（即吞吐量=执行用户代码时间/（执行用户代码时间 + GC时间）。吞吐量数值越高，垃圾回收的效率就越高。
  - 最大暂停时间：STW时间的最大值
  - 堆使用的效率：不同的垃圾回收算法，对堆内存的使用方式是不同的。比如标记清除法，可以使用完整的堆内存。而复制算法会将堆内存一分为二，每次只能使用一半内存。

  > 总结：三者不可兼得，<font color=red>不同的垃圾回收算法，适用于不同的场景。</font>

- 标记-清除算法

  - 核心思想是分为两个阶段
    - 标记阶段：将所有存活的对象进行标记。Java中使用可达性算法，从GC Root开始通过引用链遍历出所有存活的对象。
    - 清除阶段：从内存中释放没有被标记（非存活）的对象。
  - 优点：实现简单，只需要在第一阶段为每个对象维护一个标志位，第二阶段根据标志位进行清除即可
  - 缺点：
    - 碎片化：由于内存的分配很多情况是需要一块连续的区域，在对象被删除之后，内存中会出现很多细小的可用的内存单元，该单元组合起来可以放下一个较大的内存对象，但它们是分散的，可能没有容纳该对象的连续的内存空间
    - 分配速度慢：由于内存碎片的存在，需要维护一个空闲的链表，极有可能发生每次需要遍历到链表的最后才能获得合适的内存空间

- 复制算法

  - 核心思想：
    - 准备两块空间 From空间和 To空间，每次在对象分配阶段，只能使用其中一块空间。
    - 在垃圾回收阶段，将 From空间中存活的对象复制到 To空间，现From空间中的对象可以释放
    - 将两块空间的名字互换
  - 优点：
    - 吞吐量高：只需要遍历一次存活对象复制到 To空间，虽然比标记清除算法少一次遍历，但因为需要对对象进行内存空间的移动，性能逊色于标记清除算法
    - 不会产生碎片化
  - 缺点：内存使用效率低

- 标记-整理算法

  - 核心思想分为两个阶段
    - 标记阶段：将所有存活的对象进行标记。Java中使用可达性分析算法，从GC Root开始通过引用链遍历出所有存活的对象。
    - 整理算法：将存活对象移动到堆的一端。释放掉不再使用的对象的空间。
  - 优点：
    - 内存使用率高
    - 不会产生碎片化
  - 缺点：整理阶段的效率不高（整理算法有很多，如Lisp2、Two-Finger、表格算法、ImmixGC等算法等算法）

- <font color=red id="分代GC算法">分代GC算法</font>

  > 现代优秀的垃圾回收算法，会将上述的垃圾回收算法组合进行使用，其中应用最广的就是分代垃圾回收算法。

  - 将内存分为多个区域
    - 年轻代（Young）：存放存活时间比较短的对象
      - 伊甸园（Eden）
      - 幸存者区（Survivor）：复制算法
        - 幸存区0（S0、From/To）
        - 幸存区1（S1、To/From）
    - 老年代（Old）：存放存活时间比较长的对象
  
  - 虚拟机参数设置（使用SerialGC：-XX:+UseSerialGC）
  
    | 参数名                             | 参数含义                                                     |
    | ---------------------------------- | ------------------------------------------------------------ |
    | -Xmn值                             | 新生代大小                                                   |
    | -XX:SurvivorRatio=比值             | 伊甸园和每块幸存区的比例，默认8（8:1）<br/>若比值为3，年轻代20m，则伊甸区12m，幸存区0、1各4m |
    | -XX:+PrintGCDetails<br/>verbose:gc | 打印GC日志                                                   |
  
    - 内存的设置，其生效结果可能因 jdk版本 与 垃圾回收器 的不同而不同，此处使用jdk8、SerialGC
  
  - 核心思想
  
    - 分代回收时，创建出来的对象，首先会被放在Eden伊甸园
    - 如果Eden满了，新创建的对象无法放入，就会触发<font color=red>年轻代的GC</font>，称为Minor GC 或 Young GC
    - Minor GC 会把 Eden和From区 中需要回收的对象回收，把没有回收的对象放入 To区，随后将 From区和 To区名字互换
    - 每次 Minor GC中都会为对象记录年龄，初始值为0，每次GC完加1，当年龄达到阈值（具体值和垃圾回收器有关。最大15，因为对象标记mark word用了4bit记录年龄，最大值1111即15），对象就会被移到老年代
    - 如果整个年轻代满了，Minor GC后仍无法清出足够的空间存放新的对象，一些未到阈值年龄的对象也会被放入老年代
  
    - 当老年代空间不足时，无法放入新对象是，会先尝试minor GC，如果还是不足，就会触发Full GC，Full GC会对整个堆进行垃圾回收



#### 垃圾回收器

- 为什么分代GC算法要将堆分为新生代和老年代

  - 可以通过调整年轻代和老年代的比例来适应不同类型的应用程序，提高内存的利用率和性能
    - 在大多数应用中，老年代的大小都是远大于新生代的
    - 但在如购物节背景下的购物应用，订单对象可能快速增加，但该对象生命周期短，此时可以增大新生代，防止一些对象未到阈值年龄进入老年代而无法被及时回收
  - 新生代与老年代可以使用不同的垃圾回收算法，新生代一般使用复制算法，老年代可以选择标记-清除和标记-整理算法，灵活度较高
  - 新生代、老年代划分合理时，大多数情况下只会堆新生代进行GC（Minor GC），STW时间短。

- 分类与组合关系

  - <font color=red>指定垃圾回收器</font>

    > -XX:+PrintFlagsFinal：运行时，输出JVM所有参数

    - -XX:+UseSerialGC（年轻代、老年代都使用串行回收器）
    - -XX:+UseParNewGC（年轻代使用ParNew，老年代使用串行）
    - -XX:+UseParNewGC -XX:+UseConcMarkSweepGC（年轻代使用ParNew，老年代使用CMS）
      - -XX:CMSFullGCsBeforeCompaction=N（默认0），调整在N次FullGC之后整理碎片。

    - -XX:+UseParallelGC 或 -XX:+UseParallelOldGC（jdk8默认，使用 PS+PO 组合）
      - -XX:MaxGCPauseMillis=n：设置每次垃圾回收的最大停顿毫秒数
      - -XX:GCTimeRatio=n：设置吞吐量为n（用户线程执行时间=n/n +1）
      - -XX:+UseAdaptiveSizePolicy：（默认开启）设置让垃圾回收根据吞吐量和最大停顿的毫秒数自动调整内存大小

  - 垃圾回收器是垃圾回收算法的具体实现

  - 除G1之外，垃圾回收器分为年轻代和老年代。因此，除G1外，其他垃圾回收器需要成对组合使用。组合关系如下

    ![盒子模型](D:\picture\typora\后端2\垃圾回收器组合关系.png)

- 详细介绍

  - 年轻代-Serial：是一种<font color=red>单线程串行</font>回收年轻代的垃圾回收器
    - 步骤：Eden满后，会停止用户线程，使用单线程进行垃圾回收，在继续用户线程
    - 算法：复制算法
    - 优点：单CPU处理器下吞吐量优秀
    - 缺点：多CPU下吞吐量不如其他垃圾回收器，堆如果偏大会让用户线程长时间等待
    - 适用场景：Java编写的客户端程序或者硬件配置有限的场景

  - 老年代-SerialOld：是一种<font color=red>单线程串行</font>回收老年代的垃圾回收器
    - 算法：标记-整理算法
    - 优缺点、适用场景与年轻代-Serial 垃圾回收器相似
  
  
    - 年轻代-ParNew：本质是对Serial在多CPU下的优化，使用<font color=red>多线程</font>进行垃圾回收
      - 步骤：Eden满后，会停止用户线程，使用多线程进行垃圾回收，在继续用户线程
      - 算法：复制算法
      - 优点：多CPU处理器下停顿时间短
      - 缺点：吞吐量和停顿时间不入G1，所以在JDK9之后不建议使用
      - 适用场景：JDK8及之前版本中，与CMS老年代垃圾回收器搭配使用
  
  
    - 老年代-CMS：<font color=red>关注的是系统的暂停时间</font>，允许用户线程和垃圾回收线程在某些步骤中同时执行
      - 步骤：
        - 初始标记：先暂停用户线程；在单线程下，用极短的时间标记出GC Roots直接关联的对象
        - 并发标记：与用户线程并发调用，标记出GCRoots间接关联的对象
        - 重新标记：先暂停用户线程；由于并发标记阶段有些对象发生了变化，在多线程下，用极短时间纠正错标、漏标情况。
        - 并发清理：与用户线程并发调用，进行垃圾回收
      - 算法：标记-清除算法
      - 优点：系统由于垃圾回收出现的停顿时间较短，用户体验好
      - 缺点
        - 内存碎片：使用并发-清除算法，在垃圾收集结束后会存在大量的内存碎片，CMS会在Full GC时进行碎片整理，这是会导致用户线程暂停，可以使用-XX：CMSFullGCsBeforeCompaction=N（默认0），调整在N次FullGC之后整理碎片。
        - 浮动垃圾问题：无法清理在并发清理过程中产生的“浮动垃圾”，该“垃圾”只能等到下一次垃圾回收时清除，不能做到完全的垃圾回收
        - 退化：当内存不足无法分配对象时，CMS就会退化成SerialOld单线程回收老年代
      - 适用场景：大型互联网系统中，用户请求数据量大、频率高的场景。如订单接口、商品接口等
  
  
    - 年轻代-Parallel Scavenge：是jdk8默认的年轻代垃圾回收器，多线程并行回收，<font color=red>关注的是系统的吞吐量</font>。具备<font color=red>自动调整堆内存大小</font>的特点。
  
      - 算法：复制算法
  
      - 优点：吞吐量高，而且手动可控。为了提高吞吐量，虚拟机会动态调整堆的参数。
  
        - -XX:MaxGCPauseMillis=n：设置每次垃圾回收的最大停顿毫秒数
        - -XX:GCTimeRatio=n：默认99，设置吞吐量为n（用户线程执行时间=n/(n+1)）
  
        > 上面两个参数的设定值应根据多次测试得出。
        >
        > <font color=red>提高吞吐量，可能会让JVM减小年轻代的可用空间</font>
  
        - -XX:+UseAdaptiveSizePolicy：默认开启，设置让垃圾回收根据吞吐量和最大停顿的毫秒数自动调整内存大小
  
      - 缺点：不能保证单次的停顿时间
  
      - 适用场景：后台任务，不需要与用户交互（不用着重关注用户体验），并且容易产生大量的对象。如：大数据的处理，大文件的导出
  
  
    - 老年代-Parallel Old：与 PS 组合，利用多线程进行垃圾回收
  
      - 算法：标记-整理算法
      - 优点：并发收集，在多核CPU下效率最高
      - 缺点：不能保证单次的停顿时间
      - 适用场景：与PS组合使用
  
  
    - [G1](#G1)：JDK9及之后默认使用的垃圾回收器
  


  - 垃圾回收器的选择

    - JDK8及之前

        - ParNew + CMS：关注暂停时间
        - Parallel Scavenge + Parallel Old：关注吞吐量
        - G1：JDK8之前不建议，较大堆并且关注暂停时间

    - JDK9及之后：G1（默认）




#### <span id="G1">G1</span>

> JDK9及之后后默认使用的垃圾回收器
>
> -XX:+UseG1GC（打开G1开关，jdk9之前使用）

- 回收年代及算法：年轻代+老年代、复制算法

- 优点
  - 支持巨大的堆空间回收（如超过6G），并有较高的吞吐量
  - 不会产生内存碎片
  - 支持多CPU并行垃圾回收，并发标记长SATB算法效率高
  - 允许用户设置最大暂停时间
  
- 核心思想

  <table style="table-layout: fixed" border="1px" cellspacing="0">
      <tr>
          <td></td>
          <td style="background-color:#b7da88;">Eden</td>
          <td></td>
          <td style="background-color:#b7da88;">Eden</td>
          <td></td>
          <td></td>
      </tr>
      <tr>
          <td></td>
          <td></td>
          <td></td>
          <td></td>
          <td></td>
          <td style="background-color:rgba(32,178,178,0.96);">Old</td>
      </tr>
      <tr>
          <td></td>
          <td style="background-color:#ffd04c;" colspan="2">Humongous</td>
          <td style="background-color:#81eaea;">Survivor</td>
          <td></td>
          <td></td>
      </tr>
      <tr>
          <td></td>
          <td></td>
          <td></td>
          <td></td>
          <td></td>
          <td style="background-color:rgba(32,178,178,0.96);">Old</td>
      </tr>

  - G1的整个堆会被划分为多个大小相等的区域，称之为Region，区域不要求是连续的。分为多个 Eden、Survivor、Old区。Region的大小默认可通过 堆空间大小/2048 计算得到，也可以通过参数 -XX:G1HeapRegionSize=值（值必须是2的指数幂，取值范围为1M到32M）指定
  - 部分对象如果大小超过了Region的一半，会直接放到老年代，这类老年代被称为Humongous区。如果超过了Region，则会横跨多个Region
  - G1垃圾回收的两种方式
    - 年轻代回收（Young GC）
    - 混合回收（Mixed GC）

- 年轻代回收（Young GC）

  - 回收Eden和Survivor区中不用的对象。

  - 会导致STW，G1中可以通过参数 -XX:MaxGCPauseMillis=值（默认200）设置每次垃圾回收时的最大暂停时间，G1会尽可能的保证暂停时间

  - 执行流程

    - 新创建的对象会被放在Eden区。当G1判断年轻代不足（默认在年轻代占总堆空间的60%时），无法分配对象需要回收时会触发 YoungGC

    - 标记出Eden和Survivor区域中存活的对象

    - 根据最大配置的暂停时间选择某些区域，将这些区域中存活的对象复制到一个新的Survivor区中（对象年龄+1），然后清空这些区域

      > G1在进行YoungGC的过程中会去记录每次垃圾回收时每一个回收区域的平均回收耗时，作为下次回收的参考依据。这样就可以根据配置的最大暂停时间，计算出本次回收时最多能回收多少个Region区域。
      >
      > 比如 -XX:MaxGCPauseMillis=200，每个Region回收耗时40ms，那么这次回收最多只能回收4个区域（回收5个可能会超时）

    - 后续的YoungGC与之前相同，只不过Survivor区中存活的对象会被搬运到另一个Survivor区中

    - 当某个存活对象的年龄达到阈值（默认15），将会被放入老年代

    - 多次回收之后，会出现很多Old老年代，此时总堆占有率达到阈值时（可通过 -XX:InitiatingHeapOccupancyPercent=45 默认即45%）会触发混合回收。回收所有年轻代和部分老年代的对象以及大对象区。采用复制算法来完成。

- 混合回收（Mixed GC）

  - 执行流程
    - 初始标记：先暂停用户线程；再多线程并发将GCRoots直接关联的对象标记为存活
    - 并发标记：与用户线程并发执行，将与GCRoots间接关联的对象也标记为存活
    - 最终标记：先暂停用户线程；由于并发标记阶段有些对象发生了变化，在多线程下，标记一些引用改变漏标的对象，不管新创建、不再关联的对象
    - 并发清理：与用户线程并发执行，将存活的对象复制到别的Region，不会产生内存碎片
  - G1对老年代的清理会优先选择存活度最低的区域来回收，这样可以保证回收效率最高，这也就是G1（Garbage First）名字的由来
  - 如果清理过程中发现没有足够的空Region来存放转移的对象，会触发FullGC（单线程执行标记-整理算法），此时可能会导致用户线程长时间暂停

  





# MQ



## 问题处理

- 消息可靠性问题：确保发送的消息至少被消费一次
- 消息延迟问题
- 消息堆积问题
- 高可用问题：避免单点mq故障



### 消息可靠性

- 哪些可能会导致消息丢失
  - 发送者发送的消息未送达exchange
  - 消息到exchange后未到达queue

- mq宕机，queue将消息丢失
- consumer接收到消息后未消费就宕机



#### 生产者消息确认

- Rabbitmq提供了publisher confirm机制来避免消息发送到MQ的过程中丢失。消息发送到MQ以后，会返回一个结果给发送者，表示消息是否处理成功。结果有两种请求
  - publisher-confirm，发送者确认
    - 消息成功投递到交换机，返回ack
    - 消息未成功投递到交换机，返回nack
  - publisher-return，发送者回执
    - 消息投递到交换机，但是没有路由到队列，返回ack，及路由失败原因
  - 确认机制发送消息时，需要给每个消息设置一个全局唯一id，以区分不同消息





#### 消息持久化

#### 消费者消息确认

#### 消费失败重试机制





### 私信交换机



### 惰性队列

### MQ集群









# ELK

![ELFK](D:\picture\typora\java2\ElasticStack\ELFK.png)

## ElasticSearch

### 概念

#### docker部署

- 还需要部署kibana容器，因此需要先创建一个网络，让es和kibana容器互联。

  ```shell
  docker network create es-net
  ```

- 拉去elasticsearch镜像

  ```shell
  docker pull elasticsearch:7.12.1
  ```

- 创建挂载目录

  ```shell
  mkdir -p /var/docker-volume/es
  ```

- 转移数据

  ```shell
  docker run -d \
  	--name es \
  	-e "ES_JAVA_OPTS=-Xms512m -Xmx512m" \
  	-e "discovery.type=single-node" \
  	--privileged \
  	--network es-net \
  	elasticsearch:7.12.1
  	
  docker cp es:/usr/share/elasticsearch/data /var/docker-volume/es
  docker cp es:/usr/share/elasticsearch/plugins /var/docker-volume/es
  
  docker stop es
  docker rm es
  ```

- 运行es容器

  ```shell
  docker run -d \
  	--name es \
  	-e "ES_JAVA_OPTS=-Xms512m -Xmx512m" \
  	-e "discovery.type=single-node" \
  	-v /var/docker-volume/es/data:/usr/share/elasticsearch/data \
  	-v /var/docker-volume/es/plugins:/usr/share/elasticsearch/plugins \
  	--privileged \
  	--network es-net \
  	-p 9200:9200 \
  	-p 9300:9300 \
  	elasticsearch:7.12.1
  ```

- 安装运行kibana

  ```shell
  docker run -d \
  	--name kibana \
  	-e ELASTICSEARCH_HOSTS=http://192.168.36.132:9200 \
  	--network=es-net \
  	-p 5601:5601 \
  	kibana:7.12.1
  ```



#### ik分词器

- 安装ik分词器

  ```shell
  # 进入容器内部
  docker exec -it es /bin/bash
  # 在线下载并安装
  ./bin/elasticsearch-plugin install https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v7.12.1/elasticsearch-analysis-ik-7.12.1.zip
  # 退出容器
  exit
  # 重启容器
  docker restart es
  ```

- 拓展词库

  - 修改ik分词器目录下的config目录中的IkAnalyzer.cfg.xml文件

    ```xml
    <?xml version="1.0" encoding="UTF-8"?>
    <!DOCTYPE properties SYSTEM "http://java.sun.com/dtd/properties.dtd">
    <properties>
    	<comment>IK Analyzer 扩展配置</comment>
    	<!--用户可以在这里配置自己的扩展字典 -->
    	<entry key="ext_dict"></entry>
    	 <!--用户可以在这里配置自己的扩展停止词字典-->
    	<entry key="ext_stopwords"></entry>
        
    	<!--用户可以在这里配置远程扩展字典 -->
    	<!-- <entry key="remote_ext_dict">words_location</entry> -->
    	<!--用户可以在这里配置远程扩展停止词字典-->
    	<!-- <entry key="remote_ext_stopwords">words_location</entry> -->
    </properties>
    ```





### CRUD

#### devTool

##### 操作索引库

- mapping
  - mapping是对索引库中文档的约束，常见的mapping属性包括
    - type：字段数据类型，常用的简单类型有：
      - 字符串：text（可分次的文本）、keyword（精确值，例如：品牌、国家、ip地址）
      - 数值：long、integer、short、byte、double、float
      - 布尔：boolean
      - 日期：date
      - 对象：object
    - index：是否创建倒排索引，默认为true
    - analyzer：使用哪种分词器
      - ik插件：ik_smart、ik_max_word
    - properties：该字段的子属性
  
- 创建索引库

  - ES中通过Restful请求操作索引库、文档。请求内容用DSL语句来表示

    ```json
    PUT /索引库名称
    {
        "mappings": {
            "properties": {
                "字段名1": {
                    "type": "text",
                    "analyzer": "ik_smart"
                },
                "字段名2": {
                    "type": "keyword",
                    "analyzer": "false",
                    "properties": {
                        "子字段": {
                            "type": "keyword"
                        }
                    }
                },
                // ... 略
            }
        }
    }
    ```

- 查询索引库

  - GET /索引库名

- 删除索引库

  - DELETE /索引库名

- 修改索引库：只能添加新字段

  ```json
  PUT /索引库名/_mapping
  {
      "properties": {
          "新字段名": {
              "type": "integer"
          }
      }
  }
  ```



##### 文档操作

- 新增文档

  ```json
  POST /索引库名/_doc/文档id
  {
      "字段1": "值1",
      "字段2": "值2",
      "字段3": {
          "子属性1": "值3",
          "子属性2": "值4"
      },
      // ...
  }
  ```

- 查询文档：GET /索引库/_doc/文档id

- 删除文档：DELETE  /索引库/_doc/文档id

- 修改文档：

  - 全文修改，会删除旧文档，添加新文档，使用PUT请求

  - 局部修改

    ```json
    PUT /索引库名/_update/文档id
    {
        "doc": {
            "字段名": "新的值"
        }
    }
    ```






#### java

##### 前置配置

- 引入es的 RestHighLevelClient 依赖

  ```xml
  <dependency>
      <groupId>org.elasticsearch.client</groupId>
      <artifactId>elasticsearch-rest-high-level-client</artifactId>
  </dependency>
  ```

- 因为springboot默认配置的es版本是7.6.2，所有需要覆盖默认的es版本

  ```xml
  <properties>
      <elasticsearch.version>7.12.1</elasticsearch.version>
  </properties>
  ```

- 初始化RestHighLevelClient

  ```java
  @SpringBootTest
  public class TestApp {
      private RestHighLevelClient client;
  
      @BeforeEach
      void setUp() {
          this.client = new RestHighLevelClient(RestClient.builder(
              HttpHost.create("http://192.168.36.132:9200")));
      }
  
      @AfterEach
      void tearDown() throws IOException {
          this.client.close();
      }
  }
  ```



##### 操作索引库

- 创建索引库

  ```java
  CreateIndexRequest request = new CreateIndexRequest("anime");
  request.source(ESConstant.animeIndex, XContentType.JSON);
  client.indices().create(request, RequestOptions.DEFAULT);
  ```

- 删除索引库

  ```java
  DeleteIndexRequest request = new DeleteIndexRequest("anime");
  client.indices().delete(request, RequestOptions.DEFAULT );
  ```

- 判断索引库是否存在

  ```java
  GetIndexRequest request = new GetIndexRequest("anime");
  boolean exists = client.indices().exists(request, RequestOptions.DEFAULT);
  System.out.println(exists);
  ```



##### 操作文档

- 新增文档

  ```java
  @Test
  public void addDoc() throws IOException {
      Anime anime = animeService.getById(1);
      AnimeDoc animeDoc = new AnimeDoc(anime);
      IndexRequest request = new IndexRequest("anime").id("1");
      request.source(JSONUtil.toJsonStr(animeDoc), XContentType.JSON);
      client.index(request, RequestOptions.DEFAULT);
  }
  ```

- 查询文档

  ```java
  GetRequest getRequest = new GetRequest("anime").id("1");
  GetResponse response = client.get(getRequest, RequestOptions.DEFAULT);
  AnimeDoc animeDoc = JSONUtil.toBean(response.getSourceAsString(), AnimeDoc.class);
  System.out.println(animeDoc);
  ```

- 删除文档

  ```java
  DeleteRequest request = new DeleteRequest("anime").id("1");
  client.delete(request, RequestOptions.DEFAULT);
  ```

- 修改文档

  - 全量更新：与新增文档类似

  - 局部更新

    ```java
    @Test
    public void updateDoc() throws IOException {
        UpdateRequest request = new UpdateRequest("anime", "1");
        request.doc("state", 10, "type", "日常");
        client.update(request, RequestOptions.DEFAULT);
    }
    ```

- 批量新增

  ```java
  BulkRequest request = new BulkRequest();
  List<Anime> list = animeService.list();
  for (Anime anime : list) {
      AnimeDoc animeDoc = new AnimeDoc(anime);
      IndexRequest indexRequest = new IndexRequest("anime")
          .id(anime.getId()+"")
          .source(JSONUtil.toJsonStr(animeDoc), XContentType.JSON);
      request.add(indexRequest);
  }
  client.bulk(request, RequestOptions.DEFAULT);
  ```





### DSL

#### devTool

##### 基本语法

- DSL Query基本语法

  ```json
  GET /索引库名/_search
  {
      "query": {
          "查询类型": {
              "查询条件": "条件值"
          }
      }
  }
  ```

- match查询

  ```json
  GET /索引库名/_search
  {
      "query": {
          "match": {
              "字段": "内容"
          }
      }
  }
  ```

- multi_match查询

  ```json
  GET /索引库名/_search
  {
      "query": {
          "multi_match": {
              "query": "内容",
              "field": ["字段1", "字段2"]
          }
      }
  }
  ```

- 精确查询

  - term：根据词条精确值查询

    ```json
    GET /索引库名/_search
    {
        "query": {
            "term": {
                "字段": {
                    "value": "值"
                }
            }
        }
    }
    ```

  - range：根据值的范围查询

    ```json
    GET /索引库名/_search
    {
        "query": {
            "range": {
                "字段": {
                    "gte": 最小值,
                    "lte": 最大值
                }
            }
        }
    }
    ```

  - geo_bounding_box：根据geo_point值落在某个矩形范围的所有文档

    ```json
    GET /索引库名/_search
    {
        "query": {
            "geo_bounding_box": {
                "字段": {
                    "top_left": {
                        "lat": 31.1,
                        "lon": 121.5
                    },
                    "bottom_right": {
                        "lat": 30.9,
                        "lon": 121.7
                    }
                }
            }
        }
    }
    ```

  - geo_distance：根据geo_point搜索附近指定范围内的所有文档

    ```json
    GET /索引库名/_search
    {
        "query": {
            "geo_distance": {
                "distance": "15km",
                "字段": "3"
            }
        }
    }
    ```

    

##### 复合查询

- 相关性算分

  - TF
    - TF（词条频率）= 词条出现次数 / 文档中词条总数
  - TF-IDF：elasticsearch5.0之前，分数会随着词频的增加而越来越大
    - IDF（逆文档频率）= log(文档总数 / 包含词条的文档总数)
    - score = ∑^n^~i~ TF  * IDF
  - BM25：elasticsearch5.0后，分数会随着词频增大而增大，但曲线最终会趋于水平

- Function Score Query

  - 修改文档的相关性算分
  - 算分函数：functions
    - filter：定义对哪些文档进行处理
    - weight：给一个常量值，作为函数结果
    - field_value_factor：用文档中的某个字段值作为函数结果
    - random_score：随机生成一个值，作为函数结果
    - scropt_score：自定义计算公式，公式结果作为函数结果
  - 加权模式：boost_mode
    - multiply：function score和query score相乘，默认
    - replace：用function score 替换 query score
    - 其他：sum、avg、max、min

  ```json
  GET /索引库名/_search
  {
      "query": {
          "function_score": {
              "query": {"match": {"字段": "内容"}},
              "functions": [
                  {
                      "filter": {"term": {"字段": "内容"}},
                      "weight": 10
                  }
              ],
              "boost_mode": "multiply"
          }
      }
  }
  ```

- Boolean Query

  - 布尔查询是一个或多个查询子句的组合，子查询的组合方式有：
    - must：必须匹配每个字符串，参与算分
    - should：选择性匹配，参与算分
    - must_not：必须不匹配，不参与算分
    - filter：必须匹配，不参与算分

  ```json
  GET /索引库名/_search
  {
      "query": {
          "bool": {
              "must": [{"term": {"字段": "内容"}}],
              "should": [{"term": {"字段1": "内容2"}, {"term": {"字段2": "内容2"}],
              "must_not": [{"range": {"price": {"let": 500}}}],
              "filter": [
                  {
                      "geo_distance": {
                          "distance": "10km",
                          "location": {"lat": 31.21, "lon": 121.5}
                      }
                  }
              ]
          }
      }
  }
  ```

  

##### 结果处理

- 结果排序

  - 默认根据相关度算分来排序，可排序的字段类型有：keyword、数值类型、地理坐标类型、日期类型
    - asc：升序
    - desc：降序

  ```json
  GET /索引库名/_search
  {
      "query": {
          "match_all": {}
      },
      "sort": [
          {"字段": "desc"},
          {
              "_geo_distance": {
                  "location": {"lat": "纬度", "lon": "经度"},
                  "order": "asc",
                  "unit": "km"
              }
          }
      ]
  }
  ```

- 分页

  - 简单分页
    - from：分页开始的位置
    - size：每页文档条数
    - 优点：支持随机翻页
    - 缺点：深度分页问题，默认查询上限是10000
  - after search
    - 先排序，再记录该页最后条数据，下次查询从该范围查询
    - 优点：利用多次查询，可查出10000以上数据
    - 缺点：只能向后查询，不支持随机翻页
  - scroll：记录快照

- 高亮显示

  - 默认匹配的字段要与需要高亮的字段相同

  ```json
  GET /索引库名/_search
  {
      "query": {
          "match": {
              "字段 ": "内容"
          }
      },
      "highlight": {
          "fields": {
              "字段": {
                  //"reuqire_field_match": "false" //字段可以不相同
                  "pre_tags": "<em>",
                  "post_tags": "</em>"
              }
          }
      }
  }
  ```

  



#### java

##### 简单查询

```java
@Test
public void matchAll() throws IOException {
    SearchRequest request = new SearchRequest("anime");

    BoolQueryBuilder boolQueryBuilder = QueryBuilders.boolQuery();
    boolQueryBuilder.must(QueryBuilders.matchQuery("all", "日常搞笑"));
    boolQueryBuilder.must(QueryBuilders.termQuery("all", "校园"));
    request.source().query(boolQueryBuilder);
    request.source().from(0).size(5);

    SearchResponse response = client.search(request, RequestOptions.DEFAULT);
    SearchHits hits = response.getHits();
    System.out.println("共搜索到 " + hits.getTotalHits().value + " 条数据");
    for (SearchHit hit : hits.getHits()) {
        System.out.println(hit.getSourceAsString());
        // 获得一个map集合，可用于替换hit中的信息
        System.out.println(hit.getHighlightFields());
    }
}
```



##### 组合查询

```java
FunctionScoreQueryBuilder functionScoreQueryBuilder = QueryBuilders.functionScoreQuery(
    QueryBuilders.boolQuery()
    .must(QueryBuilders.matchQuery("all", "日常搞笑"))
    .must(QueryBuilders.termQuery("all", "校园")),
    new FunctionScoreQueryBuilder.FilterFunctionBuilder[]{
        new FunctionScoreQueryBuilder.FilterFunctionBuilder(
            QueryBuilders.termQuery("type", "搞笑"),
            ScoreFunctionBuilders.weightFactorFunction(10))
    }
);
```





### 数据聚合

- 聚合的分类
  - Bucket：桶聚合
  - Metric：度量聚合
  - Pipeline：管道聚合

- devTool

  ```json
  GET /索引库名/_search
  {
      //"query": {}, // 可加限定条件，指定对部分数据进行聚合，默认对所有文档聚合 
      "size": 0, // 分页中每页展示数据
      "aggs": {
          "自定义聚合名": {
              "terms": {
                  "field": "聚合字段",
                  //"order": {"_count": "asc"}, // 升序排列，默认降序
                  "size": 10 // 展示数据条数
              }
          }
      }
  }
  ```

  ```json
  GET /索引库名/_search
  {
      "size": 0,
      "aggs": {
          "自定义聚合名1": {
              "terms": {"field": "聚合字段", "size": 10},
              // 聚合的嵌套
              "order": {"自定义聚合名2.avg": "asc"},
              "aggs": {
                  "自定义聚合名2": {
                      "stats": { // 聚合类型，这里的stats可以计算min、max、avg等
                          "field": "聚合字段"
                      }
                  }
              }
          }
      }
  }
  ```

- java

  ```java
  SearchRequest request = new SearchRequest("anime");
  request.source().size(0);
  request.source().aggregation(AggregationBuilders.stats("stateAgg").field("state"));
  ```

  



### 自动补全

#### 分词器

- 拼音分词器

- 自定义分词器：在创建索引库的时候设置分词器

  ```json
  PUT /test
  {
    "settings": {
      "analysis": {
        "analyzer": {
          "my_analyzer": {
            "tokenizer": "ik_max_word",
            "filter": "py"
          }
        },
        "filter": {
          "py": {
            "type": "pinyin",
            "keep_full_pinyin": false,
            "keep_joined_full_pinyin": true,
            "keep_original": true,
            "limit_first_letter_length": 16,
            "remove_duplicated_term": true,
            "none_chinese_pinyin_tokenize": false
          }
        }
      }
    },
    "mappings": {
      "properties": {
        "overview": {
          "type": "text",
          "analyzer": "my_analyzer",
          "search_analyzer": "ik_smart"
        }
      }
    }
  }
  ```

  ```json
  POST /test/_analyze
  {
    "text": "你好世界",
    "analyzer": "my_analyzer"
  }
  ```

  

#### 自动补全

- 自动补全对字段的要求
  - 类型是completion类型
  - 字段值是多词条的数组

- 查询语法

  ```json
  GET /索引库名/_search
  {
      "suggest": {
          "自定义名": {
              "text": "关键字",
              "completion": {
                  "field": "字段",
                  "skip_duplicates": true, // 跳过重复的
                  "size": 10 // 显示条数
              }
          }
      }
  }
  ```





### 数据同步

- mysql与es间数据的同步

- 解决

  - 同步调用

  - 异步通知：使用消息中间键

  - 监听binlog





### 集群

- 海量数据存储问题：
  - 将索引库从逻辑上拆分为n个分片，存储到多个节点
- 单点故障问题：
  - 将分片数据备份，并放在其他节点上
- 集群状态的监控
  - cerebro：https://github.com/lmenezes/cerebro/releases



#### 创建集群

- docker-compose编排文件

  ```shell
  version: '2.2'
  services:
    es01:
      image: elasticsearch:7.12.1
      container_name: es01
      environment:
        - node.name=es01
        - cluster.name=es-docker-cluster # 集群名称相同后，会自动组装为一个集群
        - discovery.seed_hosts=es02,es03 # 已配置容器互连后，地址简写为容器名
        - cluster.initial_master_nodes=es01,es02,es03 # 初始化的主节点
        - bootstrap.memory_lock=true
        - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
      ulimits:
        memlock:
          soft: -1
          hard: -1
      volumes:
        - ./data/node0:/usr/share/elasticsearch/data
        - ./logs/node0:/usr/share/elasticsearch/logs
      ports:
        - 9200:9200
      networks:
        - elastic
    es02:
      image: docker.elastic.co/elasticsearch/elasticsearch:7.4.0
      container_name: es02
      environment:
        - node.name=es02
        - cluster.name=es-docker-cluster
        - discovery.seed_hosts=es01,es03
        - cluster.initial_master_nodes=es01,es02,es03
        - bootstrap.memory_lock=true
        - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
      ulimits:
        memlock:
          soft: -1
          hard: -1
      volumes:
        - ./data/node1:/usr/share/elasticsearch/data
        - ./logs/node1:/usr/share/elasticsearch/logs
      networks:
        - elastic
    es03:
      image: docker.elastic.co/elasticsearch/elasticsearch:7.4.0
      container_name: es03
      environment:
        - node.name=es03
        - cluster.name=es-docker-cluster
        - discovery.seed_hosts=es01,es02
        - cluster.initial_master_nodes=es01,es02,es03
        - bootstrap.memory_lock=true
        - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
      ulimits:
        memlock:
          soft: -1
          hard: -1
      volumes:
        - ./logs/node2:/usr/share/elasticsearch/data
        - ./logs/node2:/usr/share/elasticsearch/logs
      networks:
        - elastic
        
  networks:
    elastic:
      driver: bridge
  ```

- 修改linux的系统权限

  - 编辑文件：vi /etc/sysctl.conf
  - 添加内容：vm.max_map_count=262144
  - 让配置生效：sysctl -p

- 设置分片与备份

  ```json
  PUT /索引库名
  {
      "settings": {
          "number_of_shards": 3, // 分片信息
          "number_of_replicas": 1 // 副本数量
      },
      "mappings": {"properties": { 。。。}}
  }
  ```

  

#### 集群职责

| 节点类型        | 配置参数    | 默认值 | 节点职责                                                     |
| --------------- | ----------- | ------ | ------------------------------------------------------------ |
| master eligible | node.master | true   | 备选主节点：主节点可以管理和记录集群状态、决定分片<br/>在哪个节点、处理创建和删除索引库的请求 |
| data            | node.data   | true   | 数据节点：存储数据、搜索、聚合、CRUD                         |
| ingest          | node.ingest | true   | 数据存储之前的预处理                                         |
| coordinating    |             |        | 所有es节点：路由请求，合并结果                               |

- 脑裂问题
  - 解决：成为主节点需要选票超过（eligible节点数 + 1）/ 2 才能当选，因此eligible节点最好为奇数
- coordinating节点
  - 新增是，通过算法将请求发送到一个data节点
  - 查询时，将请求路由到各个data节点，各个节点查完后，汇总到该coordinating节点
- 故障转移
  - 集群中的master节点会监控各个节点状态，如果有节点宕机
    - 启用其他节点上的备份数据
    - 将宕机节点的分片数据迁移到其他节点，使数据处于健康状态
  - 健康状态：如果有节点宕机，可利用备份数据进行恢复













## Logstash

## Kibana









# Kubenetes
